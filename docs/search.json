[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Teaching assistant at the University of Primorska, that includes (or included) labs and practicals of\n\nMarine Ecology,\nMarine Conservation Biology,\nEcology of terrestrial ecosystems,\nAdvanced topics in Conservation biology (in which I teach Introduction to R),\nBiology and conservation of large vertebrates,\nMarine protected areas - human dimensions,\nPopulation biology,\nConservation ecology of marine mammals\n\nat master study programme Nature Conservation and:\n\nBasics of using R as GIS,\nIntroductory zoology,\nBiology and diversity of vertebrates\n\nat bachelor study programme Conservation biology.\nI finished master studies of Nature Conservation in 2015 (University of Primorska, Slovenia) and bachelor studies of Ecology and Nature Conservation in 2012 (University of Maribor, Slovenia). Currently I am a PhD student formally enrolled at University of Ljubljana, Slovenia, with the dissertation title Spatial ecology and conservation of loggerhead sea turtles in Adriatic sea under supervision of Assoc. Prof. Bojan Lazar (UP) and Assist. Prof. Tomaž Skrbinšek (UL)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Matic Jančič: Teaching portfolio",
    "section": "",
    "text": "PROJECTING SPECIES DISTRIBUTION ACCORDING TO FUTURE SCENARIOS\n\n\n\nIntroduction to species distribution models in R\n\n\n\nIntroduction to species distribution models, Lab 5\n\n\n\nMatic Jančič & assist. prof. Peter Glasnović; Department of biodiversity, University of Primorska\n\n\nNov 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMODEL EVALUATION AND REPRESENTATION\n\n\n\nIntroduction to species distribution models in R\n\n\n\nIntroduction to species distribution models, Lab 4\n\n\n\nMatic Jančič & assist. prof. Peter Glasnović; Department of biodiversity, University of Primorska\n\n\nOct 31, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMODELING ALGORITHMS AND MODEL FITTING\n\n\n\nIntroduction to species distribution models in R\n\n\n\nIntroduction to species distribution models, Lab 3\n\n\n\nMatic Jančič & assist. prof. Peter Glasnović; Department of biodiversity, University of Primorska\n\n\nOct 24, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOBTAINING, ASSESSING AND EXTRACTING ENVIRONMENTAL DATA\n\n\n\nIntroduction to species distribution models in R\n\n\n\nIntroduction to species distribution models, Lab 2\n\n\n\nMatic Jančič & assist. prof. Peter Glasnović; Department of biodiversity, University of Primorska\n\n\nOct 17, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOBTAINING OCCURRENCES AND CREATING PSEUDO-ABSENCES OF SPECIES\n\n\n\nIntroduction to species distribution models in R\n\n\n\nIntroduction to species distribution models, Lab 1\n\n\n\nMatic Jančič & assist. prof. Peter Glasnović; Department of biodiversity, University of Primorska\n\n\nOct 10, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSUMMARY STATISTICS IN R\n\n\n\nIntroduction to R\n\n\n\nAdvanced Topics in Conservation Biology, Lab 5\n\n\n\nMatic Jančič; Department of biodiversity, University of Primorska\n\n\nSep 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGRAPHICAL DATA EXPLORATION IN R\n\n\n\nIntroduction to R\n\n\n\nAdvanced Topics in Conservation Biology, Lab 4\n\n\n\nMatic Jančič; Department of biodiversity, University of Primorska\n\n\nSep 18, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSELECTING, FILTERING AND CREATING NEW VARIABLES IN R\n\n\n\nIntroduction to R\n\n\n\nAdvanced Topics in Conservation Biology, Lab 3\n\n\n\nMatic Jančič; Department of biodiversity, University of Primorska\n\n\nSep 15, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWORKING DIRECTORIES AND DATA IMPORT IN R\n\n\n\nIntroduction to R\n\n\n\nAdvanced Topics in Conservation Biology, Lab 2\n\n\n\nMatic Jančič; Department of biodiversity, University of Primorska\n\n\nSep 4, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRASTRSKI PODATKI Z VISOKO LOČLJIVOSTJO V R-U\n\n\n\nUvod v R kot GIS\n\n\n\nGeografski informacijski sistemi in vede, Vaja 4\n\n\n\nMatic Jančič; Department of biodiversity, University of Primorska\n\n\nMar 25, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMARINE SPECIES AND GEOSPATIAL DATA EXPLORATION AND VISUALIZATION\n\n\n\nIntroduction to marine ecological data in R\n\n\n\nWorkshop Day 4 at Faculty of Natural Sciences, Juraj Dobrila University of Pula\n\n\n\nMatic Jančič; Department of biodiversity, University of Primorska\n\n\nMar 24, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nACCESSING MARINE GEOSPATIAL DATA IN R WITH SDMPREDICTORS\n\n\n\nIntroduction to marine ecological data in R\n\n\nIntroduction to GIS in R\n\n\n\nWorkshop Day 3 at Faculty of Natural Sciences, Juraj Dobrila University of Pula\n\n\n\nMatic Jančič; Department of biodiversity, University of Primorska\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGLOBALNI OKOLJSKI PODATKI V R-U\n\n\n\nUvod v R kot GIS\n\n\n\nGeografski informacijski sistemi in vede, Vaja 3\n\n\n\nMatic Jančič; Department of biodiversity, University of Primorska\n\n\nMar 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nACCESSING MARINE SPECIES OCCURENCES IN R WITH RGBIF\n\n\n\nIntroduction to marine ecological data in R\n\n\nIntroduction to GIS in R\n\n\n\nWorkshop Day 2 at Faculty of Natural Sciences, Juraj Dobrila University of Pula\n\n\n\nMatic Jančič (& Peter Glasnović); Department of biodiversity, University of Primorska\n\n\nMar 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nDOSTOP DO PODATKOV IZ PORTALA GBIF IN PRIKAZ Z UPORABO ORODIJ LEAFLET\n\n\n\nUvod v R kot GIS\n\n\n\nGeografski informacijski sistemi in vede, Vaja 2\n\n\n\nMatic Jančič (& Peter Glasnović); Department of biodiversity, University of Primorska\n\n\nMar 22, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nUVOD V UPORABO PROGRAMSKEGA JEZIKA R KOT GIS\n\n\n\nUvod v R kot GIS\n\n\n\nGeografski informacijski sistemi in vede, Vaja 1\n\n\n\nMatic Jančič; Department of biodiversity, University of Primorska\n\n\nMar 21, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nINTRODUCTION TO R & R STUDIO\n\n\n\nIntroduction to marine ecological data in R\n\n\nIntroduction to R\n\n\nIntroduction to GIS in R\n\n\n\nWorkshop Day 1 at Faculty of Natural Sciences, Juraj Dobrila University of Pula\n\n\n\nMatic Jančič; Department of biodiversity, University of Primorska\n\n\nMar 21, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/01_INTRODUCTION TO R & R STUDIO.html",
    "href": "posts/01_INTRODUCTION TO R & R STUDIO.html",
    "title": "INTRODUCTION TO R & R STUDIO",
    "section": "",
    "text": "Summary\n\n\n\nIn this lab, you will be introduced to:\n\nR and RStudio,\nusing R scripts to type and run basic R code,\nusing basic operations (addition, subtraction, multiplication) and logical operators in R,\nfundamental data types in R: vectors, dataframes and lists."
  },
  {
    "objectID": "posts/01_INTRODUCTION TO R & R STUDIO.html#partly-funded-by-eu-erasmus-programme-for-higher-education-staff-mobility.",
    "href": "posts/01_INTRODUCTION TO R & R STUDIO.html#partly-funded-by-eu-erasmus-programme-for-higher-education-staff-mobility.",
    "title": "INTRODUCTION TO R & R STUDIO",
    "section": "",
    "text": "Partly funded by EU Erasmus+ Programme for Higher Education Staff Mobility"
  },
  {
    "objectID": "posts/02_GIS_GBIF.html",
    "href": "posts/02_GIS_GBIF.html",
    "title": "ACCESSING MARINE SPECIES OCCURENCES IN R WITH RGBIF",
    "section": "",
    "text": "Summary\n\n\n\nIn this lab, you will be introduced to:\n\nGlobal Biodiversity Information Facility (GBIF) database,\ninstalling and loading R packages,\nusing R code to access the marine species occurrence data on GBIF server and download it,\ndata filtering and selecting to retain only information of interest,\nsimple visualization of spatial points."
  },
  {
    "objectID": "posts/02_GIS_GBIF.html#partly-funded-by-eu-erasmus-programme-for-higher-education-staff-mobility.",
    "href": "posts/02_GIS_GBIF.html#partly-funded-by-eu-erasmus-programme-for-higher-education-staff-mobility.",
    "title": "ACCESSING MARINE SPECIES OCCURENCES IN R WITH RGBIF",
    "section": "",
    "text": "Partly funded by EU Erasmus+ Programme for Higher Education Staff Mobility"
  },
  {
    "objectID": "posts/03_GIS_GLOBAL ENV DATA.html",
    "href": "posts/03_GIS_GLOBAL ENV DATA.html",
    "title": "ACCESSING MARINE GEOSPATIAL DATA IN R WITH SDMPREDICTORS",
    "section": "",
    "text": "In this lab, you will be introduced to:\n\nraster data types and R packages for working with it,\naccessing and downloading marine (and/or terrestrial) global raster data with sdmpredictors package,\ninspecting the properties of a raster layer,\ncolors in R,\nsimple visualization of global raster layer."
  },
  {
    "objectID": "posts/03_GIS_GLOBAL ENV DATA.html#partly-funded-by-eu-erasmus-programme-for-higher-education-staff-mobility.",
    "href": "posts/03_GIS_GLOBAL ENV DATA.html#partly-funded-by-eu-erasmus-programme-for-higher-education-staff-mobility.",
    "title": "ACCESSING MARINE GEOSPATIAL DATA IN R WITH SDMPREDICTORS",
    "section": "",
    "text": "Partly funded by EU Erasmus+ Programme for Higher Education Staff Mobility"
  },
  {
    "objectID": "posts/04_DATA EXPLORATION.html",
    "href": "posts/04_DATA EXPLORATION.html",
    "title": "MARINE SPECIES AND GEOSPATIAL DATA EXPLORATION AND VISUALIZATION",
    "section": "",
    "text": "In this lab, you will be introduced to:\n\nextracting values from raster layers at locations of species occurrences,\nsimple visualization of numerical data (boxplots) with ggplot2."
  },
  {
    "objectID": "posts/04_DATA EXPLORATION.html#partly-funded-by-eu-erasmus-programme-for-higher-education-staff-mobility.",
    "href": "posts/04_DATA EXPLORATION.html#partly-funded-by-eu-erasmus-programme-for-higher-education-staff-mobility.",
    "title": "MARINE SPECIES AND GEOSPATIAL DATA EXPLORATION AND VISUALIZATION",
    "section": "",
    "text": "Partly funded by EU Erasmus+ Programme for Higher Education Staff Mobility"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Glasnović, P., Fišer, Ž., Jančič, M., Balant, M., and Surina, B. (2023). Areography, environmental heterogeneity and spatial models explain patterns of past and present diversity in Edraianthus (Campanulaceae). Botanical Journal of the Linnean Society, boac079. doi: 10.1093/botlinnean/boac079.\n\n\nJančič, M., Salvemini, P., Holcer, D., Piroli, V., Haxhiu, I., and Lazar, B. (2022). Apparent increasing importance of Adriatic Sea as a developmental habitat for Mediterranean green sea turtles (Chelonia mydas). Natura Croatica 31, 225–240. doi: 10.20302/NC.2022.31.16."
  },
  {
    "objectID": "posts/02_Intro2R_data import and exploration.html#tabular-data-preparation-and-naming-conventions-in-r",
    "href": "posts/02_Intro2R_data import and exploration.html#tabular-data-preparation-and-naming-conventions-in-r",
    "title": "WORKING DIRECTORIES AND DATA IMPORT IN R",
    "section": "Tabular data preparation and naming conventions in R",
    "text": "Tabular data preparation and naming conventions in R\nThere is a set of R packages called tidyverse developed mostly by Hadley Wickham and described in his book R for data science (second edition). We will be using a lot of functions from tidyverse as they are very appropriate for R beginners. To use them to your maximum advantage, you need to get familiar with the concept of a tidy data frame:\n\nOne column is one variable (i.e. gender, height, age),\nOne row is one observation (for all measurements we did on one individual or any other given subject),\nOne field is one value.\n\n\n\n\nTidy dataframe template.\n\n\nIf you structure your dataframes in such a way, it will be efficiently organised and ready to be used when imported, processed and analysed by tidyverse and also base R functions. There are some other basic requirements/recommendations that your data should conform to in order to avoid problems while importing and using it:\n\ndecimal separator in must be a dot!\ncategorical variables should have consistent naming of the groups!\ncolumn names should be without spaces! (connect with underscore _)\ncolumn names must be without symbols! (i.e.: ?, $, *, +, (, ), -, /, }, {, |, &gt;, &lt; , #)\ncolumn names must not start with numbers!\nempty rows should be deleted!\ncomments should be deleted!\nusing č,š,ž,ć,đ is not recommended!\nformat date in the long format! (Day, month, year as: 01/01/2016)"
  },
  {
    "objectID": "posts/02_Intro2R_data import and exploration.html#what-can-be-imported-in-r-how-and-from-where",
    "href": "posts/02_Intro2R_data import and exploration.html#what-can-be-imported-in-r-how-and-from-where",
    "title": "WORKING DIRECTORIES AND DATA IMPORT IN R",
    "section": "What can be imported in R? How and from where?",
    "text": "What can be imported in R? How and from where?\nR supports a variety of file types to be imported, including:\n\ndataframes (saved as comma separated value files - .csv, excel spreadsheets - .xlsx, text files - .txt, google spreadsheets, etc. )\nR format files (.Rdata, .RDS)\ngeospatial data (shape files - .shp, raster files - .ASCII, .img or .tiff)\ndata from databases (i.e. MySQL)\nfiles from web or web databases through specialized packages (i.e. rgbif or sdmpredictors packages; GBIF = Global Biodiverstity Information Facility)\nfiles from other specialized statistical software (i.e. SPSS, STATA, SAS)\n\nFor importing files from the hard drive (most often .txt, .csv and xlsx), there is a specific function that imports specific file type. For example, read.csv() is used to import comma separated values file, read.table() for text files and read_excel() for excel spreadsheets. All this functions have a common argument, we need to specify: file or path which is the location of the document you want to import on our hard-drives. There are two ways we can specify this locations:\n\nfull file path, i.e. C:\\Users\\Matic\\OneDrive - UPR\\01_FAMNIT\\02_VAJE\\2021_22\\201_sodobni pristopi\\2_Importing data and data transfomations\\01_data\\example_data.csv - not recommended.\nfile path without the working directory, i.e. 01_data\\example_data.csv - better, but not optimal.\n\nThe working directory is a default location on the hard-drive, where R “looks” for files. As we usually don’t know which one it is, we use getwd() function with empty brackets to figure it out:\n\ngetwd()\n\nIf we want to change the working directory, we use setwd() function, where we specify the location on our computers hard drive (mandatory in quotations). For example, if I want to set Desktop as working directory for my computer, I would use:\n\nsetwd(\"C:\\Users\\matic.jancic\\Desktop“)\n\n\n\n\n\n\n\nCaution\n\n\n\nEach time we restart RStudio, the working directory will change back to the default. This means that for our code to work and import the data, we would need to re-run setwd() command.\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe preferable and recommended way to avoid potential problems with setting and resetting the working directory each time we come back to RStudio is to use R project workflow.\n\n\nWe need to create a folder on our hard-drive and assign it to an R project. An icon will appear in the folder and starting RStudio from this icon will automatically set the working directory to that particular folder. If we than keep our data, scripts and results in this folder as well, we will save ourselfs from issues associated with working directories. More info about R projects here.\n\n\n\n\n\n\nTask: Create new R project\n\n\n\nClick on File tab in your RStudio, select New project and create new R project on your Desktop called My first R project by following the instructions bellow:\n\n\n\n\n\nNew directory.\n\n\n\n\n\nNew project.\n\n\n\n\n\nMy first R project.\n\n\nGo to the Desktop of your computer and check for the new folder. What is in it?\n\n\n\nR project folder and icon.\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\n\n\nCreate two new folders within My first R project called 01_data and 02_scripts.\nClose R studio and reopen it by using the R project icon called My first R project from the new folder.\nOpen an empty R script (if not already) and use getwd() function to check your current working directory. To what is it set now?"
  },
  {
    "objectID": "posts/02_Intro2R_data import and exploration.html#datasets",
    "href": "posts/02_Intro2R_data import and exploration.html#datasets",
    "title": "WORKING DIRECTORIES AND DATA IMPORT IN R",
    "section": "Datasets",
    "text": "Datasets\n\n\n\n\n\n\nTask: download files\n\n\n\nFrom e-classroom download the files penguins.txt and iris.csv. Copy and paste them into the 01_data folder.\n\n\n\nThe penguins.txt file includes measurements of bill lengths and depths, flipper lengths and body mass for three penguin species, collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network.\nCredit: Horst AM, Hill AP, Gorman KB (2020). palmerpenguins: Palmer Archipelago (Antarctica) penguin data. R package version 0.1.0. https://allisonhorst.github.io/palmerpenguins. doi: 10.5281/zenodo.3960218.\n\nThe iris.csv contains measurements in centimeters of the petal length and width and sepal length and width of three Iris species: Iris virginica, I. versicolor and I. setosa.\n\n\n\nIris species and measurements."
  },
  {
    "objectID": "posts/02_Intro2R_data import and exploration.html#importing-.txt-and-.csv-files-in-r",
    "href": "posts/02_Intro2R_data import and exploration.html#importing-.txt-and-.csv-files-in-r",
    "title": "WORKING DIRECTORIES AND DATA IMPORT IN R",
    "section": "Importing .txt and .csv files in R",
    "text": "Importing .txt and .csv files in R\nFirst we will import penguins.txt file by using read.table() function. As the working directory is set to our project folder, we need to specify the subfolder (01_data/) and the name of the file we want to import. We must also include the file extension, .txt.\nReminders from the previous lab:\n\nthe path name is a character strings and must be contained within parenthesis \" \".\nif we want to use data after applying some function to it, we need to assign it to objects (&lt;-),\nwe are the ones that choose the names of objects (penguins in this case)\n\nTaking into account all of the above, the following code should import the penguins dataset and assign it to the penguins object:\n\npenguins &lt;- read.table(file = \"01_data/penguins.txt\") \n\nThe resulting penguins object should have 344 observations of 8 variables.\n\nLet’s continue with importing .csv file with read.csv() function. As the working directory is set to our project folder, we need to specify the subfolder (01_data/) and the name of the file we want to import. We must also include the file extension, .csv.\nTo import iris.csv and assign it to an object iris use the following code:\n\niris &lt;- read.csv(file = \"01_data/iris.csv\") \n\nThe resulting object should contain 150 observations of 5 variables.\n\nIt is recommended to always check the properties of the imported data, to verify that the import has the same properties as the file on the hard drive. Some of the functions were introduced last time, this time we will add str() and summary().\n\nnrow(iris)\n\n[1] 150\n\nncol(iris)\n\n[1] 5\n\ndim(iris)\n\n[1] 150   5\n\nclass(iris)\n\n[1] \"data.frame\"\n\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal_Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal_Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal_Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal_Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : chr  \"setosa\" \"setosa\" \"setosa\" \"setosa\" ...\n\nsummary(iris)\n\n  Sepal_Length    Sepal_Width     Petal_Length    Petal_Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n   Species         \n Length:150        \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\n\n\n\n\n\n\nTask\n\n\n\nUse all of the functions above on the penguins object."
  },
  {
    "objectID": "posts/02_Intro2R_data import and exploration.html#common-issueserrors-and-how-to-resolve-them",
    "href": "posts/02_Intro2R_data import and exploration.html#common-issueserrors-and-how-to-resolve-them",
    "title": "WORKING DIRECTORIES AND DATA IMPORT IN R",
    "section": "Common issues/errors and how to resolve them",
    "text": "Common issues/errors and how to resolve them\n\nWith the location of and path to the file\nThe most common error you will encounter with both functions, especially at the beginning, is the following:\n\n\nError in file(file, \"rt\"): cannot open the connection\n\n\n\n\n\n\n\n\nTask\n\n\n\nRun the following code. Why does it not work?\n\n\n\niris &lt;- read.table(file = \"01_data/iris.txt\") \n\niris &lt;- read.csv(file = \"iris.csv\") \n\niris &lt;- read.csv(\"01_data/iriis.csv\")\n\nThis error means that the path to the file is not specified correctly. In plain terms, R is looking for the file which\n\nis not in the folder you specified,\ndoes not have a name you specified, or\nis not in a format you specified.\n\n\n\n\n\n\n\nSolution\n\n\n\nDouble check the working directory, the folder where the data is stored, the name of the file and its extension:\n\n\n\n\nWith the number of rows and/or columns differs between original file and the created object\nSometimes the first row of the file, which includes column names, is treated as data when imported. When this happens, the columns will be named as V1, V2, etc. until the last column while the actual column names will be in the first row of the data, as can be seen below:\n\n\n            V1          V2           V3          V4      V5\n1 Sepal_Length Sepal_Width Petal_Length Petal_Width Species\n2          5.1         3.5          1.4         0.2  setosa\n3          4.9           3          1.4         0.2  setosa\n4          4.7         3.2          1.3         0.2  setosa\n5          4.6         3.1          1.5         0.2  setosa\n6            5         3.6          1.4         0.2  setosa\n\n\n\n\n\n\n\n\nSolution\n\n\n\nWithin the read.csv() or read.table() include additional argument header = TRUE. This will tell R that the first row includes column names:\nread.csv(..., header = TRUE) or read.table(..., header = TRUE).\n\n\nSometimes the imported data will have only one column. When this happens the symbol that separates the values in rows was not the one R was expecting it to be, as can be seen below:\n\n\n  Sepal_Length.Sepal_Width.Petal_Length.Petal_Width.Species\n1                                    5.1,3.5,1.4,0.2,setosa\n2                                      4.9,3,1.4,0.2,setosa\n3                                    4.7,3.2,1.3,0.2,setosa\n4                                    4.6,3.1,1.5,0.2,setosa\n5                                      5,3.6,1.4,0.2,setosa\n6                                    5.4,3.9,1.7,0.4,setosa\n\n\n\n\n\n\n\n\nSolution\n\n\n\nWe determine the symbol that separates the values from the output and set it within the read.csv() or read.table(). In this example, the separator is comma - ,, which we set with the argument sep = \",\":\nread.csv(..., sep = \",\") or read.table(..., sep = \",\").\nAnother very common separator you will encounter in the .csv files is a semicolon - ;, while in the .txt tab \\t is commonly used by program encoding. Note that the separator is included within quotations!"
  },
  {
    "objectID": "posts/02_Intro2R_data import and exploration.html#exercise",
    "href": "posts/02_Intro2R_data import and exploration.html#exercise",
    "title": "WORKING DIRECTORIES AND DATA IMPORT IN R",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\nTask\n\n\n\nRead the instructions carefully. If you don’t understand something or something doesn’t work straight away, first think about the problem/error, consult the materials in front of, the neighbor on your left, then on your right. If after all that you still don’t know how to fix the problem or proceed, than ask me for help!\n1.1) Open an empty excel file. By following the tidy data frame concepts and basic requirements the data should conform to, create a random dataset. You can be creative and type in the excel whatever pops on your mind, but at minimum make two columns with numbers and two columns with names/categories for 10 observations.\n1.2) When done, go to File tab and choose Save as and select where you want the file to be saved. In the pop-up window, choose a name for your file than click on the dropdown menu next to the Save as type and choose CSV (Comma delimited).\n1.3) Import this file into R and explore if it was imported correctly.\n\n2.1) Find one dataset in either .csv or .txt format online.\n2.2) Download it, import it into R and assign it to an object with meaningful name.\n2.3) Check if it was imported correctly, i.e. that it contains the same number of rows and observations as the file on your hardrive. If not, check if you encountered one of the most common errors, that are listed above.\n\n\nSave the script with all you commands"
  },
  {
    "objectID": "posts/02_Intro2R_data import and exploration.html#exercise-until-the-end-of-the-lab-if-not-completed-homework",
    "href": "posts/02_Intro2R_data import and exploration.html#exercise-until-the-end-of-the-lab-if-not-completed-homework",
    "title": "WORKING DIRECTORIES AND DATA IMPORT IN R",
    "section": "Exercise until the end of the lab, if not completed homework",
    "text": "Exercise until the end of the lab, if not completed homework\nADD DATACAMP HOMEWORK …\n\nFor those strugling to find the .csv or .txt datasets online: link."
  },
  {
    "objectID": "posts/02_Intro2R_data import and exploration.html#exercise-until-the-end-of-the-lab-or-homework-if-not-completed",
    "href": "posts/02_Intro2R_data import and exploration.html#exercise-until-the-end-of-the-lab-or-homework-if-not-completed",
    "title": "WORKING DIRECTORIES AND DATA IMPORT IN R",
    "section": "Exercise until the end of the lab or homework, if not completed",
    "text": "Exercise until the end of the lab or homework, if not completed\n\n\n\nDatacamp assignment: data import.\n\n\n\nFor those strugling to find the .csv or .txt datasets online: link."
  },
  {
    "objectID": "posts/01_INTRODUCTION TO R & R STUDIO.html#task",
    "href": "posts/01_INTRODUCTION TO R & R STUDIO.html#task",
    "title": "INTRODUCTION TO R & R STUDIO",
    "section": "Task",
    "text": "Task\nOpen an empty R script from the File dropdown menu by clicking New file \\ R script. The script will have a name Untitled1 (or Untitled2, if a blank script was already open).\nSave the script to the Desktop of your computer and name it Introduction to R."
  },
  {
    "objectID": "posts/03_Intro2R_selecting, filtering_and_creating_new_variables.html#import-iris-dataset",
    "href": "posts/03_Intro2R_selecting, filtering_and_creating_new_variables.html#import-iris-dataset",
    "title": "SELECTING, FILTERING AND CREATING NEW VARIABLES IN R",
    "section": "Import iris dataset",
    "text": "Import iris dataset\n\n\n\n\n\n\nTask\n\n\n\nStart the RStudio from the R project icon that you created in the previous lab!\n\n\nTo be sure that the working directory is set to your project folder, use the get getwd() function. The result should end with .../My first R project (if you followed instructions in the second lab).\n\ngetwd()\n\nImport the dataset, assign it to an object called iris and inspect that it was loaded correctly:\n\niris &lt;- read.csv(file = \"01_data/iris.csv\") \n\nhead(iris)\n\n  Sepal_Length Sepal_Width Petal_Length Petal_Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal_Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal_Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal_Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal_Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : chr  \"setosa\" \"setosa\" \"setosa\" \"setosa\" ..."
  },
  {
    "objectID": "posts/03_Intro2R_selecting, filtering_and_creating_new_variables.html#selecting-and-filtering-dataframes",
    "href": "posts/03_Intro2R_selecting, filtering_and_creating_new_variables.html#selecting-and-filtering-dataframes",
    "title": "SELECTING, FILTERING AND CREATING NEW VARIABLES IN R",
    "section": "Selecting and filtering dataframes",
    "text": "Selecting and filtering dataframes\nEverything in R can be done in multiple ways. We will look at how to filter and select parts of the data, how to create new variables and how to export our data. All of these are commonly used approaches, that you will use in the following exercises and also other classes. I will show you how to use base R functions and functions from dplyr package. Note, that there are some other packages and approaches, that can be used, each having its benefits and drawbacks (i.e. data.table package).\n\nBase R\n\n\n\n\n\n\nWhat does base R mean?\n\n\n\nWhen we install R to our computers, we “only” get access to some functionalities that are available within R framework - this is called base R. The reason for this is, that there are so many available “tools/add-ons”, of which individual user doesn’t need a vast majority. Additional functionalities can be added easily and tailored to individual needs.\n\n\nFor selecting a single column from a dataframe using base R we use the $ sign. Before $ sign we write the name of data object we want to select from, after $ sign the name of column we want to select. From the imported data frame, we would like to take only the values of Petal_Length. By doing this, R simply prints the values in the console:\n\niris$Petal_Length\n\n  [1] 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3 1.4\n [19] 1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4 1.5 1.2\n [37] 1.3 1.4 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7 4.5 4.9 4.0\n [55] 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1 4.5 3.9 4.8 4.0\n [73] 4.9 4.7 4.3 4.4 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5 4.5 4.7 4.4 4.1 4.0\n [91] 4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1 5.9 5.6 5.8 6.6 4.5 6.3\n[109] 5.8 6.1 5.1 5.3 5.5 5.0 5.1 5.3 5.5 6.7 6.9 5.0 5.7 4.9 6.7 4.9 5.7 6.0\n[127] 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9\n[145] 5.7 5.2 5.0 5.2 5.4 5.1\n\n\nAlternative way is to use square brackets - [ , ]. Comma in the brackets separates filtering by rows (left) and columns (right). For column Petal_Length we specify its position in a dataframe.\n\niris[,3]\n\n  [1] 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 1.5 1.6 1.4 1.1 1.2 1.5 1.3 1.4\n [19] 1.7 1.5 1.7 1.5 1.0 1.7 1.9 1.6 1.6 1.5 1.4 1.6 1.6 1.5 1.5 1.4 1.5 1.2\n [37] 1.3 1.4 1.3 1.5 1.3 1.3 1.3 1.6 1.9 1.4 1.6 1.4 1.5 1.4 4.7 4.5 4.9 4.0\n [55] 4.6 4.5 4.7 3.3 4.6 3.9 3.5 4.2 4.0 4.7 3.6 4.4 4.5 4.1 4.5 3.9 4.8 4.0\n [73] 4.9 4.7 4.3 4.4 4.8 5.0 4.5 3.5 3.8 3.7 3.9 5.1 4.5 4.5 4.7 4.4 4.1 4.0\n [91] 4.4 4.6 4.0 3.3 4.2 4.2 4.2 4.3 3.0 4.1 6.0 5.1 5.9 5.6 5.8 6.6 4.5 6.3\n[109] 5.8 6.1 5.1 5.3 5.5 5.0 5.1 5.3 5.5 6.7 6.9 5.0 5.7 4.9 6.7 4.9 5.7 6.0\n[127] 4.8 4.9 5.6 5.8 6.1 6.4 5.6 5.1 5.6 6.1 5.6 5.5 4.8 5.4 5.6 5.1 5.1 5.9\n[145] 5.7 5.2 5.0 5.2 5.4 5.1\n\n\n\n\n\n\n\n\nWarning\n\n\n\nIf for filtering we use the number of column, the results might change if the input data changes! In case you change your .csv file on the hard-drive, and the third column now contains another variable, R will take the third column and not column with Petal_Length, as it doesn’t care for the changes you made and you might not notice that. However, this can (will) have effect on the subsequent analysis, if it depends on this particular filtering operation.\n\n\n\nTo filter out specific values of one column using base R we use square brackets - [ , ] and specify a column with the $ and an expression for filtering. All of this must be on the left side of the comma! For example, if we would like to filter out all rows with Petal_width smaller than 0.2 cm:\n\niris[iris$Petal_Width &lt; 0.2,] \n\n   Sepal_Length Sepal_Width Petal_Length Petal_Width Species\n10          4.9         3.1          1.5         0.1  setosa\n13          4.8         3.0          1.4         0.1  setosa\n14          4.3         3.0          1.1         0.1  setosa\n33          5.2         4.1          1.5         0.1  setosa\n38          4.9         3.6          1.4         0.1  setosa\n\n\nWe can also combine two conditions for filtering (AND or OR). For two conditions to apply at the same time we use AND operator - &:\n\niris[iris$Petal_Width &lt; 0.2 & iris$Sepal_Length &gt; 4.8,] \n\n   Sepal_Length Sepal_Width Petal_Length Petal_Width Species\n10          4.9         3.1          1.5         0.1  setosa\n33          5.2         4.1          1.5         0.1  setosa\n38          4.9         3.6          1.4         0.1  setosa\n\n\nTo apply one OR the other condition, we use OR operator |:\n\niris[iris$Petal_Width &lt; 0.2 | iris$Sepal_Length &gt; 7.6, ] \n\n    Sepal_Length Sepal_Width Petal_Length Petal_Width   Species\n10           4.9         3.1          1.5         0.1    setosa\n13           4.8         3.0          1.4         0.1    setosa\n14           4.3         3.0          1.1         0.1    setosa\n33           5.2         4.1          1.5         0.1    setosa\n38           4.9         3.6          1.4         0.1    setosa\n118          7.7         3.8          6.7         2.2 virginica\n119          7.7         2.6          6.9         2.3 virginica\n123          7.7         2.8          6.7         2.0 virginica\n132          7.9         3.8          6.4         2.0 virginica\n136          7.7         3.0          6.1         2.3 virginica\n\n\nIn both cases, the whole expression must be written on the left side of the comma  to work.\nSometimes we want to filter based on a specific word. In our case, maybe only one of the three species. We use double equal sign and write the word precisely as it is in our dataframe, included within the quotes. With the $ we tell R in which column it should look for the word:\n\niris[iris$Species == \"virginica\",]\n\n    Sepal_Length Sepal_Width Petal_Length Petal_Width   Species\n101          6.3         3.3          6.0         2.5 virginica\n102          5.8         2.7          5.1         1.9 virginica\n103          7.1         3.0          5.9         2.1 virginica\n104          6.3         2.9          5.6         1.8 virginica\n105          6.5         3.0          5.8         2.2 virginica\n106          7.6         3.0          6.6         2.1 virginica\n107          4.9         2.5          4.5         1.7 virginica\n108          7.3         2.9          6.3         1.8 virginica\n109          6.7         2.5          5.8         1.8 virginica\n110          7.2         3.6          6.1         2.5 virginica\n111          6.5         3.2          5.1         2.0 virginica\n112          6.4         2.7          5.3         1.9 virginica\n113          6.8         3.0          5.5         2.1 virginica\n114          5.7         2.5          5.0         2.0 virginica\n115          5.8         2.8          5.1         2.4 virginica\n116          6.4         3.2          5.3         2.3 virginica\n117          6.5         3.0          5.5         1.8 virginica\n118          7.7         3.8          6.7         2.2 virginica\n119          7.7         2.6          6.9         2.3 virginica\n120          6.0         2.2          5.0         1.5 virginica\n121          6.9         3.2          5.7         2.3 virginica\n122          5.6         2.8          4.9         2.0 virginica\n123          7.7         2.8          6.7         2.0 virginica\n124          6.3         2.7          4.9         1.8 virginica\n125          6.7         3.3          5.7         2.1 virginica\n126          7.2         3.2          6.0         1.8 virginica\n127          6.2         2.8          4.8         1.8 virginica\n128          6.1         3.0          4.9         1.8 virginica\n129          6.4         2.8          5.6         2.1 virginica\n130          7.2         3.0          5.8         1.6 virginica\n131          7.4         2.8          6.1         1.9 virginica\n132          7.9         3.8          6.4         2.0 virginica\n133          6.4         2.8          5.6         2.2 virginica\n134          6.3         2.8          5.1         1.5 virginica\n135          6.1         2.6          5.6         1.4 virginica\n136          7.7         3.0          6.1         2.3 virginica\n137          6.3         3.4          5.6         2.4 virginica\n138          6.4         3.1          5.5         1.8 virginica\n139          6.0         3.0          4.8         1.8 virginica\n140          6.9         3.1          5.4         2.1 virginica\n141          6.7         3.1          5.6         2.4 virginica\n142          6.9         3.1          5.1         2.3 virginica\n143          5.8         2.7          5.1         1.9 virginica\n144          6.8         3.2          5.9         2.3 virginica\n145          6.7         3.3          5.7         2.5 virginica\n146          6.7         3.0          5.2         2.3 virginica\n147          6.3         2.5          5.0         1.9 virginica\n148          6.5         3.0          5.2         2.0 virginica\n149          6.2         3.4          5.4         2.3 virginica\n150          5.9         3.0          5.1         1.8 virginica\n\n\n\n\n\nDplyr R package\nOne alternative to do all of the above is to use dplyr package, which is more intuitive to use. It cannot be applied to all data types, but works perfectly with the tidy data frames. It does not come with the base R, so we need to install and load it.\nIn R, we install a package using install.packages() function with the name of the package in quotation marks within the parenthesis. This (should) automatically download and install the package. We need to load the package each time that we start or restart R or RStudio. This is done with library() function with the name of package without quotation marks in the parenthesis. Each package comes with a document in which all important information are available, example for dplyr can be accessed here. More popular packages usually have informative “cheat sheets” as well (here).\n\n\n\n\n\n\nPackages\n\n\n\nTo add new functionalities to base R, we need to install R packages from the internet (imagine R package as an add-on or extension of the base installation). Installation needs to be done only once, before the first use of the package!\nHowever, installing the package does not make it available for use. Again, not all packages are needed all the time so we have to load the package each time we restart R or RStudio to be able to use it!\n\n\n\ninstall.packages(\"dplyr\")\n\n\nlibrary(dplyr)\n\n\n\n\n\n\n\nTip\n\n\n\nIf you encounter the following error: Error in ... : could not find function \"...\", the most likely reason is that you have not run the library function, to make the package available within your current R session!\n\n\nFor selecting a single column from a dataframe we use select() function which takes two arguments: the name of data object we want to select from and the name of column we want to select. With select() function we can choose multiple columns and also rename them inside a single command. Same example as above, taking only the values of Petal_Length from iris:\n\nselect(iris, Petal_Length)\n\n    Petal_Length\n1            1.4\n2            1.4\n3            1.3\n4            1.5\n5            1.4\n6            1.7\n7            1.4\n8            1.5\n9            1.4\n10           1.5\n11           1.5\n12           1.6\n13           1.4\n14           1.1\n15           1.2\n16           1.5\n17           1.3\n18           1.4\n19           1.7\n20           1.5\n21           1.7\n22           1.5\n23           1.0\n24           1.7\n25           1.9\n26           1.6\n27           1.6\n28           1.5\n29           1.4\n30           1.6\n31           1.6\n32           1.5\n33           1.5\n34           1.4\n35           1.5\n36           1.2\n37           1.3\n38           1.4\n39           1.3\n40           1.5\n41           1.3\n42           1.3\n43           1.3\n44           1.6\n45           1.9\n46           1.4\n47           1.6\n48           1.4\n49           1.5\n50           1.4\n51           4.7\n52           4.5\n53           4.9\n54           4.0\n55           4.6\n56           4.5\n57           4.7\n58           3.3\n59           4.6\n60           3.9\n61           3.5\n62           4.2\n63           4.0\n64           4.7\n65           3.6\n66           4.4\n67           4.5\n68           4.1\n69           4.5\n70           3.9\n71           4.8\n72           4.0\n73           4.9\n74           4.7\n75           4.3\n76           4.4\n77           4.8\n78           5.0\n79           4.5\n80           3.5\n81           3.8\n82           3.7\n83           3.9\n84           5.1\n85           4.5\n86           4.5\n87           4.7\n88           4.4\n89           4.1\n90           4.0\n91           4.4\n92           4.6\n93           4.0\n94           3.3\n95           4.2\n96           4.2\n97           4.2\n98           4.3\n99           3.0\n100          4.1\n101          6.0\n102          5.1\n103          5.9\n104          5.6\n105          5.8\n106          6.6\n107          4.5\n108          6.3\n109          5.8\n110          6.1\n111          5.1\n112          5.3\n113          5.5\n114          5.0\n115          5.1\n116          5.3\n117          5.5\n118          6.7\n119          6.9\n120          5.0\n121          5.7\n122          4.9\n123          6.7\n124          4.9\n125          5.7\n126          6.0\n127          4.8\n128          4.9\n129          5.6\n130          5.8\n131          6.1\n132          6.4\n133          5.6\n134          5.1\n135          5.6\n136          6.1\n137          5.6\n138          5.5\n139          4.8\n140          5.4\n141          5.6\n142          5.1\n143          5.1\n144          5.9\n145          5.7\n146          5.2\n147          5.0\n148          5.2\n149          5.4\n150          5.1\n\n\nFor filtering by row values we use filter() function which also takes two arguments: the name of data object we want to select from and the expression based on which we want to filter. Same example as above:\n\nfilter(iris, Petal_Width &lt; 0.2)\n\n  Sepal_Length Sepal_Width Petal_Length Petal_Width Species\n1          4.9         3.1          1.5         0.1  setosa\n2          4.8         3.0          1.4         0.1  setosa\n3          4.3         3.0          1.1         0.1  setosa\n4          5.2         4.1          1.5         0.1  setosa\n5          4.9         3.6          1.4         0.1  setosa\n\n\nAnd combine two conditions within the select, same examples as above:\n\nfilter(iris, Petal_Width &lt; 0.2 & Sepal_Length &gt; 4.8)\n\n  Sepal_Length Sepal_Width Petal_Length Petal_Width Species\n1          4.9         3.1          1.5         0.1  setosa\n2          5.2         4.1          1.5         0.1  setosa\n3          4.9         3.6          1.4         0.1  setosa\n\n\n\nfilter(iris, Petal_Width &lt; 0.2 | Sepal_Length &gt; 7.6)\n\n   Sepal_Length Sepal_Width Petal_Length Petal_Width   Species\n1           4.9         3.1          1.5         0.1    setosa\n2           4.8         3.0          1.4         0.1    setosa\n3           4.3         3.0          1.1         0.1    setosa\n4           5.2         4.1          1.5         0.1    setosa\n5           4.9         3.6          1.4         0.1    setosa\n6           7.7         3.8          6.7         2.2 virginica\n7           7.7         2.6          6.9         2.3 virginica\n8           7.7         2.8          6.7         2.0 virginica\n9           7.9         3.8          6.4         2.0 virginica\n10          7.7         3.0          6.1         2.3 virginica\n\n\nNext, filtering by word, same example:\n\nfilter(iris, Species == \"virginica\")\n\n   Sepal_Length Sepal_Width Petal_Length Petal_Width   Species\n1           6.3         3.3          6.0         2.5 virginica\n2           5.8         2.7          5.1         1.9 virginica\n3           7.1         3.0          5.9         2.1 virginica\n4           6.3         2.9          5.6         1.8 virginica\n5           6.5         3.0          5.8         2.2 virginica\n6           7.6         3.0          6.6         2.1 virginica\n7           4.9         2.5          4.5         1.7 virginica\n8           7.3         2.9          6.3         1.8 virginica\n9           6.7         2.5          5.8         1.8 virginica\n10          7.2         3.6          6.1         2.5 virginica\n11          6.5         3.2          5.1         2.0 virginica\n12          6.4         2.7          5.3         1.9 virginica\n13          6.8         3.0          5.5         2.1 virginica\n14          5.7         2.5          5.0         2.0 virginica\n15          5.8         2.8          5.1         2.4 virginica\n16          6.4         3.2          5.3         2.3 virginica\n17          6.5         3.0          5.5         1.8 virginica\n18          7.7         3.8          6.7         2.2 virginica\n19          7.7         2.6          6.9         2.3 virginica\n20          6.0         2.2          5.0         1.5 virginica\n21          6.9         3.2          5.7         2.3 virginica\n22          5.6         2.8          4.9         2.0 virginica\n23          7.7         2.8          6.7         2.0 virginica\n24          6.3         2.7          4.9         1.8 virginica\n25          6.7         3.3          5.7         2.1 virginica\n26          7.2         3.2          6.0         1.8 virginica\n27          6.2         2.8          4.8         1.8 virginica\n28          6.1         3.0          4.9         1.8 virginica\n29          6.4         2.8          5.6         2.1 virginica\n30          7.2         3.0          5.8         1.6 virginica\n31          7.4         2.8          6.1         1.9 virginica\n32          7.9         3.8          6.4         2.0 virginica\n33          6.4         2.8          5.6         2.2 virginica\n34          6.3         2.8          5.1         1.5 virginica\n35          6.1         2.6          5.6         1.4 virginica\n36          7.7         3.0          6.1         2.3 virginica\n37          6.3         3.4          5.6         2.4 virginica\n38          6.4         3.1          5.5         1.8 virginica\n39          6.0         3.0          4.8         1.8 virginica\n40          6.9         3.1          5.4         2.1 virginica\n41          6.7         3.1          5.6         2.4 virginica\n42          6.9         3.1          5.1         2.3 virginica\n43          5.8         2.7          5.1         1.9 virginica\n44          6.8         3.2          5.9         2.3 virginica\n45          6.7         3.3          5.7         2.5 virginica\n46          6.7         3.0          5.2         2.3 virginica\n47          6.3         2.5          5.0         1.9 virginica\n48          6.5         3.0          5.2         2.0 virginica\n49          6.2         3.4          5.4         2.3 virginica\n50          5.9         3.0          5.1         1.8 virginica\n\n\n\n\n\n\n\n\nQuestions to consider\n\n\n\n\nDid you notice any difference between outputs after using the same operations in base R and dplyr?\nWhat is an R package? How do you access and use its functionalities?"
  },
  {
    "objectID": "posts/03_Intro2R_selecting, filtering_and_creating_new_variables.html#creating-new-variables-in-r",
    "href": "posts/03_Intro2R_selecting, filtering_and_creating_new_variables.html#creating-new-variables-in-r",
    "title": "SELECTING, FILTERING AND CREATING NEW VARIABLES IN R",
    "section": "Creating new variables in R",
    "text": "Creating new variables in R\nWith the $ we can also create and assign new variables to our data frame. Before the assign operator we specify the name of the new variable (must not be the same as existing column names, otherwise it will overwrite one existing column). After the assign operator we specify what we want to be stored in this new variable. For example, we can calculate the ratio between Sepal_Length and Sepal_Width. R will go from row to row, calculate the ratio and store it in the same row of the new column:\n\niris$ratio &lt;- iris$Sepal_Length / iris$Sepal_Width\n\nnames(iris)\n\n[1] \"Sepal_Length\" \"Sepal_Width\"  \"Petal_Length\" \"Petal_Width\"  \"Species\"     \n[6] \"ratio\"       \n\nstr(iris)\n\n'data.frame':   150 obs. of  6 variables:\n $ Sepal_Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal_Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal_Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal_Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : chr  \"setosa\" \"setosa\" \"setosa\" \"setosa\" ...\n $ ratio       : num  1.46 1.63 1.47 1.48 1.39 ...\n\n\nFor creating new variables, we use mutate() function which also takes two arguments: the name of data object we want to select from and the name of the new variable followed by the expression, based on which the variable will be created. Same example as above, just choosing a different column name:\n\niris &lt;- mutate(iris, ratio2 = Sepal_Length / Sepal_Width)\n\nnames(iris)\n\n[1] \"Sepal_Length\" \"Sepal_Width\"  \"Petal_Length\" \"Petal_Width\"  \"Species\"     \n[6] \"ratio\"        \"ratio2\"      \n\nstr(iris)      \n\n'data.frame':   150 obs. of  7 variables:\n $ Sepal_Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal_Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal_Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal_Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : chr  \"setosa\" \"setosa\" \"setosa\" \"setosa\" ...\n $ ratio       : num  1.46 1.63 1.47 1.48 1.39 ...\n $ ratio2      : num  1.46 1.63 1.47 1.48 1.39 ..."
  },
  {
    "objectID": "posts/03_Intro2R_selecting, filtering_and_creating_new_variables.html#exporting-datasets",
    "href": "posts/03_Intro2R_selecting, filtering_and_creating_new_variables.html#exporting-datasets",
    "title": "SELECTING, FILTERING AND CREATING NEW VARIABLES IN R",
    "section": "Exporting datasets",
    "text": "Exporting datasets\nOpposite to importing files with read functions, we export files with corresponding write functions. For exporting to .csv file, we use write.csv() and for .txt file write.table(). Both have two arguments, first is x, which is the R object we want to export (in our case iris) and the other file, the name of the file that will be created on computers hard drive, in our case “iris_new.csv\". Adding prefix \"01_data/...\" will save it to that particular folder within our working directory.The argument rownames = FALSE will prevent R to add a column with row names, that would contain consecutive numbers starting from 1.\n\nwrite.csv(x = iris, file = \"01_data/iris_new.csv\", row.names = FALSE)\n\nwrite.table(x = iris, file = \"01_data/iris_new.txt\", row.names = FALSE)\n\n\n\n\n\n\n\nTask\n\n\n\nCheck your R project directory on the hard drive, if the two files are indeed there."
  },
  {
    "objectID": "posts/03_Intro2R_selecting, filtering_and_creating_new_variables.html#exercises",
    "href": "posts/03_Intro2R_selecting, filtering_and_creating_new_variables.html#exercises",
    "title": "SELECTING, FILTERING AND CREATING NEW VARIABLES IN R",
    "section": "Exercises",
    "text": "Exercises\n\n\n\n\n\n\nTask\n\n\n\nRead the instructions carefully. If you don’t understand something or something doesn’t work straight away, first think about the problem/error, consult the materials in front of you, than google, than the neighbor on your left and on your right. If after all that you still don’t know how to fix the problem or proceed, than ask me for help!\n\n1.1) Import the penguins dataset and check if the file was correctly imported (344 observations, 8 variables) adjust the code if needed.\n1.2) Inspect the dataset and figure which penguin species are included and on which islands they were monitored in the dataset?\n1.3) Using base R, filter the dataset to contain only penguins with bill_depth_mm less than 17.3.\n1.4) Using base R, filter the dataset to contain only all penguins from Dream island in 2008. Were all three species recorded there that year?\n1.5) Using dplyr, filter the dataset to contain only penguins with flipper_length_mm more than 213.\n1.6) Using dplyr, filter the dataset to contain only penguin female penguins from Biscoe island.\n1.7) Using base R, create a new column in which you calculate the ratio of bill length to bill depth.\n1.8) Using dplyr, create a new column in which body mass will be expressed in kilograms instead of grams (body_mass_g).\n1.9) Export the dataframe with two new columns as a penguins_new.txt file.\n\n2.1) Import the dataset you downloaded from the internet in the previous lab.\n2.2) Using base R and dplyr, perform four sensible filtering and/or selecting operations.\n2.3) In case your data has two or more numerical columns, create one new column using mathematical operation on two other columns of your choice by both base R and dplyr.\n2.4) In case your data has only one column with numerical data, calculate a new column as a square root or squared value of the numerical column.\n2.5) export your dataset with new columns in a format of your choice.\n\n\n\nUntil the end of the class or homework\n\n\n\nDatacamp assignment, Lab 3"
  },
  {
    "objectID": "posts/03_Intro2R_selecting, filtering_and_creating_new_variables.html#mandatory-reading-before-next-class",
    "href": "posts/03_Intro2R_selecting, filtering_and_creating_new_variables.html#mandatory-reading-before-next-class",
    "title": "SELECTING, FILTERING AND CREATING NEW VARIABLES IN R",
    "section": "Mandatory reading before next class",
    "text": "Mandatory reading before next class\n(on e-classroom)\nZuur, Ieno & Elphick, 2010, A protocol for data exploration to avoid common statistical problems"
  },
  {
    "objectID": "posts/02_Intro2R_data_import_and_exploration.html#tabular-data-preparation-and-naming-conventions-in-r",
    "href": "posts/02_Intro2R_data_import_and_exploration.html#tabular-data-preparation-and-naming-conventions-in-r",
    "title": "WORKING DIRECTORIES AND DATA IMPORT IN R",
    "section": "Tabular data preparation and naming conventions in R",
    "text": "Tabular data preparation and naming conventions in R\nThere is a set of R packages called tidyverse developed mostly by Hadley Wickham and described in his book R for data science (second edition). We will be using a lot of functions from tidyverse as they are very appropriate for R beginners. To use them to your maximum advantage, you need to get familiar with the concept of a tidy data frame:\n\nOne column is one variable (i.e. gender, height, age),\nOne row is one observation (for all measurements we did on one individual or any other given subject),\nOne field is one value.\n\n\n\n\nTidy dataframe template.\n\n\nIf you structure your dataframes in such a way, it will be efficiently organised and ready to be used when imported, processed and analysed by tidyverse and also base R functions. There are some other basic requirements/recommendations that your data should conform to in order to avoid problems while importing and using it:\n\ndecimal separator in must be a dot!\ncategorical variables should have consistent naming of the groups!\ncolumn names should be without spaces! (connect with underscore _)\ncolumn names must be without symbols! (i.e.: ?, $, *, +, (, ), -, /, }, {, |, &gt;, &lt; , #)\ncolumn names must not start with numbers!\nempty rows should be deleted!\ncomments should be deleted!\nusing č,š,ž,ć,đ is not recommended!\nformat date in the long format! (Day, month, year as: 01/01/2016)"
  },
  {
    "objectID": "posts/02_Intro2R_data_import_and_exploration.html#what-can-be-imported-in-r-how-and-from-where",
    "href": "posts/02_Intro2R_data_import_and_exploration.html#what-can-be-imported-in-r-how-and-from-where",
    "title": "WORKING DIRECTORIES AND DATA IMPORT IN R",
    "section": "What can be imported in R? How and from where?",
    "text": "What can be imported in R? How and from where?\nR supports a variety of file types to be imported, including:\n\ndataframes (saved as comma separated value files - .csv, excel spreadsheets - .xlsx, text files - .txt, google spreadsheets, etc. )\nR format files (.Rdata, .RDS)\ngeospatial data (shape files - .shp, raster files - .ASCII, .img or .tiff)\ndata from databases (i.e. MySQL)\nfiles from web or web databases through specialized packages (i.e. rgbif or sdmpredictors packages; GBIF = Global Biodiverstity Information Facility)\nfiles from other specialized statistical software (i.e. SPSS, STATA, SAS)\n\nFor importing files from the hard drive (most often .txt, .csv and xlsx), there is a specific function that imports specific file type. For example, read.csv() is used to import comma separated values file, read.table() for text files and read_excel() for excel spreadsheets. All this functions have a common argument, we need to specify: file or path which is the location of the document you want to import on our hard-drives. There are two ways we can specify this locations:\n\nfull file path, i.e. C:\\Users\\Matic\\OneDrive - UPR\\01_FAMNIT\\02_VAJE\\2021_22\\201_sodobni pristopi\\2_Importing data and data transfomations\\01_data\\example_data.csv - not recommended.\nfile path without the working directory, i.e. 01_data\\example_data.csv - better, but not optimal.\n\nThe working directory is a default location on the hard-drive, where R “looks” for files. As we usually don’t know which one it is, we use getwd() function with empty brackets to figure it out:\n\ngetwd()\n\nIf we want to change the working directory, we use setwd() function, where we specify the location on our computers hard drive (mandatory in quotations). For example, if I want to set Desktop as working directory for my computer, I would use:\n\nsetwd(\"C:\\Users\\matic.jancic\\Desktop“)\n\n\n\n\n\n\n\nCaution\n\n\n\nEach time we restart RStudio, the working directory will change back to the default. This means that for our code to work and import the data, we would need to re-run setwd() command.\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe preferable and recommended way to avoid potential problems with setting and resetting the working directory each time we come back to RStudio is to use R project workflow.\n\n\nWe need to create a folder on our hard-drive and assign it to an R project. An icon will appear in the folder and starting RStudio from this icon will automatically set the working directory to that particular folder. If we than keep our data, scripts and results in this folder as well, we will save ourselfs from issues associated with working directories. More info about R projects here.\n\n\n\n\n\n\nTask: Create new R project\n\n\n\nClick on File tab in your RStudio, select New project and create new R project on your Desktop called My first R project by following the instructions bellow:\n\n\n\n\n\nNew directory.\n\n\n\n\n\nNew project.\n\n\n\n\n\nMy first R project.\n\n\nGo to the Desktop of your computer and check for the new folder. What is in it?\n\n\n\nR project folder and icon.\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\n\n\nCreate two new folders within My first R project called 01_data and 02_scripts.\nClose R studio and reopen it by using the R project icon called My first R project from the new folder.\nOpen an empty R script (if not already) and use getwd() function to check your current working directory. To what is it set now?"
  },
  {
    "objectID": "posts/02_Intro2R_data_import_and_exploration.html#datasets",
    "href": "posts/02_Intro2R_data_import_and_exploration.html#datasets",
    "title": "WORKING DIRECTORIES AND DATA IMPORT IN R",
    "section": "Datasets",
    "text": "Datasets\n\n\n\n\n\n\nTask: download files\n\n\n\nFrom e-classroom download the files penguins.txt and iris.csv. Copy and paste them into the 01_data folder.\n\n\n\nThe penguins.txt file includes measurements of bill lengths and depths, flipper lengths and body mass for three penguin species, collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network.\nCredit: Horst AM, Hill AP, Gorman KB (2020). palmerpenguins: Palmer Archipelago (Antarctica) penguin data. R package version 0.1.0. https://allisonhorst.github.io/palmerpenguins. doi: 10.5281/zenodo.3960218.\n\nThe iris.csv contains measurements in centimeters of the petal length and width and sepal length and width of three Iris species: Iris virginica, I. versicolor and I. setosa.\n\n\n\nIris species and measurements."
  },
  {
    "objectID": "posts/02_Intro2R_data_import_and_exploration.html#importing-.txt-and-.csv-files-in-r",
    "href": "posts/02_Intro2R_data_import_and_exploration.html#importing-.txt-and-.csv-files-in-r",
    "title": "WORKING DIRECTORIES AND DATA IMPORT IN R",
    "section": "Importing .txt and .csv files in R",
    "text": "Importing .txt and .csv files in R\nFirst we will import penguins.txt file by using read.table() function. As the working directory is set to our project folder, we need to specify the subfolder (01_data/) and the name of the file we want to import. We must also include the file extension, .txt.\nReminders from the previous lab:\n\nthe path name is a character strings and must be contained within parenthesis \" \".\nif we want to use data after applying some function to it, we need to assign it to objects (&lt;-),\nwe are the ones that choose the names of objects (penguins in this case)\n\nTaking into account all of the above, the following code should import the penguins dataset and assign it to the penguins object:\n\npenguins &lt;- read.table(file = \"01_data/penguins.txt\") \n\nThe resulting penguins object should have 344 observations of 8 variables.\n\nLet’s continue with importing .csv file with read.csv() function. As the working directory is set to our project folder, we need to specify the subfolder (01_data/) and the name of the file we want to import. We must also include the file extension, .csv.\nTo import iris.csv and assign it to an object iris use the following code:\n\niris &lt;- read.csv(file = \"01_data/iris.csv\") \n\nThe resulting object should contain 150 observations of 5 variables.\n\nIt is recommended to always check the properties of the imported data, to verify that the import has the same properties as the file on the hard drive. Some of the functions were introduced last time, this time we will add str() and summary().\n\nnrow(iris)\n\n[1] 150\n\nncol(iris)\n\n[1] 5\n\ndim(iris)\n\n[1] 150   5\n\nclass(iris)\n\n[1] \"data.frame\"\n\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal_Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal_Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal_Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal_Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : chr  \"setosa\" \"setosa\" \"setosa\" \"setosa\" ...\n\nsummary(iris)\n\n  Sepal_Length    Sepal_Width     Petal_Length    Petal_Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n   Species         \n Length:150        \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\n\n\n\n\n\n\n\nTask\n\n\n\nUse all of the functions above on the penguins object."
  },
  {
    "objectID": "posts/02_Intro2R_data_import_and_exploration.html#common-issueserrors-and-how-to-resolve-them",
    "href": "posts/02_Intro2R_data_import_and_exploration.html#common-issueserrors-and-how-to-resolve-them",
    "title": "WORKING DIRECTORIES AND DATA IMPORT IN R",
    "section": "Common issues/errors and how to resolve them",
    "text": "Common issues/errors and how to resolve them\n\nWith the location of and path to the file\nThe most common error you will encounter with both functions, especially at the beginning, is the following:\n\n\nError in file(file, \"rt\"): cannot open the connection\n\n\n\n\n\n\n\n\nTask\n\n\n\nRun the following code. Why does it not work?\n\n\n\niris &lt;- read.table(file = \"01_data/iris.txt\") \n\niris &lt;- read.csv(file = \"iris.csv\") \n\niris &lt;- read.csv(\"01_data/iriis.csv\")\n\nThis error means that the path to the file is not specified correctly. In plain terms, R is looking for the file which\n\nis not in the folder you specified,\ndoes not have a name you specified, or\nis not in a format you specified.\n\n\n\n\n\n\n\nSolution\n\n\n\nDouble check the working directory, the folder where the data is stored, the name of the file and its extension:\n\n\n\n\nWith the number of rows and/or columns differs between original file and the created object\nSometimes the first row of the file, which includes column names, is treated as data when imported. When this happens, the columns will be named as V1, V2, etc. until the last column while the actual column names will be in the first row of the data, as can be seen below:\n\n\n            V1          V2           V3          V4      V5\n1 Sepal_Length Sepal_Width Petal_Length Petal_Width Species\n2          5.1         3.5          1.4         0.2  setosa\n3          4.9           3          1.4         0.2  setosa\n4          4.7         3.2          1.3         0.2  setosa\n5          4.6         3.1          1.5         0.2  setosa\n6            5         3.6          1.4         0.2  setosa\n\n\n\n\n\n\n\n\nSolution\n\n\n\nWithin the read.csv() or read.table() include additional argument header = TRUE. This will tell R that the first row includes column names:\nread.csv(..., header = TRUE) or read.table(..., header = TRUE).\n\n\nSometimes the imported data will have only one column. When this happens the symbol that separates the values in rows was not the one R was expecting it to be, as can be seen below:\n\n\n  Sepal_Length.Sepal_Width.Petal_Length.Petal_Width.Species\n1                                    5.1,3.5,1.4,0.2,setosa\n2                                      4.9,3,1.4,0.2,setosa\n3                                    4.7,3.2,1.3,0.2,setosa\n4                                    4.6,3.1,1.5,0.2,setosa\n5                                      5,3.6,1.4,0.2,setosa\n6                                    5.4,3.9,1.7,0.4,setosa\n\n\n\n\n\n\n\n\nSolution\n\n\n\nWe determine the symbol that separates the values from the output and set it within the read.csv() or read.table(). In this example, the separator is comma - ,, which we set with the argument sep = \",\":\nread.csv(..., sep = \",\") or read.table(..., sep = \",\").\nAnother very common separator you will encounter in the .csv files is a semicolon - ;, while in the .txt tab \\t is commonly used by program encoding. Note that the separator is included within quotations!"
  },
  {
    "objectID": "posts/02_Intro2R_data_import_and_exploration.html#exercise",
    "href": "posts/02_Intro2R_data_import_and_exploration.html#exercise",
    "title": "WORKING DIRECTORIES AND DATA IMPORT IN R",
    "section": "Exercise",
    "text": "Exercise\n\n\n\n\n\n\nTask\n\n\n\nRead the instructions carefully. If you don’t understand something or something doesn’t work straight away, first think about the problem/error, consult the materials in front of, the neighbor on your left, then on your right. If after all that you still don’t know how to fix the problem or proceed, than ask me for help!\n1.1) Open an empty excel file. By following the tidy data frame concepts and basic requirements the data should conform to, create a random dataset. You can be creative and type in the excel whatever pops on your mind, but at minimum make two columns with numbers and two columns with names/categories for 10 observations.\n1.2) When done, go to File tab and choose Save as and select where you want the file to be saved. In the pop-up window, choose a name for your file than click on the dropdown menu next to the Save as type and choose CSV (Comma delimited).\n1.3) Import this file into R and explore if it was imported correctly.\n\n2.1) Find one dataset in either .csv or .txt format online. The dataset should at minimum contain 100 observations (rows), one column with measurements (for example: weight, height, population or number of individuals), and one or two columns that divide the data into groups (for example: year, species, country etc.).\n2.2) Download it, import it into R and assign it to an object with meaningful name.\n2.3) Check if it was imported correctly, i.e. that it contains the same number of rows and observations as the file on your hardrive. If not, check if you encountered one of the most common errors, that are listed above.\n\n\nSave the script with all you commands"
  },
  {
    "objectID": "posts/02_Intro2R_data_import_and_exploration.html#exercise-until-the-end-of-the-lab-or-homework-if-not-completed",
    "href": "posts/02_Intro2R_data_import_and_exploration.html#exercise-until-the-end-of-the-lab-or-homework-if-not-completed",
    "title": "WORKING DIRECTORIES AND DATA IMPORT IN R",
    "section": "Exercise until the end of the lab or homework, if not completed",
    "text": "Exercise until the end of the lab or homework, if not completed\n\n\n\nDatacamp assignment: data import.\n\n\n\nFor those strugling to find the .csv or .txt datasets online: link."
  },
  {
    "objectID": "posts/04_Intro2R_visual_data_exploration.html",
    "href": "posts/04_Intro2R_visual_data_exploration.html",
    "title": "GRAPHICAL DATA EXPLORATION IN R",
    "section": "",
    "text": "Summary\n\n\n\nIn this lab you will learn how to:\n\nexplore data using boxplots, dotchart and scatterplots,\neffectively visualise data for multiple groups,\nmanipulate plot elements and export plots in high quality."
  },
  {
    "objectID": "posts/04_Intro2R_visual_data_exploration.html#why-data-exploration",
    "href": "posts/04_Intro2R_visual_data_exploration.html#why-data-exploration",
    "title": "GRAPHICAL DATA EXPLORATION IN R",
    "section": "Why data exploration?",
    "text": "Why data exploration?\n\n\n\n\n\n\nQuestions to consider\n\n\n\n\nWhy is it recommended and very important to perform data exploration before starting any statistical analysis?\nWhat are the most common issues, that you can encounter in your biological datasets (referring to Zuur et al., 2010)?\n\n\n\n\nAnscombe quartet\nAn example dataset that shows the importance of visual data exploration is the famous Anscombe’s quartet, comprised of four data sets that have nearly identical descriptive statistics, yet are very different. Each dataset consists of eleven (x, y) points that were constructed by the statistician Francis Anscombe to demonstrate both the importance of graphing data before analyzing it and the effect of outliers and other influential observations on statistical properties. The dataset is available as built in dataset (can be loaded by data(anscombe) in a sligthly different format).\n\n\n\n\n\nx1\nx2\nx3\nx4\ny1\ny2\ny3\ny4\n\n\n\n\n10\n10\n10\n8\n8.04\n9.14\n7.46\n6.58\n\n\n8\n8\n8\n8\n6.95\n8.14\n6.77\n5.76\n\n\n13\n13\n13\n8\n7.58\n8.74\n12.74\n7.71\n\n\n9\n9\n9\n8\n8.81\n8.77\n7.11\n8.84\n\n\n11\n11\n11\n8\n8.33\n9.26\n7.81\n8.47\n\n\n14\n14\n14\n8\n9.96\n8.10\n8.84\n7.04\n\n\n6\n6\n6\n8\n7.24\n6.13\n6.08\n5.25\n\n\n4\n4\n4\n19\n4.26\n3.10\n5.39\n12.50\n\n\n12\n12\n12\n8\n10.84\n9.13\n8.15\n5.56\n\n\n7\n7\n7\n8\n4.82\n7.26\n6.42\n7.91\n\n\n5\n5\n5\n8\n5.68\n4.74\n5.73\n6.89\n\n\n\n\n\n\nFirst we will visualize this datasets. As we are looking at the relationship between two numerical variables, we need to use points for representation in 2D space and split the data by the ID of a sample.\n\n\n\n\n\n\n\n\n\n\n\nTask\n\n\n\nHow would you describe the relationship between x and y variable in each dataset? Is the relationships between x & y the same among the datasets?\n\n\nLets look at the summaries of the x and y variables divided by each ID value:\n\nthe mean value and variance of x,\nthe mean value and variance of y and\ncorrelation between x and y.\n\n\n\n\n\n\nID\nmean_x\nvar_x\nmean_y\nvar_y\ncorrelation\n\n\n\n\na\n9\n11\n7.500909\n4.127269\n0.8164205\n\n\nb\n9\n11\n7.500909\n4.127629\n0.8162365\n\n\nc\n9\n11\n7.500000\n4.122620\n0.8162867\n\n\nd\n9\n11\n7.500909\n4.123249\n0.8165214\n\n\n\n\n\nProperties of the four dataset are almost identical, right? The differences start on the third decimal of variance and correlation factor.\nSimilar to the statistical properties of x and y, the results of the linear regression are the same for all 4 datasets:\n\n\n\n\n\n\n\n\n\n\n\nQuestions to consider\n\n\n\n\nIs there an actual linear relationship between x and y? In which dataset?"
  },
  {
    "objectID": "posts/04_Intro2R_visual_data_exploration.html#import-iris-dataset",
    "href": "posts/04_Intro2R_visual_data_exploration.html#import-iris-dataset",
    "title": "GRAPHICAL DATA EXPLORATION IN R",
    "section": "Import iris dataset",
    "text": "Import iris dataset\n\n\n\n\n\n\nTask\n\n\n\nStart the RStudio from the R project icon that you created in the previous lab!\n\n\nTo be sure that the working directory is set to your project folder, use the get getwd() function. The result should end with .../My first R project (if you followed the instructions in the second lab).\n\ngetwd()\n\nImport the dataset, assign it to an object called iris and inspect that it was loaded correctly:\n\niris &lt;- read.csv(file = \"01_data/iris.csv\") \n\nhead(iris)\n\n  Sepal_Length Sepal_Width Petal_Length Petal_Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal_Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal_Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal_Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal_Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : chr  \"setosa\" \"setosa\" \"setosa\" \"setosa\" ...\n\n\nWe will take one additional step in data preparation. In the first lab you were introduced to vector types. If we take a look at the column Species, You will see that it is treated as a character.\n\nclass(iris$Species)\n\n[1] \"character\"\n\n\nSome functions we will use today, require however, the character data to be treated asfactors. The values itself do not change, but R treats them differently. We will thus create a new column (for the sake of demonstration), named Species_f, with f remembering us that this is a factor. The function that will convert values from character to factor isas.factor():\n\niris$Species_f &lt;- as.factor(iris$Species)\n\nhead(iris)\n\n  Sepal_Length Sepal_Width Petal_Length Petal_Width Species Species_f\n1          5.1         3.5          1.4         0.2  setosa    setosa\n2          4.9         3.0          1.4         0.2  setosa    setosa\n3          4.7         3.2          1.3         0.2  setosa    setosa\n4          4.6         3.1          1.5         0.2  setosa    setosa\n5          5.0         3.6          1.4         0.2  setosa    setosa\n6          5.4         3.9          1.7         0.4  setosa    setosa\n\nclass(iris$Species_f)\n\n[1] \"factor\""
  },
  {
    "objectID": "posts/04_Intro2R_visual_data_exploration.html#graphical-data-exploration",
    "href": "posts/04_Intro2R_visual_data_exploration.html#graphical-data-exploration",
    "title": "GRAPHICAL DATA EXPLORATION IN R",
    "section": "Graphical data exploration",
    "text": "Graphical data exploration\n\nBoxplots & dotcharts\nWe will start with visualising iris data. We will take a look at how to create a boxplot and Cleveland dotplot (Zuur, Ieno & Elphich, 2010, Step 1). A boxplot divides data based on its 25th and 75th quantiles (the box), and further on the upper and lower range of 1.5 * Inter Quantile Range (upper and lower whisker) and “outliers” - values that are outside these range (solid dots).\nWe will use package ggplot2 to create and design our boxplots. First we need to install it install.packages(\"ggplot2\") - and than load it to make its functionality available to use - library(ggplot2).\n\ninstall.packages(\"ggplot2\")\nlibrary(ggplot2)\n\nThe basic function to create any plot is ggplot() which contains two arguments we need to define: data and aes(). For data we specify the object in which information for our plot is stored, in our case this will be iris. In aes() argument we can set many different arguments, for us at this point the y and x are important, as with them we specify which column or variable we want to use as y and/or x axis of our plot. The aes() is a shortened version of aesthetics, meaning that with it we define visual characterics of our plots.\nA second function we add to ggplot() is a type of a plot we want to make, in our case this will geom_boxplot(), that initially does not require any arguments and which we add with a + sign.\nFirst we will create a boxplot for all values of Sepal_Length column in iris dataframe. We will define data = iris and aes(y = Sepal_Length) followed by the + sign. We continue in the next row and add geom_boxplot() with empty brackets.\n\nggplot(data = iris, # which data object we will plot\n       # which variable will be displayed on y - axis\n       aes(y = Sepal_Length)) +\n    # what type of a plot we will create\n    geom_boxplot() \n\n\n\n\n\nCleveland dotplot plots the row number of an observation againts the observation value, and provide more detailed information than a boxplot. Points that stick out on the right-hand side, or on the left-hand side, are observed values that are considerably larger, or smaller, than the majority of the observations, and require further investigation.\nCleveland dotplot is a part of base R and it is created by using the dotchart() function. It takes one mandatory argument, the data we want to plot, and two additional arguments, with which we give names to x and y axis (xlab and ylab):\n\ndotchart(iris$Sepal_Length,\n         xlab = \"Sepal length (cm)\", # this is the name of x axis\n         ylab = \"Order of the data\") #this is the name of y axis\n\n\n\n\n\nNext, we know that we have data for three species. So in the next boxplot, we will display data separately for each group. We do this by adding x = Species_f inside aes():\n\nggplot(data = iris, \n       # adding variable that will be displayed on x - axis\n       aes(x = Species_f, y = Sepal_Length)) + \n    geom_boxplot() \n\n\n\n\nFor Cleveland dotplot, we include argument groups = iris$Species_f, to display data separately for the three groups:\n\ndotchart(iris$Sepal_Length,\n         groups = iris$Species_f,\n         xlab = \"Sepal length (cm)\", # this is the name of x axis\n         ylab = \"Order of the data\") #this is the name of y axis\n\n\n\n\n\n\n\n\n\n\nQuestions to consider\n\n\n\nTake a look at the boxplot and dotplot, where data is grouped by species.\n\nCan you observe any patterns?\nWhat about the differences between the three species?\n\n\n\n\n\n\nScatterplots\nWe are often interested in visualising two numerical variables, to inspect if there are any patterns within the data (similar to our introductory Anscombe example). We call this a scatterplot, and we will plot Sepal_Length on the x axis and Sepal_Width on the y axis. The initial call to ggplot stays the same, while this time we use geom_point() to add points to our plot:\n\nggplot(iris, aes(x = Sepal_Length, y = Sepal_Width)) +\n    geom_point()\n\n\n\n\nAs before, we can extend this to incorporate the information about the species. One option is to use the color = argument within the aes() function. This will automatically give each species a predefined color and will display the legend on the side.\n\nggplot(iris, aes(x = Sepal_Length, y = Sepal_Width, color = Species_f)) +\n    geom_point() \n\n\n\n\nIn case that observations are overlapping by a large degree, we can use faceting to divide plots by each species. For this we need to add the facet_wrap() function, where ~ Species_f denotes that species is the variable by which R should divide the data:\n\nggplot(iris, aes(x = Sepal_Length, y = Sepal_Width)) +\n    geom_point() +\n    facet_wrap(~ Species_f)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nBy default, facets have the same values on the x and y axis. The good thing is, that this makes it easy to compare the three groups (species). On the other hand, in each facet, there is a lot of white (empty) space."
  },
  {
    "objectID": "posts/04_Intro2R_visual_data_exploration.html#changing-plot-elements-and-design",
    "href": "posts/04_Intro2R_visual_data_exploration.html#changing-plot-elements-and-design",
    "title": "GRAPHICAL DATA EXPLORATION IN R",
    "section": "Changing plot elements and design",
    "text": "Changing plot elements and design\nWe will continue with just a bit of “polishing” to make plots more suitable for scientific/professional publications (including your masters thesis). We will extend the scatter plot, where the iris species were denoted by color. Remember, to add another commands to ggplots we simply continue the last line with the + sign.\nFirst we will change the annotation of x and y - axis with xlab() and ylab() functions. Inside the brackets we will define the name of the axis - \"Sepal Length (cm)\" and \"Sepal Width (cm)\". Remember that character strings must be included in quotations \"\":\n\nggplot(iris, aes(x = Sepal_Length, \n                 y = Sepal_Width, \n                 color = Species_f)) +\n    geom_point() +\n    ylab(\"Sepal Length (cm)\") +\n    xlab(\"Sepal Width (cm)\")\n\n\n\n\nWe can also change the legend title, which now includes the _f. To do that, we can use labs() function in which we tell R that the name of the variable that we are using to color the points is Species:\n\nggplot(iris, aes(x = Sepal_Length, \n                 y = Sepal_Width, \n                 color = Species_f)) +\n    geom_point() +\n    ylab(\"Sepal Length (cm)\")+\n    xlab(\"Sepal Width (cm)\") +\n    labs(color = \"Species\")\n\n\n\n\nThe last thing we will change today will be the design of plot elements. We can do that manually, but there are already several themes prepared (including some specific R packages, such as ggthemes - more info here or here. To us, theme_bw() and theme_classic() are of interest.\nWe use the same commands to create the boxplot, we add the + sign, continue in the next row and add theme_bw() with empty brackets.\n\nggplot(iris, aes(x = Sepal_Length, \n                 y = Sepal_Width, \n                 color = Species_f)) +\n    geom_point() +\n    ylab(\"Sepal Length (cm)\")+\n    xlab(\"Sepal Width (cm)\") +\n    labs(color = \"Species\") +\n    theme_bw()\n\n\n\n\nWe repeat the process, but this time add theme_classic() with empty brackets.\n\nggplot(iris, aes(x = Sepal_Length, \n                 y = Sepal_Width, \n                 color = Species_f)) +\n    geom_point() +\n    ylab(\"Sepal Length (cm)\")+\n    xlab(\"Sepal Width (cm)\") +\n    labs(color = \"Species\") +\n    theme_classic() \n\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\nAre there any other things you would like to modify (for example change the size of the points)?\nIf you have any suggestions, we can try to add them before exporting the plot!\n\n\n\nLets also take a look at how we can export this boxplot in high resolution print quality. First we save our plot to an object, lets call it plot_to_export. Then, we install, if needed, and load the ggpubr package, from which we use ggexport function. Within it, we will define 4 arguments:filename =, width =, height and res, which is an abbreviation for resolution (300 is a minimum requirement for quality print):\n\nplot_to_export &lt;- \n    ggplot(iris, aes(x = Sepal_Length, \n                     y = Sepal_Width, \n                     color = Species_f)) +\n        geom_point() +\n        ylab(\"Sepal Length (cm)\")+\n        xlab(\"Sepal Width (cm)\") +\n        labs(color = \"Species\") +\n        theme_classic()\n\n# load required package\ninstall.packages(\"ggpubr\")\nlibrary(ggpubr)\n\n# we need to set width, height and res manually, \n# usually change the numbers several times to get what we want\nggexport(plot_to_export,\n         filename = \"iris_scatter.png\",\n         width = 2400, \n         height = 1800, \n         res=300)"
  },
  {
    "objectID": "posts/04_Intro2R_visual_data_exploration.html#exercises",
    "href": "posts/04_Intro2R_visual_data_exploration.html#exercises",
    "title": "GRAPHICAL DATA EXPLORATION IN R",
    "section": "Exercises",
    "text": "Exercises\n\n\n\n\n\n\nTask\n\n\n\nRead the instructions carefully. If you don’t understand something or something doesn’t work straight away, first think about the problem/error, consult the materials in front of you, than google, than the neighbor on your left and on your right. If after all that you still don’t know how to fix the problem or proceed, than ask me for help!\n\n1.1) Import the penguins dataset and check if the file was correctly imported (344 observations, 8 variables), adjust the code if needed.\n1.2) Create new columns in which species, island and sex will be treated as factors by R.\n1.3) Create a boxplot which will display values of body_mass_g separately for each species.\n1.4) Create a dotchart which will display values of flipper_length_mm for each species.\n1.5.1) Create a scatter plot which will display bill_length_mm in relationship to bill_depth_mm with species denoted by different colors.\n1.5.2) Rename x and y axis to Bill Length (mm) and Bill Depth (mm), and legend title to Species.\n1.5.3) Change the plot theme to either theme_bw() or theme_classic().\n1.5.4) Export the plot to your computer in high resolution and save it as penguins_scatter.png.\nExpected outputs of the exercises shown below:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nDid you get the following warnings after running the ggplot commands?\nRemoved 2 rows containing non-finite values (stat_boxplot()). Removed 2 rows containing missing values (geom_point()).\nWhat do they mean?\n\n\n\n\n\n\n\n\n\nTask\n\n\n\n2.1) Import the dataset you downloaded from the internet in the previous lab.\n2.2) Create new columns in which character data will be treated as factors by R (if you have any).\n2.3) Choose one numerical variable and create a boxplot. Divide that boxplot by different groups if it makes sense. Change the names of axis titles and change the default theme.\n2.4) Choose one numerical variable and create a dotchart. Divide that dotchart by different groups if it makes sense.\n2.5) If there are two numerical columns in you data, create a scatter plot. Color points according to different groups if it makes sense, change the names of axis titles and change the default theme.\n\n\n\nUntil the end of the class or homework\n\n\n\nDatacamp assignment, Lab 4"
  },
  {
    "objectID": "posts/04_Intro2R_visual_data_exploration.html#mandatory-reading-before-next-class",
    "href": "posts/04_Intro2R_visual_data_exploration.html#mandatory-reading-before-next-class",
    "title": "GRAPHICAL DATA EXPLORATION IN R",
    "section": "Mandatory reading before next class",
    "text": "Mandatory reading before next class\n(on e-classroom)\nDytham, 2011, Choosing and using statistics for biologists:\nChapter 5: Statistics, variables and distributions Chapter 6: Descriptive and presentational techniques"
  },
  {
    "objectID": "posts/05_Intro2R_summary statistics.html",
    "href": "posts/05_Intro2R_summary statistics.html",
    "title": "SUMMARY STATISTICS IN R",
    "section": "",
    "text": "Summary\n\n\n\nIn this lab you will learn how to:\n\ncalculate summary statistics: arithmetic mean, median, standard deviation, interquantile range,\ncalculate summary statistics for different groups in the data using dplyr."
  },
  {
    "objectID": "posts/05_Intro2R_summary statistics.html#import-iris-and-penguins-dataset",
    "href": "posts/05_Intro2R_summary statistics.html#import-iris-and-penguins-dataset",
    "title": "SUMMARY STATISTICS IN R",
    "section": "Import iris and penguins dataset",
    "text": "Import iris and penguins dataset\n\n\n\n\n\n\nTask\n\n\n\nStart the RStudio from the R project icon that you created in the previous lab!\n\n\nTo be sure that the working directory is set to your project folder, use the get getwd() function. The result should end with .../My first R project (if you followed the instructions in the second lab).\n\ngetwd()\n\nImport the dataset, assign it to an object called iris and inspect that it was loaded correctly:\n\niris &lt;- read.csv(file = \"01_data/iris.csv\") \npenguins &lt;- read.table(file = \"01_data/penguins.txt\")\n\nhead(iris); str(iris)\n\n  Sepal_Length Sepal_Width Petal_Length Petal_Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal_Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal_Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal_Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal_Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : chr  \"setosa\" \"setosa\" \"setosa\" \"setosa\" ...\n\nhead(penguins); str(penguins)\n\n  species    island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n1  Adelie Torgersen           39.1          18.7               181        3750\n2  Adelie Torgersen           39.5          17.4               186        3800\n3  Adelie Torgersen           40.3          18.0               195        3250\n4  Adelie Torgersen             NA            NA                NA          NA\n5  Adelie Torgersen           36.7          19.3               193        3450\n6  Adelie Torgersen           39.3          20.6               190        3650\n     sex year\n1   male 2007\n2 female 2007\n3 female 2007\n4   &lt;NA&gt; 2007\n5 female 2007\n6   male 2007\n\n\n'data.frame':   344 obs. of  8 variables:\n $ species          : chr  \"Adelie\" \"Adelie\" \"Adelie\" \"Adelie\" ...\n $ island           : chr  \"Torgersen\" \"Torgersen\" \"Torgersen\" \"Torgersen\" ...\n $ bill_length_mm   : num  39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num  18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int  181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int  3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : chr  \"male\" \"female\" \"female\" NA ...\n $ year             : int  2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ..."
  },
  {
    "objectID": "posts/05_Intro2R_summary statistics.html#summary-statistics",
    "href": "posts/05_Intro2R_summary statistics.html#summary-statistics",
    "title": "SUMMARY STATISTICS IN R",
    "section": "Summary statistics",
    "text": "Summary statistics\nSummary statistics include among other the following common measures of central tendency and variability of numerical variables:\n\nmean\n\nvariance\nstandard deviation (SD)\nstandard error of mean\n\nmedian\n\nquantiles (25th and 75 th percentile)\ninterquantile range (IQR).\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nHow is the arithmetic mean defined? Are there occasions when it is not an appropriate measure to use?\nWhat is variance and what standard deviation? In what units are the defined compared to the variable itself and the mean value?\nHow is the median defined? In which occasions it is more appropriate to use it?\n\n\n\nWhen to use each?\nExplore at minimum graphically using the histogram and than decide which is more appropriate. If the distribution resembles normal, than mean and SD, if not, than median and quantiles. The histogram can be ploted with ggplot, in which we define what we want to be ploted on the x axis, the y axis will be drawn bY default. Than we need to add the geom_histogram():\nExample of iris for Sepal_Length:\n\nlibrary(ggplot2)\n\nggplot(iris, aes(x = Sepal_Length)) +\n    geom_histogram()\n\n\n\n\nAnd for penguins of fliper_length_mm:\n\nggplot(penguins, aes(x = flipper_length_mm)) +\n    geom_histogram() \n\n\n\n\n\nFor each of the summary statistics above there is an appropriate R function to calculate it for us. First, we will calculate the median - median() function, quantiles - quantile() and interquantile range - IQR() function. We will calculate this for the column Sepal_Length of iris dataset, again remember that we access columns with $:\n\nmedian(iris$Sepal_Length)\n\n[1] 5.8\n\nquantile(iris$Sepal_Length)\n\n  0%  25%  50%  75% 100% \n 4.3  5.1  5.8  6.4  7.9 \n\nIQR(iris$Sepal_Length)\n\n[1] 1.3\n\n\nNext, the mean or average value of our numeric variable, variance and standard deviation. For this we use functions mean(), var() and sd(), from before we know, that we use $ to access columns:\n\nmean(iris$Sepal_Length)\n\n[1] 5.843333\n\nvar(iris$Sepal_Length)\n\n[1] 0.6856935\n\nsd(iris$Sepal_Length)\n\n[1] 0.8280661\n\n\n\nLets do the same for penguins:\n\nmedian(penguins$flipper_length_mm)\n\n[1] NA\n\n\nThis is certainly not what you expected, right? Instead of a number we got back NA. This is because our dataset contains NA values in the column flipper_length_mm. We fix this by adding argument na.rm = TRUE to all of these functions. With this argument we tell R to ignore or dismiss NA values if it finds them. The functions with included argument:\n\nmedian(penguins$flipper_length_mm, na.rm = TRUE)\n\n[1] 197\n\nquantile(penguins$flipper_length_mm, na.rm = TRUE)\n\n  0%  25%  50%  75% 100% \n 172  190  197  213  231 \n\nIQR(penguins$flipper_length_mm, na.rm = TRUE)\n\n[1] 23\n\nmean(penguins$flipper_length_mm, na.rm = TRUE)\n\n[1] 200.9152\n\nvar(penguins$flipper_length_mm, na.rm = TRUE)\n\n[1] 197.7318\n\nsd(penguins$flipper_length_mm, na.rm = TRUE)\n\n[1] 14.06171"
  },
  {
    "objectID": "posts/05_Intro2R_summary statistics.html#summary-statistics-for-two-or-more-groups",
    "href": "posts/05_Intro2R_summary statistics.html#summary-statistics-for-two-or-more-groups",
    "title": "SUMMARY STATISTICS IN R",
    "section": "Summary statistics for two or more groups",
    "text": "Summary statistics for two or more groups\nHowever, we know that our data consists of multiple species and it would be sensible to group it by the Species column.\n\nlibrary(ggplot2)\n\nggplot(iris, aes(x = Sepal_Length)) +\n    geom_histogram() +\n    facet_wrap(~Species)\n\n\n\n\nFor this, we will return to the dplyr package, that enables to do this with ease - we can use the group_by() function to instruct R to treat groups separately. Next, we can use summarise() function to compute the summary statistics. We can also add the column, that will tell us the number of elements in each group with - n(). We will compute also the mean and the standard deviation of Sepal_Length.\n\n\n\n\n\n\nTip\n\n\n\nThe %&gt;% is used to “chain” operations meaning that one operation follows the next in the specified order and with that our code is more compact, efficient and readable. Below code is therefore read as:\n\ntake iris object\ngroup data in iris object by categories in Species column\nwithin summarise function compute:\n\nnumber of individuals belonging to each group n(),\nmean value of column Sepal_length for each group,\nand the standard deviation of Sepal_length.\n\n\n\n\nThe functions we will be using in the following examples are a part of the dplyr package, so we must load it before we can use them with library() function.\n\nlibrary(dplyr) \n\niris %&gt;%\n    group_by(Species) %&gt;%\n    summarise(\n        n(), # does not require any additional argument\n        mean(Sepal_Length), # you are already familiar with mean()\n        sd(Sepal_Length) # and sd() function\n    )\n\n# A tibble: 3 × 4\n  Species    `n()` `mean(Sepal_Length)` `sd(Sepal_Length)`\n  &lt;chr&gt;      &lt;int&gt;                &lt;dbl&gt;              &lt;dbl&gt;\n1 setosa        50                 5.01              0.352\n2 versicolor    50                 5.94              0.516\n3 virginica     50                 6.59              0.636\n\n\nThe above call can be slightly modified, so the outcome is more informative. We will name our results so it is easier to understand what we have calculated. We will name the outputs as number_of_animals, mean_sep_length and sd_sep_length and put this names in front of the corresponding functions within summarise() function.\n\n# We can name the results so it is easier to know what we got\niris %&gt;%\n    group_by(Species) %&gt;%\n    summarise(\n        n_individuals = n(),\n        mean_sep_length = mean(Sepal_Length),\n        sd_sep_length = sd(Sepal_Length)\n) \n\n# A tibble: 3 × 4\n  Species    n_individuals mean_sep_length sd_sep_length\n  &lt;chr&gt;              &lt;int&gt;           &lt;dbl&gt;         &lt;dbl&gt;\n1 setosa                50            5.01         0.352\n2 versicolor            50            5.94         0.516\n3 virginica             50            6.59         0.636"
  },
  {
    "objectID": "posts/05_Intro2R_summary statistics.html#exercises",
    "href": "posts/05_Intro2R_summary statistics.html#exercises",
    "title": "SUMMARY STATISTICS IN R",
    "section": "Exercises",
    "text": "Exercises\n\n\n\n\n\n\nTask\n\n\n\nRead the instructions carefully. If you don’t understand something or something doesn’t work straight away, first think about the problem/error, consult the materials in front of you, than google, than the neighbor on your left and on your right. If after all that you still don’t know how to fix the problem or proceed, than ask me for help!\n\nFor penguins dataset:\n1.1) Create a histogram of body_mass_g that is divided by species and sex of the penguins. To do that, you will need to include ~ species + sex within the function, that divides the data.\n1.2) Calculate median and interquantile range for bill_length_mm divided by species and island using dplyr package. Add also the column in which the number of individuals of each group will be shown.\n1.3) Calculate mean and standard deviation for bill_depth_mm divided by species and sex using dplyr package. Add also the column in which the number of individuals of each group will be shown.\nExpected outputs of the exercises shown below:\n\n\n\n\n\n\n\n# A tibble: 5 × 5\n# Groups:   species [3]\n  species   island        N median_bill_length iqr_bill_length\n  &lt;chr&gt;     &lt;chr&gt;     &lt;int&gt;              &lt;dbl&gt;           &lt;dbl&gt;\n1 Adelie    Biscoe       44               38.7            3.02\n2 Adelie    Dream        56               38.6            3.62\n3 Adelie    Torgersen    52               38.9            4.45\n4 Chinstrap Dream        68               49.6            4.73\n5 Gentoo    Biscoe      124               47.3            4.25\n\n\n# A tibble: 8 × 5\n# Groups:   species [3]\n  species   sex        N mean_bill_length sd_bill_length\n  &lt;chr&gt;     &lt;chr&gt;  &lt;int&gt;            &lt;dbl&gt;          &lt;dbl&gt;\n1 Adelie    female    73             37.3           2.03\n2 Adelie    male      73             40.4           2.28\n3 Adelie    &lt;NA&gt;       6             37.8           2.80\n4 Chinstrap female    34             46.6           3.11\n5 Chinstrap male      34             51.1           1.56\n6 Gentoo    female    58             45.6           2.05\n7 Gentoo    male      61             49.5           2.72\n8 Gentoo    &lt;NA&gt;       5             45.6           1.37\n\n\n\n\n\n\n\n\nQuestion\n\n\n\n\nWhat do you think about displaying the data of individuals with unknown sex (NA)? Would it be sensible to omit it? If yes, in which cases?\n\n\n\n\n\n\n\n\n\n\nTask\n\n\n\n2.1) Import the dataset you downloaded from the internet in the previous lab.\n2.2) Create histograms of numerical columns using ggplot.\n2.3) Create histograms of numerical columns divided by sensible groups using ggplot.\n2.4) Calculate summary statistics: mean, median, standard deviation and IQR for two numerical columns in your dataset. Divide the data into sensible groups.\n\n\n\nFinal report\n\n\n\n\n\n\nFinal report\n\n\n\nPrepare a report in MS Word format, cover page and 3-5 pages with content, that will include:\n\na short description of the dataset that you used as your own example in the labs (you can also include photos or other graphics for better illustration),\na boxplot, a dotchart, a scatterplot and a histogram of your data, keep in mind if there are meaningful groups that can divide your data,\na table in which summary statistics of numerical variables will be presented,\na short text (several sentences) accompanying each figure and the table.\n\n\n\nDeadline: 15th November 2023, Upload to e-classroom.\n\n\nUntil the end of the class or homework\n\n\n\nDatacamp assignment, Lab 5"
  },
  {
    "objectID": "posts/04_Intro2R_visual_data_exploration.html#reading-before-next-lab",
    "href": "posts/04_Intro2R_visual_data_exploration.html#reading-before-next-lab",
    "title": "GRAPHICAL DATA EXPLORATION IN R",
    "section": "Reading before next lab",
    "text": "Reading before next lab\n(on e-classroom)\nDytham, 2011, Choosing and using statistics for biologists:\nChapter 5: Statistics, variables and distributions Chapter 6: Descriptive and presentational techniques"
  },
  {
    "objectID": "posts/01_SDMs_species_occurence_and_absence.html",
    "href": "posts/01_SDMs_species_occurence_and_absence.html",
    "title": "OBTAINING OCCURRENCES AND CREATING PSEUDO-ABSENCES OF SPECIES",
    "section": "",
    "text": "Summary\n\n\n\nIn this lab you will:\n\nuse R code to access species occurrence data on GBIF server and download it,\nfilter and select data to retain only information of interest,\nlearn how to simulate pseudo-absence points in areas around species presences,\ncreate an interactive map of spatial points."
  },
  {
    "objectID": "posts/01_SDMs_species_occurence_and_absence.html#before-we-start",
    "href": "posts/01_SDMs_species_occurence_and_absence.html#before-we-start",
    "title": "OBTAINING OCCURRENCES AND CREATING PSEUDO-ABSENCES OF SPECIES",
    "section": "Before we start",
    "text": "Before we start\n\n\n\n\n\n\nTask\n\n\n\n\nCreate new R project following Lab 2 of Intro to R, and name it Introduction to species distribution models,\nCreate folders 01_data, 02_scripts, 03_results,\nOpen new R script and save it as Erebia stirius.\nWhen following this lab, copy & paste the code so it is organised as it is in the teaching materials."
  },
  {
    "objectID": "posts/01_SDMs_species_occurence_and_absence.html#lab-plan",
    "href": "posts/01_SDMs_species_occurence_and_absence.html#lab-plan",
    "title": "OBTAINING OCCURRENCES AND CREATING PSEUDO-ABSENCES OF SPECIES",
    "section": "Lab plan",
    "text": "Lab plan"
  },
  {
    "objectID": "posts/01_SDMs_species_occurence_and_absence.html#occurence-data-of-organisms-points-in-space-and-time-for-distribution-models",
    "href": "posts/01_SDMs_species_occurence_and_absence.html#occurence-data-of-organisms-points-in-space-and-time-for-distribution-models",
    "title": "Obtaining occurrences and creating pseudo-absences of species",
    "section": "Occurence data of organisms (points in space and time) for distribution models",
    "text": "Occurence data of organisms (points in space and time) for distribution models\nOccurrences of organisms can be collected from multiple sources (see Guisan et al., 2017, pp. 111):\n\nField data,\nTracking data,\nLiterature data,\nHerbarium and museum data or\nDatabases (that can contain all of the above).\n\nThe minimum number of presences ought to be more than 30 (as model performance declines severely, if fewer than), while sample size effects usually become less critical above 50 presences. Additionally, for more robust parameter estimation, a rule of thumb is to have a minimum of ten presence observations available per environmental predictor used. Guisan et al. (2017) advises this minimum to be raised to 20 - 50 observations per predictor (depending on the complexity of the models to be built).\nWe will take advantage of obtaining occurrences provided by a global and freely accessible database Global Biodiversity Information Facility - GBIF. GBIF is an international network and data infrastructure funded by the world’s governments and aimed at providing anyone, anywhere, open access to data about all types of life on Earth. More about GBIF database you can find here.\n\n\n\n\nGBIF dataset website\n\n\n\nOur lab will be focused on a butterfly species of Erebia genus:\n\n\n\n\nE. stirius.\n\n\n\n\nErebia stirius - Stirian ringlet: endemic to the area between the SE Alps and the N Dinaric Alps, where it inhabits grassy, rocky slopes, between 700 and 1800 m. Caterpillars feed mainly on the grass species Sesleria caerulea. The species is listed as Least Concerned by the IUCN (link)\n\n\n\n\n\n\nE. stirius distribution.\n\n\n\n\nWe will access the occurrence data straight from R with using occ_search() function from rgbif package to download the data from the portal. To do this for E. stirius we have to set argument scientificName = \"Erebia stirius\".\n\ninstall.packages(\"rgbif\")\ninstall.packages(\"tidyverse\")\n\n\nlibrary(rgbif)\nlibrary(tidyverse)\n\n# access data: Erebia stirius and assign it to object stirius_gbif\nstirius_gbif &lt;- occ_search(scientificName = \"Erebia stirius\",\n                           # increase the default number of retrieved \n                           # locations to 1000 \n                           limit = 1000) \n\nThe downloaded dataset is a list from which we extract only data element with the $ sign:\n\nstirius &lt;- stirius_gbif$data \n\n\n\n\n\n\n\nTask\n\n\n\nClick on the stirius_gbif and explore the dataframe. What are the columns that are useful to us and which do not seem important?\n\n\nWhen we examine the returned data frame, there are many columns, that seem to have no particular meaning for us. So we will select only those, that we might need for further investigation or use. For sure we need GPS coordinates (decimalLatitude and decimalLongitude) while along with that, we will extract the error of the GPS coordinates (coordinateUncertaintyInMeters), year of publishing the record, basis of record (basisOfRecord). Remember that within select() we can rename columns in the same step (lat = and lon = for example) and using %&gt;% operator we chain operations, meaning that the subsequent operations will be executed on the object preceding the operator.\n\n\n\n\n\n\nWarning\n\n\n\nFunctions select() and filter() are defined in multiple R packages. Depending on which package was loaded last by library(), R chooses which version of the function it will apply. If we do not get the expected result from the function or an unexpected error after running it, this is the likeliest cause.\n\n\n\n\n\n\n\n\nTip\n\n\n\nWe can avoid problems with commonly named functions by telling R a priori which function from which package we want to use. For example, select() or filter() from dplyr as follows:\n\ndplyr::filter(),\ndplyr::select().\n\n\n\n\nstirius &lt;- stirius %&gt;% \n    dplyr::select(species, \n           lat = decimalLatitude,\n           lon = decimalLongitude,\n           gps_error_m = coordinateUncertaintyInMeters,\n           year,\n           record_origin = basisOfRecord)\n\nNext steps in occurrence data preparation is to:\n\nexclude all NA values in the GPS coordinates (with drop_na() from tidyr), as if we do not have coordinates, we cannot use these occurrences in the analysis.\n\n\nstirius &lt;- stirius %&gt;% \n    tidyr::drop_na(lat, lon) \n\n\nexamine the year when the record was published and decide, what year range we will include (i.e. very old records might be biased due to differences in environmental conditions)\n\n\nlibrary(ggplot2)\n\nggplot(stirius, aes(x = year)) +\n    geom_histogram() +\n    theme_classic()\n\n\n\n\n\nexamine record origin (if museum, we need to check that location provided is not museum location!),\n\n\ntable(stirius$record_origin)\n\n\n HUMAN_OBSERVATION    LIVING_SPECIMEN  MATERIAL_CITATION    MATERIAL_SAMPLE \n                67                  1                119                  2 \n        OCCURRENCE PRESERVED_SPECIMEN \n               352                 44 \n\n\n\nexamine gps errors and decide, what to do with records with large location error (i.e. more than 5 km).\n\n\nggplot(stirius, aes(x = gps_error_m)) +\n    geom_histogram() +\n    theme_classic()\n\n\n\n\nAnd retain only the observations that satisfy our criteria. For later convenience, we will also add a column ID with consecutive numbers starting from 1.\n\nstirius &lt;- \n    stirius %&gt;% \n    filter(\n        year &gt; 1950, # retain only records after 1950\n        # retain observations and occurences\n        record_origin %in% c(\"HUMAN_OBSERVATION\", \"OCCURRENCE\"), \n        gps_error_m &lt;= 5000 # with 5000 m or less error\n    ) \n\nstirius &lt;- stirius %&gt;% \n    # add an ID column: numbers from 1 to max number of rows\n    mutate(ID = seq(1:nrow(stirius)))\n\nLastly, lets check the properties of our data frame:\n\nstr(stirius)\n\ntibble [154 × 7] (S3: tbl_df/tbl/data.frame)\n $ species      : chr [1:154] \"Erebia parmenio\" \"Erebia parmenio\" \"Erebia parmenio\" \"Erebia parmenio\" ...\n $ lat          : num [1:154] 45.8 45.7 46 46.4 46.4 ...\n $ lon          : num [1:154] 11.2 10.8 10.7 13.6 13.6 ...\n $ gps_error_m  : num [1:154] 61 184 25 25 26 6 25 50 20 50 ...\n $ year         : int [1:154] 2022 2022 2022 2021 2021 2021 2020 2020 2020 2020 ...\n $ record_origin: chr [1:154] \"HUMAN_OBSERVATION\" \"HUMAN_OBSERVATION\" \"HUMAN_OBSERVATION\" \"HUMAN_OBSERVATION\" ...\n $ ID           : int [1:154] 1 2 3 4 5 6 7 8 9 10 ...\n\nsummary(stirius)\n\n   species               lat             lon         gps_error_m  \n Length:154         Min.   :45.27   Min.   :10.68   Min.   :   2  \n Class :character   1st Qu.:45.80   1st Qu.:13.20   1st Qu.:  25  \n Mode  :character   Median :46.37   Median :13.72   Median : 500  \n                    Mean   :46.20   Mean   :13.44   Mean   :1614  \n                    3rd Qu.:46.44   3rd Qu.:14.02   3rd Qu.:5000  \n                    Max.   :47.62   Max.   :15.15   Max.   :5000  \n      year      record_origin            ID        \n Min.   :1951   Length:154         Min.   :  1.00  \n 1st Qu.:1972   Class :character   1st Qu.: 39.25  \n Median :1981   Mode  :character   Median : 77.50  \n Mean   :1989                      Mean   : 77.50  \n 3rd Qu.:2013                      3rd Qu.:115.75  \n Max.   :2022                      Max.   :154.00  \n\n\n\nMap occurences with leaflet interactive maps\nNow that we have downloaded the data, we will display them on a map, so we get a feeling of where our two species have been observed. For that we will use leaflet package which provides us an easy way for creating interactive maps. It functions similar to creating plots with ggplot, the difference is that we add new layers to the plots with %&gt;% operator. The basic function for mapping is leaflet() inside which we specify data object we want to plot, in our case stirius. With addProviderTiles() we add background to our map and with argument provider = \"Stamen.TerrainBackground\" we specify which type of background. You can explore other options for background here. You can change the background by replacing \"Stamen.TerrainBackground\" with another name, i.e. \"OpenTopoMap\". Next we add our points with function addCircleMarkers(), within which we must specify names of columns in our data that represent longitude (lon) and latitude (lat) preceeded by the ~ sign.\n\n\ninstall.packages(\"leaflet\")\n\n\nlibrary(leaflet) # fast, simple and efficient interactive mapping\n\nleaflet(stirius) %&gt;%\n    addProviderTiles(provider = \"Stamen.TerrainBackground\") %&gt;%\n    addCircleMarkers(lng = ~lon, \n                     lat = ~lat)\n\n\n\n\n\n\n\n\n\n\n\nTask\n\n\n\nTo confirm whether the occurence locations are reliable, we should compare them with the known distribution range of the species. Do this map reflect the species distribution according to IUCN?\n\n\n\n\n\nE. stirius distribution.\n\n\n\nHowever, there are some points, that don’t seem OK:\n\none is located at the center of Garda lake,\nanother is located at the Adriatic coast (there seem to be more occurences here, as the point is not transparent).\n\nLets adapt the map a bit, to figure out which points in the data these two are. We will add the label = argument, that will pop-up the ID of each point, when we hover over:\n\nleaflet(stirius) %&gt;%\n    addProviderTiles(provider = \"Stamen.TerrainBackground\") %&gt;%\n    addCircleMarkers(lng = ~lon, \n                     lat = ~lat, \n                     label = ~ID) # pop up with the ID number\n\n\n\n\n\n\nWe will remove this two as they seem erroneous. Within filter() we will use ! to retain the inverse of the IDs we will provide (I added also the ID 82 & 83, as both lie directly below the record number 104):\n\nstirius &lt;- stirius %&gt;% \n    dplyr::filter(!ID %in% c(82, 83, 114, 140))\n\nNow redraw the map, to see if it was successful:\n\nleaflet(stirius) %&gt;%\n    addProviderTiles(provider = \"Stamen.TerrainBackground\") %&gt;%\n    addCircleMarkers(lng = ~lon, \n                     lat = ~lat, \n                     label = ~ID) # pop up with the ID number\n\n\n\n\n\n\n\n\n\n\n\nQuestions to consider\n\n\n\nHow reliable is the data obtained from GBIF?\nShould we put more considerations on the origin of the occurrence data? For example, is it coming from research studies or was it provided by the citizen scientists?\nIn general, what are the main possible errors or biases that can be present in collecting species occurrence data?"
  },
  {
    "objectID": "posts/01_SDMs_species_occurence_and_absence.html#absences-and-what-to-do-if-we-dont-have-them",
    "href": "posts/01_SDMs_species_occurence_and_absence.html#absences-and-what-to-do-if-we-dont-have-them",
    "title": "OBTAINING OCCURRENCES AND CREATING PSEUDO-ABSENCES OF SPECIES",
    "section": "Absences and what to do if we don’t have them",
    "text": "Absences and what to do if we don’t have them\nReal absences are hard to obtain in most cases (i.e. species present, but not detected; research areas to big to monitor all available area, etc.). For that reason, there are multiple options to generate pseudo-absences, depending on the species, type of data, research question, scale of inference (global, regional, local):\n\nbackground,\nbuffer,\nCorrelated Random Walks,\nreverse Correlated Random Walks,\nother.\n\n\n\n\nPseudo absence generation methods (Hazen et al., 2021)\n\n\nFor simplicity, we will use the buffer method. For now, we will just create a buffer around our points, which will be later used as an area for pseudo-absence points creation. In order to perform spatial operations on our data, we need to transform it into appropriate spatial format with coordinates() function from sp package. We will create a new object called stirius_sp, which we will transform. After the assign operator we define which columns in our data represent longitude and latitude. With class() we check that the transformation was successful.\n\ninstall.packages(\"sp\")\ninstall.packages(\"raster\")\n\n\nlibrary(sp)\nlibrary(raster)\n\nstirius_sp &lt;- stirius\n\n# In order to perform spatial operations on our data, we need to transform it\n# into appropriate type of object with coordinates function\ncoordinates(stirius_sp) &lt;- ~ lon + lat\n\nclass(stirius_sp) # we want SpatialPointsDataFrame\n\n[1] \"SpatialPointsDataFrame\"\nattr(,\"package\")\n[1] \"sp\"\n\n\nNext we create a buffer around our points with buffer() function and set its width = to 20 km (20000m). As the buffer() function is contained in more than one package, I specified that I want the one from raster package with ::. Note that 25 km buffer width is an arbitrary number, I choose it based on the assumed dispersal potential of the butterfly species. When creating buffers it is crucial, that we choose a distance, that is biologically or ecologically sensible. For example, whales can travel tens of km per day, while a mole will likely spend its entire lifespan within a single small or medium meadow.\n\nstirius_buffer &lt;- raster::buffer(stirius_sp, # arround occurences of E. stirius \n                          width = 25000) # create 25 km buffer \n\nclass(stirius_buffer)\n\n[1] \"SpatialPolygons\"\nattr(,\"package\")\n[1] \"sp\"\n\n\nLets map the created buffer with leaflet, this time instead of mapping points we add a the buffer layer with addPolygons() function without any additional arguments:\n\nleaflet(stirius_buffer) %&gt;% \n    addProviderTiles(provider = \"Esri.WorldImagery\") %&gt;%\n    addPolygons()\n\n\n\n\n\nThe next thing we will do is create a set of pseudo absence points within our buffer. For this we will need the terra package and change the stirius_buffer into appropriate terra format. We will save it in a new object called stirius_buffer_tr, and transform it using vect() function:\n\nlibrary(terra)\n\nstirius_buffer_tr &lt;- vect(stirius_buffer)\n\nclass(stirius_buffer_tr)\n\n[1] \"SpatVector\"\nattr(,\"package\")\n[1] \"terra\"\n\n\nThe pseudo absence points can be created using spatSample() function, that performs random sampling within the buffer provided (stirius_buffer_tr). The second argument tells the function, how many points we want to create. At this step, there are many considerations, that need to be taken into account, as the subsequent results can depend heavily on the number of points that we decide to sample (Barbet-Massin et al., 2012, Fieberg et al., 2021). We will keep it simple and create the same number of pseudo absences as we have presences (nrow(stirius) = 150). We will save these points into object stirius_abs:\n\nstirius_abs &lt;- spatSample(stirius_buffer_tr,\n                          size = nrow(stirius))\n\nclass(stirius_abs)\n\n[1] \"SpatVector\"\nattr(,\"package\")\n[1] \"terra\"\n\n\nBefore displaying the points on a map, we need to change the stirius_abs from terra format to a regular data frame. For that, we extract the coordinates from the object stirius_abs (terra::geom()) and change it to dataframe (as.data.frame()):\n\nstirius_abs_df &lt;- as.data.frame(terra::geom(stirius_abs))\n\nclass(stirius_abs_df)\n\n[1] \"data.frame\"\n\n\nWith head() function, we display the first six rows of the dataframe, and we can note that the coordinates are stored in columns x and y:\n\nhead(stirius_abs_df)\n\n  geom part        x        y hole\n1    1    1 14.67693 46.29390    0\n2    2    1 11.50673 46.31340    0\n3    3    1 13.70121 46.68214    0\n4    4    1 14.25173 46.31043    0\n5    5    1 13.41612 47.63194    0\n6    6    1 13.33008 46.35428    0\n\n\nAnd map them, to see where they were created:\n\nleaflet(stirius_abs_df) %&gt;%\n    addProviderTiles(provider = \"Esri.WorldImagery\") %&gt;%\n    addCircleMarkers(lng = ~x, \n                     lat = ~y, \n                     color = \"red\")"
  },
  {
    "objectID": "posts/01_SDMs_species_occurence_and_absence.html#finalising-presence-absence-datasets",
    "href": "posts/01_SDMs_species_occurence_and_absence.html#finalising-presence-absence-datasets",
    "title": "OBTAINING OCCURRENCES AND CREATING PSEUDO-ABSENCES OF SPECIES",
    "section": "Finalising presence absence datasets",
    "text": "Finalising presence absence datasets\nThere is one more step in preparation of presences of E. stirius (stirius) dataset. We need to add a column (new variable) that will denote that this are points, where species is present (1). As we will not need other variables, we will select only species, both coordinates and presence columns:\n\nlibrary(dplyr)\n\n\n\nstirius &lt;- stirius %&gt;%\n    # create new column, denoting this are points where species is present\n    dplyr::mutate(presence = 1) %&gt;%  \n    dplyr::select(\n        species,\n        lat,\n        lon,\n        presence\n    )\n\nThe same step is needed in preparation of pseudo-absences, only this time time we need to add a column (new variable) that will denote that this are points, where the species is not present (0), or better said points that we have created as pseudo absences. As we will not need other variables, we will select only species, both coordinates (and rename them to lat and lon) and presence column:\n\n#stirius_abs_df &lt;- readRDS(\"01_data/stirius_abs_df.RDS\") \n\n\nstirius_abs_df &lt;- stirius_abs_df %&gt;%  \n    dplyr::mutate(species = \"Erebia parmenio\", # create now column with species name\n                  # create new column, denoting this are points where species is pseudo absent\n                  presence = 0) %&gt;% \n    dplyr::select(\n        species,\n        lat = y, # rename y to lat\n        lon = x, # rename x to lon\n        presence\n    )\n\nIn this last step today, we will merge the two dataframes together. Above steps prepared them to contain columns with the same names and the same information, which is a prerequisite for merging. We use rbind() function, which binds (merges) two tables in a way, that the first data frame is continued by the second, retaining the same number of columns as original data frame:\n\nhead(stirius) ; head(stirius_abs_df)\n\n# A tibble: 6 × 4\n  species           lat   lon presence\n  &lt;chr&gt;           &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 Erebia parmenio  45.8  11.2        1\n2 Erebia parmenio  45.7  10.8        1\n3 Erebia parmenio  46.0  10.7        1\n4 Erebia parmenio  46.4  13.6        1\n5 Erebia parmenio  46.4  13.6        1\n6 Erebia parmenio  46.4  13.6        1\n\n\n          species      lat      lon presence\n1 Erebia parmenio 46.29390 14.67693        0\n2 Erebia parmenio 46.31340 11.50673        0\n3 Erebia parmenio 46.68214 13.70121        0\n4 Erebia parmenio 46.31043 14.25173        0\n5 Erebia parmenio 47.63194 13.41612        0\n6 Erebia parmenio 46.35428 13.33008        0\n\nstirius_pa &lt;- rbind(stirius_abs_df, stirius)"
  },
  {
    "objectID": "posts/01_SDMs_species_occurence_and_absence.html#export-the-data",
    "href": "posts/01_SDMs_species_occurence_and_absence.html#export-the-data",
    "title": "OBTAINING OCCURRENCES AND CREATING PSEUDO-ABSENCES OF SPECIES",
    "section": "Export the data",
    "text": "Export the data\nWe will export the presence absence dataframe and the buffer, so they will be available to us in the following labs, when we will need it.\n\nsaveRDS(stirius_pa, \"01_data/stirius_pa.RDS\")\nsaveRDS(stirius_buffer, \"01_data/stirius_buffer.RDS\")"
  },
  {
    "objectID": "posts/01_SDMs_species_occurence_and_absence.html#assignment",
    "href": "posts/01_SDMs_species_occurence_and_absence.html#assignment",
    "title": "OBTAINING OCCURRENCES AND CREATING PSEUDO-ABSENCES OF SPECIES",
    "section": "Assignment",
    "text": "Assignment\n\n\n\n\n\n\nTask\n\n\n\n\nCreate new R script and name it as the species you choose to work on.\nCopy - paste the code from the Erebia stirius script to your empty script.\nAdapt the code to achieve the following:\n\n3.1) download the data for your species from GBIF,\n3.2) filter the data to retain only reliable occurrence locations,\n3.3) create a spatial buffer around occurrences and sample pseudo-absence within it,\n3.4) merge the presence and pseudo-absence dataframes, and export them to the hard drive (also the buffer),\n3.5) save the script with the code for your species,\n3.6) make sure that the project folder will be available to you next week at the labs (either store it on usb, cloud or similar, in case it gets deleted from computers)."
  },
  {
    "objectID": "posts/01_SDMs_species_occurence_and_absence.html#occurence-data-for-distribution-models",
    "href": "posts/01_SDMs_species_occurence_and_absence.html#occurence-data-for-distribution-models",
    "title": "OBTAINING OCCURRENCES AND CREATING PSEUDO-ABSENCES OF SPECIES",
    "section": "Occurence data for distribution models",
    "text": "Occurence data for distribution models\nOccurrences of organisms can be collected from multiple sources (see Guisan et al., 2017, pp. 111):\n\nField data,\nTracking data,\nLiterature data,\nHerbarium and museum data or\nDatabases (that can contain all of the above).\n\nThe minimum number of presences ought to be more than 30 (as model performance declines severely, if fewer than), while sample size effects usually become less critical above 50 presences. Additionally, for more robust parameter estimation, a rule of thumb is to have a minimum of ten presence observations available per environmental variable used. Guisan et al. (2017) advises this minimum to be raised to 20 - 50 observations per predictor (depending on the complexity of the models to be built).\nWe will take advantage of obtaining occurrences provided by a global and freely accessible database Global Biodiversity Information Facility - GBIF. GBIF is an international network and data infrastructure funded by the world’s governments and aimed at providing anyone, anywhere, open access to data about all types of life on Earth. More about GBIF database you can find here.\n\n\n\n\nGBIF dataset website\n\n\n\nOur lab will be focused on a butterfly species of Erebia genus:\n\n\n\n\nE. stirius.\n\n\n\n\nErebia stirius - Stirian ringlet: endemic to the area between the SE Alps and the N Dinaric Alps, where it inhabits grassy, rocky slopes, between 700 and 1800 m. Caterpillars feed mainly on the grass species Sesleria caerulea. The species is listed as Least Concerned by the IUCN (link)\n\n\n\n\n\n\nE. stirius distribution.\n\n\n\n\nWe will access the occurrence data straight from R with using occ_search() function from rgbif package to download the data from the portal. To do this for E. stirius we have to set argument scientificName = \"Erebia stirius\".\n\ninstall.packages(\"rgbif\")\ninstall.packages(\"tidyverse\")\n\n\nlibrary(rgbif)\nlibrary(tidyverse)\n\n# access data: Erebia stirius and assign it to object stirius_gbif\nstirius_gbif &lt;- occ_search(scientificName = \"Erebia stirius\",\n                           # increase the default number of retrieved \n                           # locations to 1000 \n                           limit = 1000) \n\nThe downloaded dataset is a list from which we extract only data element with the $ sign:\n\nstirius &lt;- stirius_gbif$data \n\n\n\n\n\n\n\nTask\n\n\n\nClick on the stirius_gbif and explore the dataframe. What are the columns that are useful to us and which do not seem important?\n\n\nWhen we examine the returned data frame, there are many columns, that seem to have no particular meaning for us. So we will select only those, that we might need for further investigation or use. For sure we need GPS coordinates (decimalLatitude and decimalLongitude) while along with that, we will extract the error of the GPS coordinates (coordinateUncertaintyInMeters), year of publishing the record, basis of record (basisOfRecord). Remember that within select() we can rename columns in the same step (lat = and lon = for example) and using %&gt;% operator we chain operations, meaning that the subsequent operations will be executed on the object preceding the operator.\n\n\n\n\n\n\nWarning\n\n\n\nFunctions select() and filter() are defined in multiple R packages. Depending on which package was loaded last by library(), R chooses which version of the function it will apply. If we do not get the expected result from the function or an unexpected error after running it, this is the likeliest cause.\n\n\n\n\n\n\n\n\nTip\n\n\n\nWe can avoid problems with commonly named functions by telling R a priori which function from which package we want to use. For example, select() or filter() from dplyr as follows:\n\ndplyr::filter(),\ndplyr::select().\n\n\n\n\nstirius &lt;- stirius %&gt;% \n    dplyr::select(species, \n           lat = decimalLatitude,\n           lon = decimalLongitude,\n           gps_error_m = coordinateUncertaintyInMeters,\n           year,\n           record_origin = basisOfRecord)\n\nNext steps in occurrence data preparation is to:\n\nexclude all NA values in the GPS coordinates (with drop_na() from tidyr), as if we do not have coordinates, we cannot use these occurrences in the analysis.\n\n\nstirius &lt;- stirius %&gt;% \n    tidyr::drop_na(lat, lon) \n\n\nexamine the year when the record was published and decide, what year range we will include (i.e. very old records might be biased due to differences in environmental conditions)\n\n\nlibrary(ggplot2)\n\nggplot(stirius, aes(x = year)) +\n    geom_histogram() +\n    theme_classic()\n\n\n\n\n\nexamine record origin (if museum, we need to check that location provided is not museum location!),\n\n\ntable(stirius$record_origin)\n\n\n HUMAN_OBSERVATION    LIVING_SPECIMEN  MATERIAL_CITATION    MATERIAL_SAMPLE \n                67                  1                119                  2 \n        OCCURRENCE PRESERVED_SPECIMEN \n               352                 44 \n\n\n\nexamine gps errors and decide, what to do with records with large location error (i.e. more than 5 km).\n\n\nggplot(stirius, aes(x = gps_error_m)) +\n    geom_histogram() +\n    theme_classic()\n\n\n\n\nAnd retain only the observations that satisfy our criteria. For later convenience, we will also add a column ID with consecutive numbers starting from 1.\n\nstirius &lt;- \n    stirius %&gt;% \n    filter(\n        year &gt; 1950, # retain only records after 1950\n        # retain observations and occurences\n        record_origin %in% c(\"HUMAN_OBSERVATION\", \"OCCURRENCE\"), \n        gps_error_m &lt;= 5000 # with 5000 m or less error\n    ) \n\nstirius &lt;- stirius %&gt;% \n    # add an ID column: numbers from 1 to max number of rows\n    mutate(ID = seq(1:nrow(stirius)))\n\nLastly, lets check the properties of our data frame:\n\nstr(stirius)\n\ntibble [154 × 7] (S3: tbl_df/tbl/data.frame)\n $ species      : chr [1:154] \"Erebia parmenio\" \"Erebia parmenio\" \"Erebia parmenio\" \"Erebia parmenio\" ...\n $ lat          : num [1:154] 45.8 45.7 46 46.4 46.4 ...\n $ lon          : num [1:154] 11.2 10.8 10.7 13.6 13.6 ...\n $ gps_error_m  : num [1:154] 61 184 25 25 26 6 25 50 20 50 ...\n $ year         : int [1:154] 2022 2022 2022 2021 2021 2021 2020 2020 2020 2020 ...\n $ record_origin: chr [1:154] \"HUMAN_OBSERVATION\" \"HUMAN_OBSERVATION\" \"HUMAN_OBSERVATION\" \"HUMAN_OBSERVATION\" ...\n $ ID           : int [1:154] 1 2 3 4 5 6 7 8 9 10 ...\n\nsummary(stirius)\n\n   species               lat             lon         gps_error_m  \n Length:154         Min.   :45.27   Min.   :10.68   Min.   :   2  \n Class :character   1st Qu.:45.80   1st Qu.:13.20   1st Qu.:  25  \n Mode  :character   Median :46.37   Median :13.72   Median : 500  \n                    Mean   :46.20   Mean   :13.44   Mean   :1614  \n                    3rd Qu.:46.44   3rd Qu.:14.02   3rd Qu.:5000  \n                    Max.   :47.62   Max.   :15.15   Max.   :5000  \n      year      record_origin            ID        \n Min.   :1951   Length:154         Min.   :  1.00  \n 1st Qu.:1972   Class :character   1st Qu.: 39.25  \n Median :1981   Mode  :character   Median : 77.50  \n Mean   :1989                      Mean   : 77.50  \n 3rd Qu.:2013                      3rd Qu.:115.75  \n Max.   :2022                      Max.   :154.00  \n\n\n\nMap occurences with leaflet interactive maps\nNow that we have downloaded the data, we will display them on a map, so we get a feeling of where our two species have been observed. For that we will use leaflet package which provides us an easy way for creating interactive maps. It functions similar to creating plots with ggplot, the difference is that we add new layers to the plots with %&gt;% operator. The basic function for mapping is leaflet() inside which we specify data object we want to plot, in our case stirius. With addProviderTiles() we add background to our map and with argument provider = \"Esri.WorldImagery\" we specify which type of background. You can explore other options for background here. You can change the background by replacing \"Esri.WorldImagery\" with another name, i.e. \"OpenTopoMap\". Next we add our points with function addCircleMarkers(), within which we must specify names of columns in our data that represent longitude (lon) and latitude (lat) preceeded by the ~ sign.\n\n\ninstall.packages(\"leaflet\")\n\n\nlibrary(leaflet) # fast, simple and efficient interactive mapping\n\nleaflet(stirius) %&gt;%\n    addProviderTiles(provider = \"Esri.WorldImagery\") %&gt;%\n    addCircleMarkers(lng = ~lon, \n                     lat = ~lat)\n\n\n\n\n\n\n\n\n\n\n\nTask\n\n\n\nTo confirm whether the occurence locations are reliable, we should compare them with the known distribution range of the species. Do this map reflect the species distribution according to IUCN?\n\n\n\n\n\nE. stirius distribution.\n\n\n\nHowever, there are some points, that don’t seem OK:\n\none is located at the center of Garda lake,\nanother is located at the Adriatic coast (there seem to be more occurences here, as the point is not transparent).\n\nLets adapt the map a bit, to figure out which points in the data these two are. We will add the label = argument, that will pop-up the ID of each point, when we hover over:\n\nleaflet(stirius) %&gt;%\n    addProviderTiles(provider = \"Esri.WorldImagery\") %&gt;%\n    addCircleMarkers(lng = ~lon, \n                     lat = ~lat, \n                     label = ~ID) # pop up with the ID number\n\n\n\n\n\n\nWe will remove this two as they seem erroneous. Within filter() we will use ! to retain the inverse of the IDs we will provide (I added also the ID 82 & 83, as both lie directly below the record number 104):\n\nstirius &lt;- stirius %&gt;% \n    dplyr::filter(!ID %in% c(82, 83, 114, 140))\n\nNow redraw the map, to see if it was successful:\n\nleaflet(stirius) %&gt;%\n    addProviderTiles(provider = \"Esri.WorldImagery\") %&gt;%\n    addCircleMarkers(lng = ~lon, \n                     lat = ~lat, \n                     label = ~ID) # pop up with the ID number\n\n\n\n\n\n\n\n\n\n\n\nQuestions to consider\n\n\n\nHow reliable is the data obtained from GBIF?\nShould we put more considerations on the origin of the occurrence data? For example, is it coming from research studies or was it provided by the citizen scientists?\nIn general, what are the main possible errors or biases that can be present in collecting species occurrence data?"
  },
  {
    "objectID": "posts/02_SDMs_env_covariates_terra.html",
    "href": "posts/02_SDMs_env_covariates_terra.html",
    "title": "OBTAINING, ASSESSING AND EXTRACTING ENVIRONMENTAL DATA",
    "section": "",
    "text": "Summary\n\n\n\nIn this lab you will:\n\nuse R code to access terrestrial environmental data from WorldClim server and download it,\ncreate a map of environmental data,\ncrop environmental data to the area of interest (buffer),\nassess correlations between environmental data for robust variable selection (Zuur et al., 2010),\nextract environmental data for each presence and pseudo-absence locations."
  },
  {
    "objectID": "posts/02_SDMs_env_covariates_terra.html#before-we-start",
    "href": "posts/02_SDMs_env_covariates_terra.html#before-we-start",
    "title": "OBTAINING, ASSESSING AND EXTRACTING ENVIRONMENTAL DATA",
    "section": "Before we start",
    "text": "Before we start\n\n\n\n\n\n\nTask\n\n\n\n\nOpen the folder Introduction to species distribution models,\nStart RStudio from the Rproject icon named Introduction to species distribution models.\nOpen the R script named Erebia stirius.\nWhen following this lab, continue to copy & paste the code in the script so it is organised as it is in teaching materials."
  },
  {
    "objectID": "posts/02_SDMs_env_covariates_terra.html#lab-plan",
    "href": "posts/02_SDMs_env_covariates_terra.html#lab-plan",
    "title": "OBTAINING, ASSESSING AND EXTRACTING ENVIRONMENTAL DATA",
    "section": "Lab plan",
    "text": "Lab plan"
  },
  {
    "objectID": "posts/02_SDMs_env_covariates_terra.html#environmental-data",
    "href": "posts/02_SDMs_env_covariates_terra.html#environmental-data",
    "title": "OBTAINING, ASSESSING AND EXTRACTING ENVIRONMENTAL DATA",
    "section": "Environmental data",
    "text": "Environmental data\n“For use in a distribution model, it is usual to reformat all environmental data to a raster grid. … Formatting all data to the same raster grid ensures that environmental data are available for every cell in which biological data have been recorded. These cells, containing both biological data and environmental data, are used to build the species’ distribution model”. (Pearson, 2010)\n\n\nQuick look at the raster data (in R)\nThere are three possible grid types in which raster files can be defined, of which squared grid is used most often.\n\n\n\nExample raster grids.\n\n\nResolution or scale is a property of raster, that defines the size of the grid cells. At lower resolutions, cells are bigger and precision of the raster is lower. At higher resolutions the cells are smaller and the precision is higher. The choice of resolution depends on the size of the area of our research (global, regional, local), species or phenomenon in question (large scale migrations vs. endemic, restricted species) and availability of data. The common grid sizes available today go from 10 arc minutes (~20 km)(i.e. worldclim) to 30x30 meters (landsat).\n\n\n\nRaster resolutions.\n\n\n\n\n\n\n\n\nImportant consideration\n\n\n\nWhat do we need to consider when we choose the grid of raster data for building species distribution models?\n\n\nRasters in R can be stored as:\n\na single layer (RasterLayer)\nmulti-layer raster brick - can only be linked to a single (multi-layer) file (RasterBrick)\nmulti-layer raster stack - can be formed from separate files and/or from a few layers (‘bands’) from a single file (RasterStack)\nany of the above as SpatRaster, “umbrella” data type in the terra package, which includes all the above data types from the raster package.\n\n\n\nPresent global environmental data\nFor this practice we will focus only on climatic data provided by WorldClim. WorldClim is a database of high spatial resolution global weather and climate data. These data can be used for mapping and spatial modeling. The data are provided for use in research and related activities.\nWorldClim - contains climatic and bioclimatic variables for:\n\npresent (resolution: 10 arc min; 5 min; 2.5 min; 30 arc-seconds = ~1 km)\nfuture - CMIP6 (we will use CMIP5) - (2050, 2070; resolution; 10 min; 5 min; 2,5 min; 30 arc-seconds = ~1 km)\npast (10 min; 5 min; 2.5 min)\n\nMid Holocene (6 KY);\nLGM (22 KY);\nLast inter-glacial (120-140 thousand years)\n\nit provides also the global Digital elevation model.\n\nBioclimatic variables are derived from the monthly temperature and rainfall values in order to generate more biologically meaningful variables. These are often used in species distribution modeling and related ecological modeling techniques. These bioclimatic variables represent\n\nannual trends (e.g., mean annual temperature, annual precipitation),\nseasonality (e.g., annual range in temperature and precipitation) and\nextreme or limiting environmental factors (e.g., temperature of the coldest and warmest month, and precipitation of the wet and dry quarters).\n\n\nThe variables in worldclim dataset follow nomenclature BIO1, BIO2, …, to BIO19 and actual environmental variables behind these codes are:\n\nBIO1 = Annual Mean Temperature\nBIO2 = Mean Diurnal Range (Mean of monthly (max temp ‐ min temp))\nBIO3 = Isothermality (P2/P7) (* 100)\nBIO4 = Temperature Seasonality (standard deviation *100)\nBIO5 = Max Temperature of Warmest Month\nBIO6 = Min Temperature of Coldest Month\nBIO7 = Temperature Annual Range (P5‐P6)\nBIO8 = Mean Temperature of Wettest Quarter\nBIO9 = Mean Temperature of Driest Quarter\nBIO10 = Mean Temperature of Warmest Quarter\nBIO11 = Mean Temperature of Coldest Quarter\nBIO12 = Annual Precipitation\nBIO13 = Precipitation of Wettest Month\nBIO14 = Precipitation of Driest Month\nBIO15 = Precipitation Seasonality (Coefficient of Variation)\nBIO16 = Precipitation of Wettest Quarter\nBIO17 = Precipitation of Driest Quarter\nBIO18 = Precipitation of Warmest Quarter\nBIO19 = Precipitation of Coldest Quarter\n\n\nWe access and download global bioclimatic variables with function geodata() from terra package. We assign dowloaded data to bioclim_data object. We will download the data at spatial resolution of 2.5 degrees (~4.8 km; res =). With var = \"bio\" we define that we want to download bioclimatic variables dataset.\nAs this dataset is roughly 650 MB big, it might take a while to download.\n\n# Download Bioclim variables\n# might take some time to download!!!\nlibrary(terra)\n\nbioclim_data &lt;- geodata::worldclim_global(var = \"bio\",\n                                          res = 2.5,\n                                          path = \"01_data\")\n\nThe dataset is of class SpatRaster, as there were 19 separate layers downloaded to your hard-drive and assigned to a single object:\n\nclass(bioclim_data) ; names(bioclim_data)\n\n[1] \"SpatRaster\"\nattr(,\"package\")\n[1] \"terra\"\n\n\n [1] \"wc2.1_2.5m_bio_1\"  \"wc2.1_2.5m_bio_2\"  \"wc2.1_2.5m_bio_3\" \n [4] \"wc2.1_2.5m_bio_4\"  \"wc2.1_2.5m_bio_5\"  \"wc2.1_2.5m_bio_6\" \n [7] \"wc2.1_2.5m_bio_7\"  \"wc2.1_2.5m_bio_8\"  \"wc2.1_2.5m_bio_9\" \n[10] \"wc2.1_2.5m_bio_10\" \"wc2.1_2.5m_bio_11\" \"wc2.1_2.5m_bio_12\"\n[13] \"wc2.1_2.5m_bio_13\" \"wc2.1_2.5m_bio_14\" \"wc2.1_2.5m_bio_15\"\n[16] \"wc2.1_2.5m_bio_16\" \"wc2.1_2.5m_bio_17\" \"wc2.1_2.5m_bio_18\"\n[19] \"wc2.1_2.5m_bio_19\"\n\n\nThe name of each variable starts with wc2.1_2.5m_ and ends with bio_x. The first part of the name tells us about the variable itself - wc2.1 means it come from WorldClim version 2.1 and 2.5m tells us it is in 2.5 arc minute resolution. The last part is the variable itself, bio for bioclimatic variables and x as the consecutive number of the variable in the list, going from 1 - 19.\n\nWe can simply visualise this data using the plot() function. As the terra package is loaded, it will know by default, that it needs to plot raster images and it will display all of the included layers (the default maximum is actually 16, so layers 17 - 19 are not displayed):\n\nplot(bioclim_data) \n\n\n\n\nTo visualize one layer from bioclim_data object we must use double square brackets [[]] with the number of the variable we want to extract (the variables BIO1 to BIO19 are arranged in increasing order from 1 - 19). If we use the number 19, we will plot the layer BIO19 = Precipitation of Coldest Quarter:\n\nplot(bioclim_data[[19]]) \n\n\n\n\n\n\n\n\n\n\nTask\n\n\n\nChange the number 19 in plot(bioclim_data[[19]]) and make individul plots for a couple of other bioclimatic variables. Consult the list above and try to understand how that variable is changing globally and why.\n\n\n\n\nCropping environmental layers to extents of species buffer\nThe stirius_buffer was created in Lab 1 and saved to stirius_buffer.RDS file in the 01_data folder of our project. Thus, we need to import it with readRDS() and reassign it to stirius_buffer object. As we will rely on terra throughout the lab, we will transform it straight away to SpatVector by terra:vect():\n\nstirius_buffer &lt;- terra::vect(readRDS(\"01_data/stirius_buffer.RDS\"))\n\nCropping is a bit complicated: we need to create a mask that will contain bioclim variables cropped or extracted from the entire bioclim_data only for the area of stirius_buffer. We do this with mask() function within which we set the cropped extent with crop() function - both are from raster package.\n\nbioclim_stirius &lt;- mask(crop(bioclim_data,\n                             stirius_buffer),\n                        stirius_buffer) \n\n\nLets check what were the results of the code above, by plotting the cropped layers:\n\nplot(bioclim_stirius)\n\n\n\nplot(bioclim_stirius[[19]])"
  },
  {
    "objectID": "posts/02_SDMs_env_covariates_terra.html#variable-selection-assessing-correlations-collinearity-among-environemntal-variables",
    "href": "posts/02_SDMs_env_covariates_terra.html#variable-selection-assessing-correlations-collinearity-among-environemntal-variables",
    "title": "OBTAINING, ASSESSING AND EXTRACTING ENVIRONMENTAL DATA",
    "section": "Variable selection: assessing correlations (collinearity) among environemntal variables",
    "text": "Variable selection: assessing correlations (collinearity) among environemntal variables\n\n\n\n\n\n\nWhat is collinearity and why should we address it?\n\n\n\n“If the underlying question in a study is which covariates are driving the response variable(s), then the biggest problem to overcome is often collinearity. Collinearity is the existence of correlation between covariates. Common examples are covariates like weight and length, or water depth and distance to the shoreline. If collinearity is ignored, one is likely to end up with a confusing statistical analysis in which nothing is significant, but where dropping one covariate can make the others significant, or even change the sign of estimated parameters.” (Zuur et al., 2010)\n\n\nCollinearity of environmental variables (correlation between pairs of variables higher than |0.7|) can be a problem when fitting models. It means that we are adding redundant information to models that can obscure the actually important variables and their effects. To address collinearity in our initial set of predictors we will use the function removeCollinearity() from the package virtualspecies. This function:\n\ncalculates the Pearson correlation factors between all pairs of variables (method = \"pearson\"),\ncreates the distance matrix based on these values,\nplots the hierarchical cluster according to distances between variables (plot = TRUE),\nhighlights the variables that are correlated at a specified threshold (multicollinearity.cutoff = 0.7).\n\nOur remaining task is to select one variable per each block (in red rectangles below), which will give us a subset of variables that are not strongly correlated.\n\n\n\n\n\n\nImportant consideration\n\n\n\nThis analysis provides us with statistical basis to reduce the number of variables that we will use for model building (Zuur et al., 2010; Irving et al., 2020). However, we need to use our knowledge on the ecology of our species of interest to select a final set of predictor variables that are not correlated and more importantly, that have biological/ecological meaning in explaining the distribution of selected species. We should be able to support the selection of our predictor variables with references or present good arguments for selecting each one.\n\n\n\ninstall.packages(\"virtualspecies\")\n\n\nvirtualspecies::removeCollinearity(bioclim_stirius, \n                                   plot = TRUE, \n                                   multicollinearity.cutoff = 0.7, \n                                   method = \"pearson\")\n\n\n\n\n[[1]]\n[1] \"wc2.1_2.5m_bio_1\"  \"wc2.1_2.5m_bio_5\"  \"wc2.1_2.5m_bio_6\" \n[4] \"wc2.1_2.5m_bio_9\"  \"wc2.1_2.5m_bio_10\" \"wc2.1_2.5m_bio_11\"\n\n[[2]]\n[1] \"wc2.1_2.5m_bio_2\" \"wc2.1_2.5m_bio_3\"\n\n[[3]]\n[1] \"wc2.1_2.5m_bio_4\" \"wc2.1_2.5m_bio_7\"\n\n[[4]]\n[1] \"wc2.1_2.5m_bio_8\"\n\n[[5]]\n[1] \"wc2.1_2.5m_bio_12\" \"wc2.1_2.5m_bio_13\" \"wc2.1_2.5m_bio_14\"\n[4] \"wc2.1_2.5m_bio_16\" \"wc2.1_2.5m_bio_17\" \"wc2.1_2.5m_bio_19\"\n\n[[6]]\n[1] \"wc2.1_2.5m_bio_15\"\n\n[[7]]\n[1] \"wc2.1_2.5m_bio_18\"\n\n\n\nReminder:\nErebia stirius or Stirian ringlet: butterfly species, endemic to the area between the SE Alps and the N Dinaric Alps, where it inhabits grassy, rocky slopes, between 700 and 1800 m. Caterpillars feed mainly on the grass species Sesleria caerulea.\n\nWe note that there are three variables alone inside the red rectangle. These are not highly correlated to any other, and can be selected without any additional statistical consideration:\n\nBIO8 = Mean Temperature of Wettest Quarter\nBIO15 = Precipitation Seasonality\nBIO18 = Precipitation of Warmest Quarter\n\nOur first decision is to select only one from the first big rectangle:\n\nBIO12 = Annual Precipitation\nBIO13 = Precipitation of Wettest Month\nBIO14 = Precipitation of Driest Month\nBIO16 = Precipitation of Wettest Quarter\nBIO17 = Precipitation of Driest Quarter (potentially influencing growth of grass species Sesleria caerulea?)\nBIO19 = Precipitation of Coldest Quarter\n\nand to select only one from the second big rectangle:\n\nBIO1 = Annual Mean Temperature\nBIO5 = Max Temperature of Warmest Month\nBIO6 = Min Temperature of Coldest Month (potentially inhibiting species occupying higher altitudes?)\nBIO9 = Mean Temperature of Driest Quarter\nBIO10 = Mean Temperature of Warmest Quarter\nBIO11 = Mean Temperature of Coldest Quarter\n\nAnd lastly between two pairs:\n\nBIO2 = Mean Diurnal Range (potentially influencing length of breeding season)\nBIO3 = Isothermality\n\nand\n\nBIO4 = Temperature Seasonality (potentially influencing length of breeding season)\nBIO7 = Temperature Annual Range\n\nWhen we have this final selection, we subset (retain) only the selected variables, that we will use for modelling.\n\nbioclim_stirius &lt;- subset(bioclim_stirius, \n                                  c(\"wc2.1_2.5m_bio_2\",\n                                    \"wc2.1_2.5m_bio_4\",\n                                    \"wc2.1_2.5m_bio_6\",\n                                    \"wc2.1_2.5m_bio_8\",\n                                    \"wc2.1_2.5m_bio_15\",\n                                    \"wc2.1_2.5m_bio_17\",\n                                    \"wc2.1_2.5m_bio_18\"))\n\nnames(bioclim_stirius) \n\n[1] \"wc2.1_2.5m_bio_2\"  \"wc2.1_2.5m_bio_4\"  \"wc2.1_2.5m_bio_6\" \n[4] \"wc2.1_2.5m_bio_8\"  \"wc2.1_2.5m_bio_15\" \"wc2.1_2.5m_bio_17\"\n[7] \"wc2.1_2.5m_bio_18\"\n\n\n\nLast step in the preparation of data is to extract the environmental values for each presence and pseudo-absence point (remember we stored them in stirius_pa.RDS in the first lab, with coordinates being in columns lon and lat. We extract values from raster files using extract() function. The first argument is the raster layer or layers, from which we want to extract. The second argument are the longitude and latitude coordinates of the points of interest. We will access them with dplyr::select() from stirius_pa. Extracted data will be stored temporarily in a new object stirius_pa_bioclim:\n\nstirius_pa &lt;- readRDS(\"01_data/stirius_pa.RDS\")\n\nstirius_pa_bioclim &lt;- extract(\n    bioclim_stirius,\n    dplyr::select(stirius_pa, lon, lat)\n)\n\nLastly, we will merge the environmental data with our presence - pseudo-absence dataset using cbind() function:\n\nstirius_pa &lt;- cbind(\n    stirius_pa,\n    stirius_pa_bioclim\n)\n\nhead(stirius_pa)\n\n          species      lat      lon presence ID wc2.1_2.5m_bio_2\n1 Erebia parmenio 45.95096 11.44143        0  1         7.052333\n2 Erebia parmenio 46.00191 14.06301        0  2         8.737666\n3 Erebia parmenio 46.91182 12.49829        0  3         7.005333\n4 Erebia parmenio 46.49978 13.67425        0  4         9.366000\n5 Erebia parmenio 46.48025 12.94345        0  5         8.426000\n6 Erebia parmenio 46.58441 14.02201        0  6        10.477333\n  wc2.1_2.5m_bio_4 wc2.1_2.5m_bio_6 wc2.1_2.5m_bio_8 wc2.1_2.5m_bio_15\n1         650.0859           -5.364        13.902666          45.91653\n2         701.4801           -5.088         4.383333          20.45457\n3         620.9182           -9.740         8.678666          30.58824\n4         692.6573           -7.992         5.906000          24.87869\n5         646.9081           -6.872        13.117333          30.09015\n6         791.2856           -6.952        17.753334          30.01317\n  wc2.1_2.5m_bio_17 wc2.1_2.5m_bio_18\n1                65               232\n2               408               495\n3               212               469\n4               262               478\n5               200               447\n6               168               374\n\n\nWe will also apply drop_na() function to the whole dataset, to remove all the pseudo-absence points that might have been generated on the sea, lakes or rivers (having environmental data equal to NA:\n\nlibrary(dplyr)\n\nstirius_pa &lt;- stirius_pa %&gt;% \n    tidyr::drop_na()"
  },
  {
    "objectID": "posts/02_SDMs_env_covariates_terra.html#export-the-data",
    "href": "posts/02_SDMs_env_covariates_terra.html#export-the-data",
    "title": "OBTAINING, ASSESSING AND EXTRACTING ENVIRONMENTAL DATA",
    "section": "Export the data",
    "text": "Export the data\nWe will export the final presence - pseudo absence dataframe, which now contains also the values at each location for associated environmental variables. We will export also the cropped environmental variables (bioclim_stirius), so they will be available to us in the following labs, when we will need it.\n\nsaveRDS(stirius_pa, \"01_data/stirius_pa_final.RDS\")\nsaveRDS(bioclim_stirius, \"01_data/bioclim_stirius.RDS\")"
  },
  {
    "objectID": "posts/02_SDMs_env_covariates_terra.html#assignment",
    "href": "posts/02_SDMs_env_covariates_terra.html#assignment",
    "title": "OBTAINING, ASSESSING AND EXTRACTING ENVIRONMENTAL DATA",
    "section": "Assignment",
    "text": "Assignment\n\n\n\n\n\n\nTask\n\n\n\n\nOpen R script that you named after the species you choose to work on.\nCopy - paste today's code from the Erebia stirius script to the end of your script.\nAdapt the code to achieve the following:\n\n3.1) crop the global bioclim_data to the extent of your species buffer (you will need to import the buffer, if you saved it in the previous lab or rerun the code above, to create it again),\n3.2) assess the collinearity between variables within the cropped area and select meaningful variables for further analysis,\n3.3) extract values for each location of your presence-pseudo absence dataset (you will need to import the dataset, if you saved it in the previous lab or rerun the code above, to create it again),\n3.4) export the final dataframe with extracted environmental data to the hard drive and also the cropped environmental variables,\n3.5) save the script with the code for your species,\n3.6) make sure that the project folder will be available to you next week at the labs (either store it on USB, cloud or similar, in case it gets deleted from computers)."
  },
  {
    "objectID": "posts/03_SDMs_Modeling_algorithms_and_model_building.html",
    "href": "posts/03_SDMs_Modeling_algorithms_and_model_building.html",
    "title": "MODELING ALGORITHMS AND MODEL FITTING",
    "section": "",
    "text": "Summary\n\n\n\nIn this lab you will:\n\nvisualise presences and pseudo absences along selected environmental variables,\nbe introduced to modelling algorithms,\nfit Generalised Linear Models and Random Forest models,\nselect the best model based on Akaike Information Criteria (AIC)."
  },
  {
    "objectID": "posts/03_SDMs_Modeling_algorithms_and_model_building.html#before-we-start",
    "href": "posts/03_SDMs_Modeling_algorithms_and_model_building.html#before-we-start",
    "title": "MODELING ALGORITHMS AND MODEL FITTING",
    "section": "Before we start",
    "text": "Before we start\n\n\n\n\n\n\nTask\n\n\n\n\nOpen the folder Introduction to species distribution models,\nStart RStudio from the Rproject icon named Introduction to species distribution models.\nOpen the R script named Erebia stirius.\nWhen following this lab, continue to copy & paste the code in the script so it is organised as it is in teaching materials."
  },
  {
    "objectID": "posts/03_SDMs_Modeling_algorithms_and_model_building.html#lab-plan",
    "href": "posts/03_SDMs_Modeling_algorithms_and_model_building.html#lab-plan",
    "title": "MODELING ALGORITHMS AND MODEL FITTING",
    "section": "Lab plan",
    "text": "Lab plan"
  },
  {
    "objectID": "posts/03_SDMs_Modeling_algorithms_and_model_building.html#visualise-stirius_pa_final-data",
    "href": "posts/03_SDMs_Modeling_algorithms_and_model_building.html#visualise-stirius_pa_final-data",
    "title": "MODELING ALGORITHMS AND MODEL FITTING",
    "section": "Visualise stirius_pa_final data",
    "text": "Visualise stirius_pa_final data\nFirst, we will load the data that we prepared in the last lab. The dataset is saved as .RDS files in 01_data folder. We will import it using readRDS() function and assign it to the objects with the same names as in lab 2: stirius_pa_final. This is a dataframe in which we prepared species presence points and pseudo-absence points and extracted values for environmental variables that are not highly correlated (bio2, bio4, bio6, bio 8, bio15, bio17 and bio18).\n\nstirius_pa_final &lt;- readRDS(\"01_data/stirius_pa_final.RDS\")\n\nThis is how our presence - pseudo-absences are distributed in geographical space. Note that pseudo-absences were generated randomly and they are very likely different on your computers.\n\n\n\n\n\n\n\nWe will first visualise, how presences (1) and pseudo-absences (0) are distributed along one environmental variable of choice (bio2):\n\nlibrary(ggplot2)\n\nggplot(stirius_pa_final, aes(x = wc2.1_2.5m_bio_2, y = presence)) +\n    geom_point() + \n    theme_classic()\n\n\n\n\nPresences and pseudo-absences along two environmental variables:\n\nggplot(stirius_pa_final, aes(x = wc2.1_2.5m_bio_2, \n                             y = wc2.1_2.5m_bio_4, \n                             col = as.factor(presence))) +\n    geom_point() + \n    theme_classic()\n\n\n\n\nPresences and pseudo-absences along three environmental variables:\n\ninstall.packages(\"scatterplot3d\")\n\n\nlibrary(\"scatterplot3d\")\n\n\ncolors &lt;- c(\"red\", \"blue\")\n\ncolors &lt;- colors[as.factor(stirius_pa_final$presence)]\n\nscatterplot3d(dplyr::select(stirius_pa_final, \n                            wc2.1_2.5m_bio_2,\n                            wc2.1_2.5m_bio_4,\n                            wc2.1_2.5m_bio_6,), \n              pch = 16, color = colors)\n\n\n\n\n\n\n\n\n\n\nTask\n\n\n\nModify the above code by changing the environmental variables along which presences - pseudo-absences are plotted. You need to change only the numbers at the end of wc2.1_2.5m_bio_x, but keep in mind, that not all numbers from 1 - 19 are available, but only those that were selected in the previous lab."
  },
  {
    "objectID": "posts/03_SDMs_Modeling_algorithms_and_model_building.html#modelling-algorithms",
    "href": "posts/03_SDMs_Modeling_algorithms_and_model_building.html#modelling-algorithms",
    "title": "MODELING ALGORITHMS AND MODEL FITTING",
    "section": "Modelling algorithms",
    "text": "Modelling algorithms\nRemember our introductory class and the questions for you:\n\nWhat is a model?\n\nHow do you understand / perceive the term model?\n\nAlgorithms for predicting/projecting the distribution of species in geographic space on the basis of a mathematical representation of their known distribution in environmental space.\nThe task of a modelling algorithm is to identify potentially complex non-linear relationships in multi-dimensional environmental space and project them to 2 dimensional geographic space (Pearson 2010). Simplified, the algorithms project:\n\nto areas of known distributional area,\nto parts of the actual distribution area, that is currently unknown but occupied,\nto areas that are currently not occupied.\n\nAdditionally, we need to acknowledge some degree of error in the algorithms ability to fit observed records, and thus expect the fourth projection:\n\nareas that are neither the actual nor the potential distribution of the species (Pearson 2010).\n\n\n\n\nTheoretical species distribution model projections.\n\n\nModeling algorithms will identify areas with similar environments to where the species has been observed. Most algorithms generally do not return the presence (1) or absence (0) of the species, but the probability or suitability for finding the species in any given cell on a map based on observed species-environment relationships.\n\nThere is plethora of different modelling algorithms used for modelling species/habitat distribution in the literature, that broadly belong to:\n\nstatistical (regression), i.e.:\n\nGeneralized Additive Models (GAM),\nGeneralized Linear Models (GLM),\nLasso and Elastic-Net Regularized Generalized Linear Models (GLMNET),\nMultivariate Adaptive Regression Splines (MARS),\nMixture Discriminant Analysis (MDA),\nFlexible Discriminant Analysis (FDA), etc.,\n\nmachine learning, i.e.:\n\nBoosted Regression Trees (BRT),\nClassification and Regression Trees (CART)\nMaximum Entropy (MAXENT)\nRandom Forests (RF),\nRecursive Partitioning and Regression Trees (RPART), etc.,\n\nartificial intelligence algorithms, i.e.:\n\nArtificial Neural Networks (ANN),\n\nSupport Vector Machines (SVM), etc.\n\n\nThese algorithms are implemented in multiple R packages, including: sdm, ENMTools, biomod2, ecospat, etc.\nThe modelling algorithm selection is based on multiple considerations, is not a straigthforward process and there are no simple answers (Pearson 2010):\n\ndata (presence only, presence - background, presence - (pseudo)absence)\naim of the study\n\nunderstanding which variables influence our species distribution?\nprediction accuracy to identify potential present distribution?\n\nprediction accuracy to extrapolation beyond the range of data used to build the model (past/future scenarios)?\n\n\nAdditionally, a developing approach is to create an ensemble of modeling algorithms - which essentially means applying multiple modeling algorithms to the data and “merge” the models together to project into present geographic space or new conditions (past / future).\nDue to high complexity of this field, we will only use the two following algorithms and just briefly address their main strengths and weaknesses:\n\nGeneralized Linear Models (GLM) and\nRandom Forests (RF)."
  },
  {
    "objectID": "posts/03_SDMs_Modeling_algorithms_and_model_building.html#generalised-linear-models-glm-guisan-et-al.-2017-p.-167",
    "href": "posts/03_SDMs_Modeling_algorithms_and_model_building.html#generalised-linear-models-glm-guisan-et-al.-2017-p.-167",
    "title": "MODELING ALGORITHMS AND MODEL FITTING",
    "section": "Generalised linear models (GLM; Guisan et al., 2017, p. 167)",
    "text": "Generalised linear models (GLM; Guisan et al., 2017, p. 167)\nThe family of presence-absence approaches is diverse and relies on different statistical principles. Among the many methods from this group we will create a model using the Generalized linear model (GLM) method. This is a regression-based approach which relates a response variable (in our case presence-absence) to a set of pre selected environmental predictors (in our case bioclimatic variables). The classical linear regression (ordinary least-square) is valid only when the response variable is normally distributed. GLMs represent a more flexible family of regression models, which allow the response variable to follow different exponential distributions (including binomial).\nADVANTAGES\n\nThe response variable can have any form of exponential distribution type (binomial in our case)\nAble to deal with categorical predictors\nRelatively easy to interpret and allows a clear understanding of how each of the predictors are influencing the outcome\nLess susceptible to overfitting\n\nLIMITATIONS\n\nNeeds relatively large datasets. The more predictor variables, the larger the sample size required. As a rule of thumb, the number of predictor variables should be less than number of presences divided by 10.\nSensitive to outliers\n\n\nA generalized linear model consists of a linear predictor:\n\\[\n\\begin{equation}\n\\ η_{i} = β_{0} + β_{1}x_{1i} + ... + β_{p}x_{pi}\n\\end{equation}\n\\]\nand a link function, that describes how response depends on the linear predictor:\n\\[\n\\begin{equation}\n\\ g(µ_{i}) = η_{i}\n\\end{equation}\n\\]\nWhen using GLM on binary data (0 and 1) a logistic function is most commonly used as a link function.\nThe process of model building can be forward or backward, sometimes also combining both strategies:\n\nforward building means starting with one predictor and adding one more in each round until full model (with all predictors)\nbackward building means starting with full model and removing predictors one by one until finding the best model.\n\n\n\nApplication of GLM to Erebia stirius dataset\nGeneralized linear models can be fitted in R using the glm() function that is included in base R. The main arguments to a glm() function are:\n\nformula,\nfamily = and\n\ndata.\n\nThe formula to glm is specified as y ∼ x1 + x2 … xi, where y is a response variable, x1, x2 to xi are the names of numeric vectors (continuous variables) or factors (categorical variables) - which are our predictor variables. All specified variables must be in the workspace or in the data frame passed to the data argument. The family argument takes the name of a family function which specifies the link function and the variance function. The exponential family functions available in R are:\n\nbinomial(link = “logit”)\ngaussian(link = “identity”)\nGamma(link = “inverse”)\ninverse.gaussian(link = “1/mu2”)\npoisson(link = “log”)\n\nThere are many other arguments (weights, subset, na.action, start = NULL, etastart, mustart, offset, control = glm.control(...), model = TRUE, method = ”glm.fit”, x = FALSE, y = TRUE, contrasts = NULL, ...) that we will not delve in, but with which we can calibrate our models to different specific situations.\nWe will do the model building as a backward process, starting by a full model. This model will include all possible environmental variables within our dataset and will be the most complex of all models. Within glm() function we specify:\n\npresence ~ bio2 + bio4 + bio8 + bio15 + bio17 + bio18 (presence explained by a linear combination of all bio variables),\nfamily = \"binomial\" (our response variable - presence - follows binomial distribution (0 and 1) and the model needs to take this into account)\ndata = stirius_pa_final (to tell the model, where to look for the data).\n\nWe will save the results of this call to an object named glm_full - “full” indicating that all possible variables are included in the model.\n\nglm_full &lt;- glm(presence ~ wc2.1_2.5m_bio_2 + wc2.1_2.5m_bio_4 + wc2.1_2.5m_bio_6 + wc2.1_2.5m_bio_8 + wc2.1_2.5m_bio_15 + wc2.1_2.5m_bio_17 + wc2.1_2.5m_bio_18, \n                # modeling presence with all env variables \n                family = \"binomial\", # using binomial distribution, and logistic function by default\n                data = stirius_pa_final) # variables and presence stored in stirius_pa_final\n\nWe explore the results of a generalised linear model using the summary() function, applied on the object in which we stored the model (glm_full):\n\nsummary(glm_full)\n\n\nCall:\nglm(formula = presence ~ wc2.1_2.5m_bio_2 + wc2.1_2.5m_bio_4 + \n    wc2.1_2.5m_bio_6 + wc2.1_2.5m_bio_8 + wc2.1_2.5m_bio_15 + \n    wc2.1_2.5m_bio_17 + wc2.1_2.5m_bio_18, family = \"binomial\", \n    data = stirius_pa_final)\n\nCoefficients:\n                    Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)       -2.4664717  3.5819782  -0.689 0.491089    \nwc2.1_2.5m_bio_2   0.2842938  0.2594362   1.096 0.273160    \nwc2.1_2.5m_bio_4   0.0004804  0.0062703   0.077 0.938925    \nwc2.1_2.5m_bio_6  -0.1024304  0.1081918  -0.947 0.343767    \nwc2.1_2.5m_bio_8  -0.2111851  0.0573542  -3.682 0.000231 ***\nwc2.1_2.5m_bio_15  0.0569347  0.0347636   1.638 0.101470    \nwc2.1_2.5m_bio_17  0.0043713  0.0044787   0.976 0.329057    \nwc2.1_2.5m_bio_18 -0.0032971  0.0032837  -1.004 0.315332    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 415.89  on 299  degrees of freedom\nResidual deviance: 366.14  on 292  degrees of freedom\nAIC: 382.14\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nInterpreting Coefficients, P-Values, Deviance and Akaike Information Criteria\nThe coefficient estimate (Estimate) in the output indicate the average change in the log odds of the response variable associated with a one unit increase in each predictor variable. For example, a one unit increase in the predictor variable bio2 is associated with an average change of -0.024 in the log odds of the response variable presence. This means that higher values of bio2 are associated with a lower likelihood of the presence variable taking on a value of 1.\nThe standard error gives us an idea of the variability associated with the coefficient estimate. The p-value (Pr(&gt;|z|)) tells us the probability associated with a particular z value. This essentially tells us how well each predictor variable is able to predict the value of the response variable in the model.\nFor example, the p-value associated with the bio2 variable is .931. Since this value is more than .05, we would say that bio2 is not statistically significant predictor variable in the model. Depending on our choice, we may decide to use a significance level of .01, .05, or 0.10 to determine whether or not each predictor variable is statistically significant. In this model, only bio8 is statistically significant (Pr(&gt;|z|) &lt; 0.05), while bio4 has the highest Pr(&gt;|z|) value (0.938), which means we can consider it as a candidate variable to exclude for the next model.\nThe null deviance in the output tells us how well the response variable can be predicted by a model with only an intercept term (meaning no predictors) and the residual deviance tells us how well the response variable can be predicted by the specific model that we fit with the selected predictor variables. The lower the value, the better the model is able to predict the value of the response variable.\nThe Akaike information criterion (AIC) is a metric that is used to compare the fit of different regression models. The actual value for the AIC is meaningless, however, when we compare two modely, the one with lower AIC value is considered to be better. However, if we fit several regression models, we can compare the AIC value of each model. The model with the lowest AIC offers the best fit, but we need to take into account the number of predictor variables in each (generally, the model who explains more/better with less variables should be selected).\n\nIn the next step, we will build a model from which we will remove the bio4 variable, that has the highest Pr(&gt;|z|) value in the full model and was not statistically significant for describing the response variable. We will save this model in a new object called glm_2\n\nglm_2 &lt;- glm(presence ~ wc2.1_2.5m_bio_2 + wc2.1_2.5m_bio_6 + wc2.1_2.5m_bio_8 + wc2.1_2.5m_bio_15 + wc2.1_2.5m_bio_17 + wc2.1_2.5m_bio_18,                 \n             family = \"binomial\", \n             data = stirius_pa_final)\n\nAnd explore the results of a generalised linear model using the summary() function, applied on the object in which we stored the model (glm_2):\n\nsummary(glm_2)\n\n\nCall:\nglm(formula = presence ~ wc2.1_2.5m_bio_2 + wc2.1_2.5m_bio_6 + \n    wc2.1_2.5m_bio_8 + wc2.1_2.5m_bio_15 + wc2.1_2.5m_bio_17 + \n    wc2.1_2.5m_bio_18, family = \"binomial\", data = stirius_pa_final)\n\nCoefficients:\n                   Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)       -2.268281   2.479203  -0.915 0.360232    \nwc2.1_2.5m_bio_2   0.299454   0.167966   1.783 0.074614 .  \nwc2.1_2.5m_bio_6  -0.100586   0.105489  -0.954 0.340324    \nwc2.1_2.5m_bio_8  -0.210032   0.055320  -3.797 0.000147 ***\nwc2.1_2.5m_bio_15  0.056761   0.034711   1.635 0.101996    \nwc2.1_2.5m_bio_17  0.004361   0.004475   0.975 0.329807    \nwc2.1_2.5m_bio_18 -0.003286   0.003280  -1.002 0.316441    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 415.89  on 299  degrees of freedom\nResidual deviance: 366.15  on 293  degrees of freedom\nAIC: 380.15\n\nNumber of Fisher Scoring iterations: 4\n\n\nIn this model, again only bio8 is statistically significant (Pr(&gt;|z|) &lt; 0.05), while bio6 has the highest Pr(&gt;|z|) value (0.340), which means we can consider it as a candidate variable to exclude for the next model.\n\nIn this step, we will build a model from which we will remove the bio6 variable, that had the highest Pr(&gt;|z|) value in the glm_2 and was not statistically significant. We will save this model in a new object called glm_3\n\nglm_3 &lt;- glm(presence ~ wc2.1_2.5m_bio_2 + wc2.1_2.5m_bio_8 + wc2.1_2.5m_bio_15 + wc2.1_2.5m_bio_17 + wc2.1_2.5m_bio_18, \n                family = \"binomial\", \n                data = stirius_pa_final)\n\nAnd explore the results of a generalised linear model using the summary() function, applied on the object in which we stored the model (glm_3):\n\nsummary(glm_3)\n\n\nCall:\nglm(formula = presence ~ wc2.1_2.5m_bio_2 + wc2.1_2.5m_bio_8 + \n    wc2.1_2.5m_bio_15 + wc2.1_2.5m_bio_17 + wc2.1_2.5m_bio_18, \n    family = \"binomial\", data = stirius_pa_final)\n\nCoefficients:\n                    Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)       -1.2466197  2.2081501  -0.565    0.572    \nwc2.1_2.5m_bio_2   0.2519153  0.1586856   1.588    0.112    \nwc2.1_2.5m_bio_8  -0.2361198  0.0482172  -4.897 9.73e-07 ***\nwc2.1_2.5m_bio_15  0.0534126  0.0339981   1.571    0.116    \nwc2.1_2.5m_bio_17  0.0014222  0.0032069   0.443    0.657    \nwc2.1_2.5m_bio_18 -0.0007011  0.0018268  -0.384    0.701    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 415.89  on 299  degrees of freedom\nResidual deviance: 367.06  on 294  degrees of freedom\nAIC: 379.06\n\nNumber of Fisher Scoring iterations: 4\n\n\nWe will drop also the bio18 variable and than conclude with modifying the model:\n\nglm_4 &lt;- glm(presence ~ wc2.1_2.5m_bio_2 + wc2.1_2.5m_bio_8 + wc2.1_2.5m_bio_15 + wc2.1_2.5m_bio_17, \n                family = \"binomial\", \n                data = stirius_pa_final)\n\nsummary(glm_4)\n\n\nCall:\nglm(formula = presence ~ wc2.1_2.5m_bio_2 + wc2.1_2.5m_bio_8 + \n    wc2.1_2.5m_bio_15 + wc2.1_2.5m_bio_17, family = \"binomial\", \n    data = stirius_pa_final)\n\nCoefficients:\n                    Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)       -1.3743378  2.1846465  -0.629    0.529    \nwc2.1_2.5m_bio_2   0.2540397  0.1588451   1.599    0.110    \nwc2.1_2.5m_bio_8  -0.2364715  0.0483321  -4.893 9.95e-07 ***\nwc2.1_2.5m_bio_15  0.0524598  0.0339204   1.547    0.122    \nwc2.1_2.5m_bio_17  0.0008035  0.0027555   0.292    0.771    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 415.89  on 299  degrees of freedom\nResidual deviance: 367.21  on 295  degrees of freedom\nAIC: 377.21\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nNow we’ve fit several GLM models, we can compare the AIC value of each model. The model with the lowest AIC generally offers the best fit.\nTo resolve a common question about AIC: What is considered a good AIC value?\nThe simple answer: There is no value for AIC that can be considered “good” or “bad” because we simply use AIC as a way to compare regression models. The model with the lowest AIC offers the best fit. The absolute value of the AIC value is not important. A rule of thumb is that models within 2 units of difference (ΔAIC) are considered as the best candidate models, while often ΔAIC ≤ 6 (maximum ≤ 10) is used for final model selection (Richards et al., 2011). Important consideration is also the number of explanatory (predictor) variables in candidate models, with simpler (parsimonious) models with the lowest number of predictors being better than models with higher number of predictor variables.\nWe extract the AIC value of the GLM models using AIC() function:\n\nAIC(glm_full)\n\n[1] 382.1426\n\nAIC(glm_2)\n\n[1] 380.1485\n\nAIC(glm_3)\n\n[1] 379.0642\n\nAIC(glm_4)\n\n[1] 377.2118\n\n\nHaving the lowest AIC and the lowest number of predictors, the glm_4 is the best candidate model among the four models we have created and will be used in the next lab to project the habitat suitability to geographic space."
  },
  {
    "objectID": "posts/03_SDMs_Modeling_algorithms_and_model_building.html#random-forest-rf-guisan-et-al.-2017-p.-203",
    "href": "posts/03_SDMs_Modeling_algorithms_and_model_building.html#random-forest-rf-guisan-et-al.-2017-p.-203",
    "title": "MODELING ALGORITHMS AND MODEL FITTING",
    "section": "Random forest (RF; Guisan et al., 2017, p. 203)",
    "text": "Random forest (RF; Guisan et al., 2017, p. 203)\nRandom forests or random decision forests are an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time. The method is relatively new, being defined and originally developed in 2001. Random forests are frequently used as “blackbox” models, as they generate reasonable predictions across a wide range of data while requiring little configuration. Random forests can be also used to rank the importance of variables in a regression or classification problem and are implemented in the R package randomForest.\nThe random forest model essentially represents an assembly of a selected number of decision trees, which are itself commonly used supervised classification algorithms. They are very popular for a few reasons:\n\nThey perform quite well on classification problems,\nthe decision path is relatively easy to interpret, and\nthe algorithm to build (train) them is fast and simple.\n\nA decision tree is a flowchart-like structure made of nodes and branches. At each node, a split on the data is performed based on one of the input features, generating two or more branches as output. More and more splits are made in the upcoming nodes and increasing numbers of branches are generated to partition the original data. This continues until a node is generated where all or almost all of the data belong to the same class and further splits — or branches — are no longer possible.\n\n\n\nFrom decision tree to a random forest.\n\n\nA nice explanation of decision tree to random forest model can be found here.\nADVANTAGES\n\nhigher accuracy than a single decision tree and other classifying/regression methods\noffer a way of averaging multiple deep decision trees to reduce variance\n\nLIMITATIONS\n\nlower interpretability within decision trees\nfollowing the paths of tens or hundreds of trees to confirm that the model has learned realistic information is very hard\n\n\nApplication of RF to Erebia stirius dataset\nThe random forest model can be fitted using randomForest() function from the randomForest package. A call to build a random forest needs the following arguments:\n\nformula,\ndata,\n\nwhile these are optional or predefined:\n\nimportance = TRUE,\nna.action = na.omit,\nntree =\nmtry =\nmaxnodes =, etc. …\n\nWe will build only a full random forest model that will include all possible environmental variables within our dataset. By default, the random forest will consist of 500 trees and will test random two variables at each split (mtry = sqrt(p); p = number of predictor variables). Within randomForest() function we specify:,\n\npresence ~ bio2 + bio4 + bio6 + bio8 + bio15 + bio17 + bio18 (presence explained by a linear combination of all bio variables),\ndata = stirius_pa_final (to tell the model, where to look for the data),\nimportance = TRUE (To assess importance of predictors in the model),\nna.action = na.omit (A function to specify the action to be taken if NAs are found - we will disregards NAs if present).\n\nWe will save the results of this call to an object named rf_full - “full” indicating that all possible variables are included in the model.\n\n\ninstall.packages(\"randomForest\")\n\n\nlibrary(randomForest)\n\n\nrf_full &lt;- randomForest(presence ~ wc2.1_2.5m_bio_2 + wc2.1_2.5m_bio_4 + wc2.1_2.5m_bio_6 + wc2.1_2.5m_bio_8 + wc2.1_2.5m_bio_15 + wc2.1_2.5m_bio_17 + wc2.1_2.5m_bio_18, \n                        data = stirius_pa_final,\n                        importance = TRUE,\n                        na.action = na.omit)\n\nWe can check the properties of our model, by typing the name of the object and running it:\n\nrf_full\n\n\nCall:\n randomForest(formula = presence ~ wc2.1_2.5m_bio_2 + wc2.1_2.5m_bio_4 +      wc2.1_2.5m_bio_6 + wc2.1_2.5m_bio_8 + wc2.1_2.5m_bio_15 +      wc2.1_2.5m_bio_17 + wc2.1_2.5m_bio_18, data = stirius_pa_final,      importance = TRUE, na.action = na.omit) \n               Type of random forest: regression\n                     Number of trees: 500\nNo. of variables tried at each split: 2\n\n          Mean of squared residuals: 0.1387778\n                    % Var explained: 44.49\n\n\nThe output first shows us the formula, by which model was built and the type of random forest that this model belongs to (regression - numerical response value) and we didn’t need to specify that. randomForest() function will perform nonlinear multiple regression as long as the response variable is numeric. It confirms, that 500 trees were built and that 2 variables were tried at each split.\nThe output provides us also the mean of squared residuals and % variance explained, both measures indicating how well the model fits the data. Residuals are a difference between prediction of the model and the actual value. In our example, 0.14 means that the model was wrong (deviation from either 0 or 1) by 14% on average.\nThe model calibration can be done by changing the ntree = and mtry = arguments and try to achieve smaller mean squared residuals or higher % variance explained.\n\nIf we want to understand which variables are important according to the model, we set the importance = TRUE as in the code above. Random forest regression will provide two numerical outputs for our variables:\n\ndecrease in mean square error (%IncMSE) and\nnode purity.\n\nPrediction error described as MSE is based on permuting out-of-bag sections of the data per individual tree and predictor, and the errors are then averaged. In the regression context, Node purity is the total decrease in residual sum of squares when splitting on a variable averaged over all trees (i.e. how well a predictor decreases variance). Of the two, MSE is a more reliable measure of variable importance that shows how much our model accuracy decreases, if we leave out each variable. With the varImpPlot() we can visualize the results:\n\nimportance(rf_full)\n\n                   %IncMSE IncNodePurity\nwc2.1_2.5m_bio_2  23.04826      7.416897\nwc2.1_2.5m_bio_4  26.54470      9.023660\nwc2.1_2.5m_bio_6  21.12047      6.833795\nwc2.1_2.5m_bio_8  32.74030     10.834862\nwc2.1_2.5m_bio_15 26.49183     12.619755\nwc2.1_2.5m_bio_17 27.11528     11.998633\nwc2.1_2.5m_bio_18 30.72778      9.866633\n\n\n\nvarImpPlot(rf_full)\n\n\n\n\nWe can see from the results that bio4 is the variable with lowest %IncMSE value, but its actual value is 23.9. That means that the accuracy of our model would drop by ~24% if we would leave this variable out. Based on this, we will not be removing any variables from our model.\n\nLastly, lets visualise some of the decision trees in our random forests. The tools for visualising them are not available in a formal R package on CRAN, but from a repository on github. For that we need to install devtools package first, and from it use the install_github() function to install araastat/reprtree package.\n\ninstall.packages(\"devtools\")\n\nlibrary(devtools)\n\ninstall_github('araastat/reprtree')\n\nAs always, we need to use library to access the function and plot them using plot.getTree() function. Within it we specify the random forest model, from which we want to plot the tree (rf_full), the number of nodes to display (depth = 4) and the consecutive number of tree to be shown (k = 500, 1 is the default).\n\nlibrary(reprtree)\n\nreprtree::plot.getTree(rf_full, depth = 4) # first\n\n\n\nreprtree::plot.getTree(rf_full, k = 500, depth = 4) # 500th\n\n\n\nreprtree::plot.getTree(rf_full, k = 333, depth = 4) # 333th\n\n\n\n\n\n\nTake home message\nIn terms of model building, calibration and assessment, it always comes down to some theory and/or logic behind the data. Do the top predictors make biological/ecological sense? If not, why?\nModeling is an iterative process. we can get a better idea about the predictive error of our models when we save some data for performance testing only and we can also try out other methods as well.\n“Rome was not built in one day, nor was any reliable model.”\n(Good & Hardin, 2012)"
  },
  {
    "objectID": "posts/03_SDMs_Modeling_algorithms_and_model_building.html#assignment",
    "href": "posts/03_SDMs_Modeling_algorithms_and_model_building.html#assignment",
    "title": "MODELING ALGORITHMS AND MODEL FITTING",
    "section": "Assignment",
    "text": "Assignment\n\n\n\n\n\n\nTask\n\n\n\n\nOpen R script that you named after the species you choose to work on.\nCopy - paste today's code from the Erebia stirius script to the end of your script.\nAdapt the code to achieve the following:\n\n3.1) visualise, how presences (1) and pseudo-absences (0) are distributed along one, two and three environmental variables,\n3.2) fit multiple Generalised Linear Models in a backward way. This means you start with all selected environmental variables and exclude step by step the ones that have the highest p-values.\n3.3) fit a Random Forest Model with all environmental variables.\n3.4) save the script with the code for your species,\n3.5) make sure that the project folder will be available to you next week at the labs (either store it on USB, cloud or similar, in case it gets deleted from computers)."
  },
  {
    "objectID": "posts/01_GIS_SI_Uvod_v_R_in_RStudio.html",
    "href": "posts/01_GIS_SI_Uvod_v_R_in_RStudio.html",
    "title": "UVOD V UPORABO PROGRAMSKEGA JEZIKA R KOT GIS",
    "section": "",
    "text": "Povzetek\n\n\n\nNa teh vajah boste:\n\nspoznali R in RStudio,\nuporabili R skript za tipkanje in izvajanje osnovnih ukazov,\nuporabili osnovne matematične in logične operatorje,\nspoznali osnonve tipe podatkov v R in osnovne podatkovne strukture: vektorje, tabele in sezname."
  },
  {
    "objectID": "posts/01_GIS_SI_Uvod_v_R_in_RStudio.html#nekaj-o-meni",
    "href": "posts/01_GIS_SI_Uvod_v_R_in_RStudio.html#nekaj-o-meni",
    "title": "UVOD V UPORABO PROGRAMSKEGA JEZIKA R KOT GIS",
    "section": "Nekaj o meni",
    "text": "Nekaj o meni\n\n\n\nTo sem jaz, pred približno 7 leti.\n\n\nVeč informacij tukaj ali tukaj ali tukaj.\nZ R-om se ukvarjam že več kot 7 let in ga uporabljam na dnevni bazi za namene raziskovanja in poučevanja (pri predmetih Sodobni pristopi v Varstveni biologiji, Geografski informacijski sistemi in vede, Ekologija kopenskih ekosistemov). Nekaj primerov uporabe spodaj:\nS to kodo:\n\ntimelineplot &lt;- ggplot(temporal_distribution, aes(x = Date, y = N, color = Gear)) +\n    geom_point(size = 4, alpha = 0.4) +\n    theme_classic() +\n    theme(axis.line.y=element_blank(), axis.text.y=element_blank(),\n          axis.title.x=element_blank(), axis.title.y=element_blank(),\n          axis.ticks.y=element_blank(), axis.text.x =element_blank(),\n          axis.ticks.x =element_blank(), axis.line.x =element_blank(),\n          legend.position=\"bottom\", legend.title = element_blank()) +\n    geom_hline(yintercept=0.05, color = \"black\", size=0.3) +\n    geom_segment(aes(y = N, yend = 0.05, xend = Date), \n                 color = \"grey\", size = 0.02) +\n    geom_text(data = month_df, aes(x=month_date_range,y = 0.04, label = month_format),\n              size = 3.5, vjust = 0.5, color = 'black', angle = 90) +\n    geom_text(data = year_df, aes(x = year_date_range, y = 0.058,\n                                  label = year_format, fontface=\"bold\"), \n              size = 3.5, color='black') \n\nSem naredil to:\n\nS to kodo:\n\nPPUE_plot &lt;- \n  ggplot(data = PPUEsummary,aes(x = Gear_Type, y = PPUE)) +\n  geom_point(aes(shape = Net_Type), size = 4,\n             position = position_dodge(width = 0.5)) +\n  scale_shape_manual(values = c(1, 19), \n                     labels = c(\"Control net\", \"Illuminated net\") )+\n  geom_errorbar(aes(group = Net_Type, ymin = PPUE - se, ymax = PPUE + se), \n                width = 0.05, \n                position = position_dodge(width = 0.5)) +\n  ylim(0, 110) +\n  ylab(\"Price per Unit Effort (EUR / 1000m * 12hrs)\") +\n  xlab(\"\") +\n  theme(panel.background = element_rect(fill = \"white\", colour = \"black\"),\n          strip.background = element_rect(fill = \"white\", colour = \"black\"),\n          legend.position = \"none\",\n          axis.title=element_text(size=10),\n          axis.text=element_text(size=10, color = \"black\"))\n\nSem naredil to:\n\nS to kodo (pozor na znak …, ki se pojavi večkrat):\n\n# ...\n\nmixed_model_level1 &lt;- glmer(presence ~ scale(BO_bathymean) + scale(BO21_tempmean_ss)+ scale(BO21_temprange_ss) + scale(BO21_tempmean_bdmean) + (1|Animal_ID), \n                            family = binomial(link=\"logit\"), \n                            data = wild.track_RSF)\n \npresent_level1 &lt;- predict(present_env_layers,\n                          mixed_model_level1,\n                          type = \"response\",\n                          re.form=~0)\n\npredictions_RCP26_2050_level1 &lt;- predict(future_RCP26_2050,\n                                         mixed_model_level1,\n                                         type = \"response\",\n                                         re.form=~0)\n\n# ...\n\nplot(present_level1, main = \"Present suitability L1\", zlim=c(0,1))\nplot(predictions_RCP26_2050_level1, main = \"Predicted suitability RCP26 2050 L1\", zlim=c(0,1))\n\n# ...\n\nSem naredil to:\n\nTudi ta dokument je narejen s pomočjo R-a in njegovih orodij ter je izvožen v html format."
  },
  {
    "objectID": "posts/01_GIS_SI_Uvod_v_R_in_RStudio.html#kaj-je-r-in-zakaj-bi-ga-vi-sploh-uporabljali",
    "href": "posts/01_GIS_SI_Uvod_v_R_in_RStudio.html#kaj-je-r-in-zakaj-bi-ga-vi-sploh-uporabljali",
    "title": "UVOD V UPORABO PROGRAMSKEGA JEZIKA R KOT GIS",
    "section": "Kaj je R in zakaj bi ga vi sploh uporabljali?",
    "text": "Kaj je R in zakaj bi ga vi sploh uporabljali?\nRazlog za to je preprost in je objavljen v sledečem članku.\n\n\n\nUporaba orodij, v katerih je za dosego rezultatov potrebno klikanje, kot npr. SPSS, se v preteklosti ni veliko spremenila. Nasprotno pa uporaba R-a v znanosti eksponentno narašča od 2005 2005.\n\n\n\nPrav tako pa boste do konca teh vaj znali dostopati do različnih podatkovnih zbirk, iz njih pridobiti podatke in jih prikazati na sledeče načine, vse z uporabo nekaj vrstic R kode:\n\n\n\n\n\n\n\n\n\n\n\nKaj je R in kaj so razlogi za njegovo vse širšo uporabo?\n\nR je sistem/programski jezik, ki sta ga ustvarila Ross Ihaka in Robert Gentleman leta 1995.\nIma mnogo zbirk funkcij za klasične in sodobne statistične analize in množico orodij za grafični prikaz podatkov.\nJe odprtokoden in brezplačen za uporabo.\nOmogoča izdelavo statičnih ali interaktivnih poročil/gradiv v obliki pdf, ppt, html dokumentov (spletnih strani, kot je tole gradivo)\nOmogoča ponovljivost. Kodo zapišemo in shranimo - ko se vrnemo čez eno leto, bo (zelo verjetno) še vedno naredila enako. Naši kolegi ali recenzenti lahko preverijo katere analize in kako smo jih naredili in ponovijo naše rezultate (osnova znanosti).\nJe izjemno razširljiv, nova orodja lahko razvijemo sami oziroma se razvijajo in objavljajo na dnevni bazi - CRAN, bioconductor!\nSkupnost uporabnikov je zelo odzivna, za vsak problem obstaja odgovor – google je naš prijatelj (how to …, error xyz in r) ali strokovni/programerski forumi (stackoverflow, stackexchange).\n\nZa mnoge je R eden od programskih jezikov, ki se jih je najlažje naučiti in uporabljati na dolgi rok, ampak je lahko zelo zahtevno in frustrirajoče na začetku. Vi ste med srečniki, da imate učitelja, ki vas bo neboleče uvedel v osnove R-a. 😉\n\nR deluje kot konzola v katero vpisujemo besedilo ali številke, pričakuje smiselne ukaze, ki jih “razume” in lahko takoj izvede. Drugače nam javi napako.\n\n\n\nKonzola osnovnega R-a.\n\n\nRStudio pa je programski vmesnik z integrirano R konzolo. Konzola znotraj RStudia omogoca dinamicno programiranje za razliko od samostojne konzole :\n\nKo vpišemo prve tri crke nam bo sam ponudil moznosti, da dokončamo izraz.\nVse vrste oklepajev samodejno zapre.\nS pritiskom na puščico 🠕 ali 🠗 se lahko premikamo navzgor ali navzdol po preteklih ukazih.\n\n\n\n\nRstudio s štirimi podokni.\n\n\n\n\n\n\n\n\nNaloga\n\n\n\nOdprite R Studio. Vmesnik izgleda nekako takole.\nOdprite novo R skripto s klikom na zavihek File, potem New file in izberete R script.\nShranite skripto na Namizje oziroma Desktop vašega računalnika in jo poimenujte Uvod v R.\n\n\n\n\n\n\n\n\nNamig\n\n\n\nTekom vaj dvignite ✋ kadarkoli se vam pojavi vprašanje. Bodite radovedni. Vsi se lahko iz tega nekaj naučimo!"
  },
  {
    "objectID": "posts/01_GIS_SI_Uvod_v_R_in_RStudio.html#osnovne-operacije-v-r-u",
    "href": "posts/01_GIS_SI_Uvod_v_R_in_RStudio.html#osnovne-operacije-v-r-u",
    "title": "UVOD V UPORABO PROGRAMSKEGA JEZIKA R KOT GIS",
    "section": "Osnovne operacije v R-u",
    "text": "Osnovne operacije v R-u\nNajosnovnejša funkcija, ki nam jo R omogoca je uporaba osnovnih aritmeticnih operacij:\n\n\n\n\n\nOperator\nDescription\nPomen\n\n\n\n\n+\nAddition\nSeštevanje\n\n\n-\nSubstraction\nOdštevanje\n\n\n*\nMultiplication\nMnoženje\n\n\n/\nDivision\nDeljenje\n\n\nsqrt()\nSquare root\nKvadratni koren\n\n\n^\nTo the power (Alt GR & 3)\nPotenciranje (Alt GR & 3)\n\n\n\n\n\n\n\n\n\n\n\nNaloga\n\n\n\nV desnem zgornjem kotu polja s kodo je ikona, ki omogoča kopiranje ukazov znotraj tega polja. Kopirajte in prilepite spodnje račune v R skripto. Premaknite kurzor v prvo vrstico s kodo in kliknite Run. Premikajte se navzdol po vrsticah z ukazi in izvedite vsakega od njih.\nNamesto klikanja na gumb Run lahko uporabite tudi bližnjico na tipkovnici: Ctrl + Enter.\nKo zaključite s primeri iz gradiv, natipkajte v skripto iz izvedite še minimalno 10 svojih primerov računskih operacij.\n\n\n\n3 + 5\n\n8 - 9\n\n7 * 7\n\n42 / 6\n\n5 ^ 5\n\n9 ^ (1/2) # kvadratni koren\n\n\n\n\n\n\n\nNamig\n\n\n\nZadnja vrstica kode je poleg računske operacije vključevala tudi znak “hashtag” (#). Le-ta nam omogoča, da posamezne dele svoje kode pokomentiramo, R konzola pa ve, da to ni del kode oziroma ukazov in ga ignorira.\nKomentarji so zelo uporabni, saj ljudje radi pozabljamo. Ko se vrnemo k svojim skriptam čez nekaj (mnogo) časa, nas prijazno opomnijo, kaj smo s posamezno kodo / ukazom želeli narediti.\n\n\n\nNaslednja stvar, ki jo bomo uporabili, so logični operatorji. Potrebovali jih bomo za filtriranje podatkov iz stolpcev ali vrstic na naslednjih vajah:\n\n\n\n\n\n\nOperator\nDescription\nPomen\n\n\n\n\n&lt;\nLess than\nManj kot\n\n\n&lt;=\nLess than or equal to\nManj kot ali enako\n\n\n&gt;\nGreater than\nVeč kot\n\n\n&gt;=\nGreater than or equal to\nVeč kot ali enako\n\n\n==\nExactly equal to\nNatančno enako kot\n\n\n!=\nNot equal to\nNi enako kot\n\n\nx | y\nOr (Alt GR & w)\nAli (Alt GR & w)\n\n\nx & y\nAnd\nIn\n\n\n\n\n\n\n\n\n\n\n\nNaloga\n\n\n\nV desnem zgornjem kotu polja s kodo je ikona, ki omogoča kopiranje ukazov znotraj tega polja. Kopirajte in prilepite spodnje račune v R skripto. Premaknite kurzor v prvo vrstico s kodo in kliknite Run. Premikajte se navzdol po vrsticah z ukazi in izvedite vsakega od njih.\nNamesto klikanja na gumb Run lahko uporabite tudi bližnjico na tipkovnici: sočasno pritisnete na Ctrl in Enter.\nKo zaključite s primeri iz gradiv, natipkajte v skripto iz izvedite še minimalno 10 svojih primerov računskih operacij.\n\n\n\n3 &lt; 5\n\n8 &lt;= 9\n\n7 &gt; 7\n\n42 &gt;= 6\n\n5 == 5\n\n10 != 1"
  },
  {
    "objectID": "posts/01_GIS_SI_Uvod_v_R_in_RStudio.html#partly-funded-by-eu-erasmus-programme-for-higher-education-staff-mobility.",
    "href": "posts/01_GIS_SI_Uvod_v_R_in_RStudio.html#partly-funded-by-eu-erasmus-programme-for-higher-education-staff-mobility.",
    "title": "UVOD V UPORABO PROGRAMSKEGA JEZIKA R KOT GIS",
    "section": "",
    "text": "Partly funded by EU Erasmus+ Programme for Higher Education Staff Mobility"
  },
  {
    "objectID": "posts/01_GIS_SI_Uvod_v_R_in_RStudio.html#podatkovne-strukture-vektorji-tabele-in-seznami",
    "href": "posts/01_GIS_SI_Uvod_v_R_in_RStudio.html#podatkovne-strukture-vektorji-tabele-in-seznami",
    "title": "UVOD V UPORABO PROGRAMSKEGA JEZIKA R KOT GIS",
    "section": "Podatkovne strukture: vektorji, tabele in seznami",
    "text": "Podatkovne strukture: vektorji, tabele in seznami\nV R je na voljo mnogo razlicnih podatkovnih struktur. Za nas so pomembni: vektor (vector), tabela (data frame), seznami (list) in razlicne oblike prostorskih podatkovnih struktur za vektorske in rastrske podatke.\n\nS tem, ko ste zgoraj dodelili vrednosti razlicnim objektom, ste dejansko že ustvarili vektorje. Ti vektorji so vsebujejo le en element - število, ki ste jim ga dodelili. Osnovna lastnost vektorja je, da vsebujeje elemente enega tipa:\n\nštevilske vrednosti (numeric; za decimalna števila mora ločilo vedno biti pika),\nlogične vrednosti (logical; TRUE, FALSE - vedno pisano z velikimi tiskanimi),\nbesede (character; uporabiti moramo ” “, da R ve, da so to besede ne imena objektov),\ncelostevilske vrednosti (integer; vkljucuje le cela stevila).\n\nPosebna oblika elementa so manjkajoce vrednosti (NA), edini podatkovni tip, ki ga lahko vkljucimo v druge oblike vektorjev.\nPosebna oblika besednega vektorja je faktorski vektor. Zanj je značilno, da posamezen element vektorja predstavlja eno kategorijo v podatkih (npr. moški ali ženski spol). Na pogled sta vektorja enaka, razlika je v tem, kako jih R obravnava.\nVektorje ustvarimo s funkcijo c(). V kolikor v vektor vključimo elemente, ki ne pripadajo istemu podatkovnemu tipu, bo R vektor spremenil tako, da bo pretvoril podatke v isti tip - tistega, ki je najosnovnejši (besedni &lt; številski &lt; logični).\n\n\n\n\n\n\nNaloga\n\n\n\nKopirajte in prilepite spodnje račune v R skripto. Premaknite kurzor v prvo vrstico s kodo in kliknite Run. Premikajte se navzdol po vrsticah z ukazi in izvedite vsakega od njih.\n\n\n\nstevilski_vektor &lt;- c(1, 2, NA, 4)\n\nlogicni_vektor &lt;- c(TRUE, TRUE, FALSE, FALSE) # obvezno velike tiskane crke\n\nbesedni_vektor &lt;- c(\"R\", \"je\", \"res\", \"cudovito\", \"orodje!\")\n\nmesani_vektor &lt;- c(\"R\", NA, 1, TRUE)\n\n\n\n\n\n\n\nNote\n\n\n\nIf a vector contains elements that belong to different types, it will coerce the entire vector to the lowest common type. An example is the mixed_vector, for which you will see shortly that all elements were converted to characters.\n\n\nS funkcijo class(). preverimo kateri tip vektorja smo ustvarili, s funkcijo length() pa koliko elementov vsebuje:\n\nlength(stevilski_vektor)\nclass(stevilski_vektor) \n\nlength(mesani_vektor) \nclass(mesani_vektor)\n\n\nNaloga 2\nUstvarite 3 vektorje:\n\nbesedni vektor, ki vsebuje vase ime in imena treh vasih sosolcev in shranite v nov objekt, ki ga bomo poimenovali imena_sosolcev. Vsako posamezno besedo vpisite znotraj posameznega para narekovajev, tako da zamenjate ___.\nstevilski vektor, ki vsebuje vaso in starosti treh vasih sosolcev in shranite v nov objekt, ki ga bomo poimenovali starost. Vsako posamezno stevilo vnesite v pripravljene oklepaje, tako da zamenjate ___, vrstni red starosti naj ustreza osebam iz prvega vektorja.\nlogicni vektor, ki ga bomo poimenovali barva_oci, vsebuje pa naj vrednosti TRUE in FALSE, skladno s tem ali ima oseba iz vektorja imena enako barvo oci kot vi (TRUE) ali ne (FALSE).\n\n\nimena_sosolcev &lt;- c(\"___\", \"___\", \"___\", \"___\") \n\nstarost &lt;- c(___, ___, ___, ___)\n\nbarva_oci &lt;- c(___, ___, ___, ___)\n\n\n\nPrimer vektorjev z geografskimi podatki\n\nime_mesta &lt;- c(\"Ljubljana\", \"Maribor\", \"Koper\", \"Kranjska Gora\", \"Novo mesto\")\ngeografska_sirina &lt;- c(46.047766, 46.550613, 45.547377,  46.4887160, 45.802626)\ngeografska_dolzina &lt;- c(14.507420, 15.645263, 13.730270,  13.787491, 15.164192)\nprebivalstvo &lt;- c(279631, 94370, 25753, 1452, 24183)\n\n\n\n\nTabele (data frames)\nTabela je v osnovi vec vektorjev, ki jih zdruzimo, tako da vsak predstavlja en stolpec v novoustvarjeni tabeli. Tabele so najpogostejsi in najpogosteje uporabljen podatkovni tip. Navadno jih v R uvozimo iz diska nasih racunalnikov, mi pa si bomo se prej pogledali, kako jih ustvarimo rocno. Ustvarili bomo stiri vektorje, ime, geografska_sirina in geografska dolzina ter prebivalstvo, ki jih bomo s funkcijo data.frame() povezali v tabelo.\n\nmesta &lt;- data.frame(ime_mesta, geografska_dolzina, geografska_sirina, prebivalstvo)\n\nPri delu s prostorskimi podatki v R-u je nujno, da so koordinate zapisane kot decimalne stopinje, brez znaka za stopinje (°). Pomembno je tudi poznavanje referencnega koordinatnega sistema (Coordinate Reference System - CRS), kadar tabelo spreminjamo v katerega od prostorskih podtkovnih tipov.\n\nPodobno kot vektorji imajo tudi tabele svoje lastnosti. Preverimo lahko koliko vrstic (nrow()) ali stolpcev (ncol()) ima tabela, ali preprosto preverimo njene dimenzije (dim()). Lahko pogledamo (in spremenimo) tudi imena stolpcev nase tabele (names()). S funkcijo str() pogledamo, kakšna je struktura naša tabele in kakšen tip podatkov podatkov je v posameznem stolpcu (chr - besedni, num - stevilski). Funkcija summary pa nam prikaze lastnosti posameznega stolpca - za stolpce s stevili izvemo npr. minimalno, maksimalno, srednjo vrednost.\n\nclass(mesta)\n\n[1] \"data.frame\"\n\nnrow(mesta)\n\n[1] 5\n\nncol(mesta)\n\n[1] 4\n\ndim(mesta)\n\n[1] 5 4\n\nnames(mesta)\n\n[1] \"ime_mesta\"          \"geografska_dolzina\" \"geografska_sirina\" \n[4] \"prebivalstvo\"      \n\nstr(mesta)\n\n'data.frame':   5 obs. of  4 variables:\n $ ime_mesta         : chr  \"Ljubljana\" \"Maribor\" \"Koper\" \"Kranjska Gora\" ...\n $ geografska_dolzina: num  14.5 15.6 13.7 13.8 15.2\n $ geografska_sirina : num  46 46.6 45.5 46.5 45.8\n $ prebivalstvo      : num  279631 94370 25753 1452 24183\n\nsummary(mesta)\n\n  ime_mesta         geografska_dolzina geografska_sirina  prebivalstvo   \n Length:5           Min.   :13.73      Min.   :45.55     Min.   :  1452  \n Class :character   1st Qu.:13.79      1st Qu.:45.80     1st Qu.: 24183  \n Mode  :character   Median :14.51      Median :46.05     Median : 25753  \n                    Mean   :14.57      Mean   :46.09     Mean   : 85078  \n                    3rd Qu.:15.16      3rd Qu.:46.49     3rd Qu.: 94370  \n                    Max.   :15.65      Max.   :46.55     Max.   :279631  \n\n\n\n\nNaloga 3\nIzberite si stiri poljubna mesta v Sloveniji, ki niso na zgornjem seznamu, in:\n\nvpisite njihova imena v vektor ime_1, tako da namesto ___ znotraj \" \" napisete ime mesta. Ko vpisete vsa mesta, kliknite run, da ustvarite vektor ime_1.\npoiscite njihove koordinate na google zemljevidih, in jih dodajte v vektorja geografska_sirina_1 in geografska_dolzina_1 tako da namesto ___ vpisete ustrezno stevilo (koordinate morajo biti v obliki decimalnih stopinj!!). Bodite pozorni, da koordinate mest vpisujete v enakem vrstnem redu, kot ste vpisali mesta v prejsnjem koraku. Ko vpisete vse koordinate, kliknite run, da posodobite vektorja.\nzdruzite vektorje iz prejsnje naloge (imena, starost, barva_oci) in vektorje iz prejsnjih alinej v tabelo, ki bo shranjena v objektu sosolci, tako da namesto ___, vpisete imena objektov:\n\n\nime_1 &lt;- c(\"___\", \"___\", \"___\", \"___\")\n\ngeografska_sirina_1 &lt;- c(___, ___, ___, ___)\n\ngeografska_dolzina_1 &lt;- c(___, ___, ___, ___)\n\nsosolci &lt;- data.frame(___, ___, ___, ___, ___, ___)\n\nclass(sosolci)\n\n\n\nOn the whiteboard I will write a couple of our names, year of birth and hair colour. As some might feel uncomfortable with sharing this information, we will replace that with NAs instead.\nType these values into script and assign them to vectors. Bind these vector to a dataframe called best_class_ever. Check the properties of our table with functions presented above. Compare if you inserted the values correctly based on the values on the whiteboard.\n\n\nLists are objects which can contain elements of different types like numbers, character strings (= words), vectors, dataframes and even other lists. List is created by using list() function and typing object names within the parenthesis. Lists are complex data structures, that are suitable for advanced use as they offer high degree of flexibility. Below code gives an example list, that contains all types of objects listed above.\n\nCopy and paste below code in the R script, move cursor to the first row with code and click Run. Move cursor to each row that contains code and repeat.\n\n\n# example_list &lt;- list(1,\n#                      \"Pula, Croatia\",\n#                      mixed_vector,\n#                      example_data_frame,\n#                      list(1,\n#                           \"Pula, Croatia\",\n#                           mixed_vector,\n#                           example_data_frame))\n# \n# example_list\n\n\nSave the R script to the desktop of your computer.\nWhen you close R studio, select Yes when it asks if you want to save your work-space.\n\n\nQuestions to consider:\n\nWhat defines an R vector and which basic vector types there are?\nHow are R vectors and R dataframes connected?\nWhat are some functions that allow us to explore the properties of vectors and dataframes in terms of number of elements, rows columns etc.?\nWhat are R lists?\n\nDo you have any questions?\n\n\n\nTake home message\nR is a language and learning it is similar to learning a foreign language. It takes time and patience. The good thing is that there are only two really important thing to grasp at the beginning: what is an object and a function, and how these two interact: a function (usualy predefined by R developers) is applied to an object (which has a given name, usualy by us) and we expect something to happen as a result. Note that you used several function on several objects today (i.e. functions c(), data.frame(), names() etc., on objects character_vector, heigth, best_class_ever etc.). This is the essence of working with R and most of the time you will be doing just that, function(object) and get what you wanted or get:\n\nfunction(object)\n\nError: &lt;text&gt;:2:0: unexpected end of input\n1: function(object)\n   ^"
  },
  {
    "objectID": "posts/01_GIS_SI_Uvod_v_R_in_RStudio.html#objekti-v-r-u",
    "href": "posts/01_GIS_SI_Uvod_v_R_in_RStudio.html#objekti-v-r-u",
    "title": "UVOD V UPORABO PROGRAMSKEGA JEZIKA R KOT GIS",
    "section": "Objekti v R-u",
    "text": "Objekti v R-u\nKljučno pri delu z R-om je shranjevanje podatkov v objekte, da do njih lahko dostopamo in jih ne rabimo vpisovati večkrat. Za to uporabimo operator za shranjevanje: &lt;-. Vrednost na desni strani operatorja bo dodeljena imenu na levi. Za ime lahko uporabimo (skoraj) karkoli. Ko uporabimo ta operator se v konzoli ne bo zgodilo nič, ime našega objekta pa se bo pojavilo v R-ovem delovnem okolju. Bližnjica za operator: sočasno pritisnete na ALT in -. Če zelimo videti vsebino posameznega objekta, njegovo ime v skripto in kliknemo na gumb Run.\n\n\n\n\n\n\nNaloga\n\n\n\nKopirajte in prilepite spodnje račune v R skripto. Premaknite kurzor v prvo vrstico s kodo in kliknite Run. Premikajte se navzdol po vrsticah z ukazi in izvedite vsakega od njih.\nKaj se je zgodilo, ko ste zagnali posamezno vrstico?\n\n\n\nkvadratni_koren_9 &lt;- 9 ^ (1/2) \n\nkvadratni_koren_9 \n\n[1] 3\n\nKvadratni_koren_9 \n\nError in eval(expr, envir, enclos): object 'Kvadratni_koren_9' not found\n\nkvadratni_koren_devet\n\nError in eval(expr, envir, enclos): object 'kvadratni_koren_devet' not found\n\n\n\n\n\n\n\n\nPozor\n\n\n\nR zahteva, da smo s svojimi ukazi (kodo) dobesedno natančni. Tipkarske napake so pomembne. Velike - male črke so pomembne!!. 99% napak na začetku uporabe so rezultat površnosti pri tipkanju ukazov!!\nNaslednjič ko naletite na napako: object ‘…’ not found, to navadno pomeni, da ukaza niste pravilno natipkali (napačno ime objekta) ali pa tega objekta še niste ustvarili (ga ni na seznamu R Global Environment).\n\n\n\n\n\n\n\n\nNamig\n\n\n\nKako se izogniti tem težavam:\nUporabite funkcijo samodejnega zaključevanje ukazov, ki ga omogoča RSudio. Ko natipkamo tri znake, nam ponudu opcije, ki se s temi znaki začnejo. S klikom na eno od njih se bo naša ukaz zaključil, mi pa s tem zmanjšamo možnost tipkarskih napak.\n\n\n\n\n\n\n\n\nNaloga\n\n\n\nV R skripto natipkajte 10 naključnih imen (besed) in vsaki besedi dodelite število ali rezultat poljubnega izračuna (kot primer zgoraj). Zaženite vsako od teh vrstic s klikom na Run. Pričakovani rezultat je 10 novih imen v vašem R Global Environment.\nPoskusite uporabiti opcijo samodejnega zaključevanja ukazov in natipkajte teh 10 imen v skripto. Zaženite vsako od teh vrstih s klikom na Run. Pričakovani rezultat je 10 imen izpisanih v vaši R Console skupaj z njihovimi dodeljenimi vrednostmi.\n\n\n\nVprašanja v razmislek:\n\nKaj so najosnovnejše stvari, za katere lahko uporabimo R?\nKaj je objekt v R-u in od kod dobi svoje ime?\nKako lahko preverimo, kaj vsebuje R objekt?\n\nAli imate vi kakšna vprašanja?"
  },
  {
    "objectID": "posts/01_GIS_SI_Uvod_v_R_in_RStudio.html#tipi-podatkov-in-podatkovnih-struktur",
    "href": "posts/01_GIS_SI_Uvod_v_R_in_RStudio.html#tipi-podatkov-in-podatkovnih-struktur",
    "title": "UVOD V UPORABO PROGRAMSKEGA JEZIKA R KOT GIS",
    "section": "Tipi podatkov in podatkovnih struktur",
    "text": "Tipi podatkov in podatkovnih struktur\nOsnovni tipi podatkov v R-u so:\n\nštevilske vrednosti (numeric; za decimalna števila mora ločilo vedno biti pika),\nlogične vrednosti (logical; TRUE, FALSE - vedno pisano z velikimi tiskanimi),\nbesede (character; uporabiti moramo \" \", da R ve, da so to besede ne imena objektov),\nceloštevilske vrednosti (integer; vključujejo le cela števila).\nin manjkajoče vrednosti (NA).\n\nV R-u obstaja mnogo različnih podatkovnih struktur. Za vas je pomembno poznavanje vektorjev (vector), tabel (data frame) in seznamov (list), spoznali pa boste tudi nekaj struktur za prostorske podatke, tako za vektorske kot tudi rastrske podatke.\n\n\nVektorji (vectors)\nOsnovna lastnost vektorja je, da vsebujeje elemente enega tipa. Edini podatkovni tip, ki je lahko drugačen od ostalih so manjkajoče vrednosti (NA). S tem ko ste zgoraj dodelili vrednosti različnim objektom, ste že ustvarili vektorje. Ti vektorji so vsebujejo le en element - število, ki ste jim ga dodelili.\nVektorje z več elementi ustvarimo s funkcijo c(), kjer znotraj oklepajev natipkamo vrednosti, ki jih ločimo z vejico. V kolikor v vektor vključimo elemente, ki ne pripadajo istemu podatkovnemu tipu, bo R vektor spremenil tako, da bo obravnaval vse elemente kot isti podatkovni tip - tisti, ki je najosnovnejši (besedni &lt; številski &lt; logični). Mi bomo ustvarili vektorje z besedami, logični vrednostmi in s števili ter enega z vsemi podatkovnimi tipi. Vsakega bomo smiselno poimenovali:\n\n\n\n\n\n\nNaloga\n\n\n\nKopirajte in prilepite spodnje ukaze v R skripto. Premaknite kurzor v prvo vrstico s kopirano kodo in kliknite Run. Premikajte se navzdol po vrsticah z ukazi in izvedite vsakega od njih. Pričakovan rezultat so štiri nova imena v vašem R Global Environment.\n\n\n\nstevilski_vektor &lt;- c(1, 2, NA, 4)\n\nlogicni_vektor &lt;- c(TRUE, TRUE, FALSE, FALSE) # obvezno velike tiskane crke\n\nbesedni_vektor &lt;- c(\"R\", \"je\", \"res\", \"cudovito\", \"orodje!\")\n\nmesani_vektor &lt;- c(\"R\", NA, 1, TRUE)\n\nS funkcijo class() znotraj katere natipkamo ime vektorja, preverimo kateri podatkovni tip vektorja smo ustvarili, s funkcijo length() pa koliko elementov vsebuje:\n\nclass(stevilski_vektor) \nclass(logicni_vektor)\nclass(besedni_vektor)\nclass(mesani_vektor)\n\nlength(stevilski_vektor)\nlength(logicni_vektor)\nlength(besedni_vektor)\nlength(mesani_vektor) \n\n\n\n\n\n\n\nPomembno\n\n\n\nČe vektor vsebuje elemente različnih podatkovnih tipov, bo tip vektorja spremenjen v najosnovnejši tip. Primer za to je mesani_vektor, v katerem so bili vsi elementi spremenjeni v besede (character).\n\n\n\n\nPrimer vektorjev z geografskimi podatki\nUstvarili bomo še pet vektorjev:\n\nime_mesta bo vsebovalo imena slovenskih mest,\ngeografska_sirina in geografska dolzina bosta vsebovala GPS koordinate teh mest,\nprebivalstvo bo vsebovalo število prebivalcev teh mest,\nvektor primorska pa nam bo povedal, če mesto leži v primorski regiji (TRUE) ali ne (FALSE):\n\n\nime_mesta &lt;- c(\"Ljubljana\", \"Maribor\", \"Koper\", \"Kranjska Gora\", \"Novo mesto\")\n\ngeografska_sirina &lt;- c(46.047766, 46.550613, 45.547377,  46.4887160, 45.802626)\n\ngeografska_dolzina &lt;- c(14.507420, 15.645263, 13.730270,  13.787491, 15.164192)\n\nprebivalstvo &lt;- c(279631, 94370, 25753, 1452, 24183)\n\nprimorska &lt;- c(FALSE, FALSE, TRUE, FALSE, FALSE)\n\n\n\n\n\n\n\nNaloga\n\n\n\nKopirajte spodnje ukaze v svoje skripte in dopolnite, tako da ustrezno zamenjate ___:\n\nustvarite besedni vektor, ki vsebuje vaše ime in imena treh vaših sošolcev. Nov objekt bomo poimenovali imena_sosolcev. Vsako posamezno ime vpišite znotraj posameznega para narekovajev, tako da zamenjate ___.\nustvarite številski vektor, ki vsebuje vašo in starosti treh vasih sošolcev. Vsako posamezno število vnesite v pripravljene oklepaje, tako da zamenjate ___, vrstni red starosti naj ustreza imenom oseb iz prvega vektorja. Nov objekt bomo poimenovali starost.\n\nlogični vektor, ki ga bomo poimenovali barva_oci, vsebuje pa naj vrednosti TRUE in FALSE, skladno s tem ali ima oseba iz vektorja imena_sosolcev enako barvo oci kot vi (TRUE) ali ne (FALSE).\nbesedni vektor, ki bo vseboval imena domačih krajev - krajev od koder prihajate vi in izbrani trije sošolci. Poimenovali ga bomo domaci_kraj.\nustvarite dva ševilska vektorja, ki bosta vsebovala koordinate domačih krajev - eden geografsko širino, drugi geografsko dolžino posameznega kraja. Poimenovali ju bomo geografska_sirina_dk in geografska_dolzina_dk. Koordinate krajev najlažje pridobite na Google Maps tako da kliknete na zemljevid v bližini kraja.\n\nKo izpolnite vse ukaze, kar pomeni, da ustrezno zamenjate vsa polja z znaki ___, premaknite kurzor v prvo vrstico s kopirano kodo in kliknite Run. Premikajte se navzdol po vrsticah z ukazi in izvedite vsakega od njih. Pričakovan rezultat je šest novih imen v vašem R Global Environment.\n\n\n\nimena_sosolcev &lt;- c(\"___\", \"___\", \"___\", \"___\") \n\nstarost &lt;- c(___, ___, ___, ___)\n\nbarva_oci &lt;- c(___, ___, ___, ___)\n\ndomaci_kraj &lt;- c(\"___\", \"___\", \"___\", \"___\")\n\ngeografska_sirina_dk &lt;- c(___, ___, ___, ___)\n\ngeografska_dolzina_dk &lt;- c(___, ___, ___, ___)\n\n\n\n\n\n\n\nPomembno\n\n\n\nPri delu s prostorskimi podatki v R-u je nujno, da so koordinate zapisane kot decimalne stopinje, brez znaka za stopinje (°). Pomembno je tudi poznavanje referenčnega koordinatnega sistema (Coordinate Reference System - CRS), kadar tabelo spreminjamo v katerega od prostorskih podatkovnih struktur.\n\n\n\n\nTabele (data frames)\nTabela je v osnovi več vektorjev, ki jih zdruzimo, tako da vsak predstavlja en stolpec v novoustvarjeni tabeli. Tabele so najpogostejša in najpogosteje uporabljena podatkovna struktura. Navadno jih v R uvozimo iz diska naših računalnikov, mi pa si bomo najprej pogledali, kako jih ustvarimo iz obstoječih vektorjev. Za to uporabimo funkcijo data.frame(), kjer znotraj oklepajev naštejemo imena vektorjev, ki jih želimo združiti v tabelo in jih ločimo z vejico. Podobno kot vektorje lahko v objekte shranjujemo tudi tabele, kar je prikazano v drugi vrstici spodnjega primera:\n\ndata.frame(ime_mesta, geografska_dolzina, geografska_sirina, prebivalstvo, primorska)\n\n      ime_mesta geografska_dolzina geografska_sirina prebivalstvo primorska\n1     Ljubljana           14.50742          46.04777       279631     FALSE\n2       Maribor           15.64526          46.55061        94370     FALSE\n3         Koper           13.73027          45.54738        25753      TRUE\n4 Kranjska Gora           13.78749          46.48872         1452     FALSE\n5    Novo mesto           15.16419          45.80263        24183     FALSE\n\nmesta &lt;- data.frame(ime_mesta, geografska_dolzina, geografska_sirina, prebivalstvo, primorska)\n\n\n\n\n\n\n\nNaloga\n\n\n\nZdružite vektorje iz prejšnje naloge (imena_sosolcev, starost, barva_oci, ) v tabelo, ki bo dodeljena objektu z imenom sosolci, tako da namesto ___, vpisete imena zgoraj ustvarjenih vektorjev:\n\nsosolci &lt;- data.frame(___, # imena\n                      ___, # starosti\n                      ___, # barva oci\n                      ___, # domaci kraj\n                      ___, # geografska sirina\n                      ___) # geografska dolzina\n\nsosolci\n\n\n\n\n\nSeznami (lists)\nSeznami so objekti, ki lahko vsebujejo različne podatkovne strukture, kot npr. števila, besede, logične vrednosti, pa tudi vektorje, tabele in tudi druge sezname. Ustvarimo jih s funkcijo list() in znotraj oklepajev navedeme katere elemnte želimo vključiti na seznam. Seznami so kompleksne podatkovne strukture, ki se pogosteje uporabljajo za zahtevnejše operacije. Spodnji primer služi samo kot demostracija, kako ustvari seznam s poljubnimi elementi, od katerih smo jih nekaj ustvarili danes na vajah:\n\n\n\n\n\n\nNaloga\n\n\n\nKopirajte ukaze v skripto in jih zaženite.\n\n\n\nseznam &lt;- list(1, \"Koper, Slovenia\", # beseda, stevilo\n               mesani_vektor, # vektor \n               mesta, # tabela\n               list(1, \"Koper, Slovenia\", mesani_vektor, mesta) # seznam\n)\n\nseznam\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] \"Koper, Slovenia\"\n\n[[3]]\n[1] \"R\"    NA     \"1\"    \"TRUE\"\n\n[[4]]\n      ime_mesta geografska_dolzina geografska_sirina prebivalstvo primorska\n1     Ljubljana           14.50742          46.04777       279631     FALSE\n2       Maribor           15.64526          46.55061        94370     FALSE\n3         Koper           13.73027          45.54738        25753      TRUE\n4 Kranjska Gora           13.78749          46.48872         1452     FALSE\n5    Novo mesto           15.16419          45.80263        24183     FALSE\n\n[[5]]\n[[5]][[1]]\n[1] 1\n\n[[5]][[2]]\n[1] \"Koper, Slovenia\"\n\n[[5]][[3]]\n[1] \"R\"    NA     \"1\"    \"TRUE\"\n\n[[5]][[4]]\n      ime_mesta geografska_dolzina geografska_sirina prebivalstvo primorska\n1     Ljubljana           14.50742          46.04777       279631     FALSE\n2       Maribor           15.64526          46.55061        94370     FALSE\n3         Koper           13.73027          45.54738        25753      TRUE\n4 Kranjska Gora           13.78749          46.48872         1452     FALSE\n5    Novo mesto           15.16419          45.80263        24183     FALSE\n\n\n\n\n\n\n\n\n\nNaloga\n\n\n\nShranite R skripto in si jo naložite na USB ali pošljite preko e-maila, da jo lahko ponovno uporabite.\n\n\n\nVprašanja v razmislek:\n\nKaj je glavna lastnost vektorjev in katere osnove tipe poznamo?\nKakšna je povezava med vektorji in tabelami?\nKaj so seznami?\n\nAli imate vi kakšna vprašanja?"
  },
  {
    "objectID": "posts/01_GIS_SI_Uvod_v_R_in_RStudio.html#seznami-lists",
    "href": "posts/01_GIS_SI_Uvod_v_R_in_RStudio.html#seznami-lists",
    "title": "UVOD V UPORABO PROGRAMSKEGA JEZIKA R KOT GIS",
    "section": "Seznami (lists)",
    "text": "Seznami (lists)\nSeznami so objekti, ki lahko vsebujejo različne podatkovne strukture, kot npr. števila, besede, logične vrednosti, pa tudi vektorje, tabele in tudi druge sezname. Ustvarimo jih s funkcijo list() in znotraj oklepajev navedeme katere elemnte želimo vključiti na seznam. Seznami so kompleksne podatkovne strukture, ki se pogosteje uporabljajo za zahtevnejše operacije. Spodnji primer služi samo kot demostracija, kako ustvari seznam s poljubnimi elementi, od katerih smo jih nekaj ustvarili danes na vajah:\n\n\n\n\n\n\nNaloga\n\n\n\nKopirajte ukaze v skripto in jih zaženite.\n\n\n\nseznam &lt;- list(1, \"Koper, Slovenia\", # beseda, stevilo\n               mesani_vektor, # vektor \n               mesta, # tabela\n               list(1, \"Koper, Slovenia\", mesani_vektor, mesta) # seznam\n)\n\nseznam\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] \"Koper, Slovenia\"\n\n[[3]]\n[1] \"R\"    NA     \"1\"    \"TRUE\"\n\n[[4]]\n      ime_mesta geografska_dolzina geografska_sirina prebivalstvo primorska\n1     Ljubljana           14.50742          46.04777       279631     FALSE\n2       Maribor           15.64526          46.55061        94370     FALSE\n3         Koper           13.73027          45.54738        25753      TRUE\n4 Kranjska Gora           13.78749          46.48872         1452     FALSE\n5    Novo mesto           15.16419          45.80263        24183     FALSE\n\n[[5]]\n[[5]][[1]]\n[1] 1\n\n[[5]][[2]]\n[1] \"Koper, Slovenia\"\n\n[[5]][[3]]\n[1] \"R\"    NA     \"1\"    \"TRUE\"\n\n[[5]][[4]]\n      ime_mesta geografska_dolzina geografska_sirina prebivalstvo primorska\n1     Ljubljana           14.50742          46.04777       279631     FALSE\n2       Maribor           15.64526          46.55061        94370     FALSE\n3         Koper           13.73027          45.54738        25753      TRUE\n4 Kranjska Gora           13.78749          46.48872         1452     FALSE\n5    Novo mesto           15.16419          45.80263        24183     FALSE\n\n\n\n\n\n\n\n\n\nNaloga\n\n\n\nShranite R skripto in si jo naložite na USB ali pošljite preko e-maila, da jo lahko ponovno uporabite.\n\n\n\nVprašanja v razmislek:\n\nKaj je glavna lastnost vektorjev in katere osnove tipe poznamo?\nKakšna je povezava med vektorji in tabelami?\nKaj so seznami?\n\nAli imate vi kakšna vprašanja?\n\n\nTake home message\nR is a language and learning it is similar to learning a foreign language. It takes time and patience. The good thing is that there are only two really important thing to grasp at the beginning: what is an object and a function, and how these two interact: a function (usualy predefined by R developers) is applied to an object (which has a given name, usualy by us) and we expect something to happen as a result. Note that you used several function on several objects today (i.e. functions c(), data.frame(), names() etc., on objects character_vector, heigth, best_class_ever etc.). This is the essence of working with R and most of the time you will be doing just that, function(object) and get what you wanted or get:\n\nfunction(object)\n\nError: &lt;text&gt;:2:0: unexpected end of input\n1: function(object)\n   ^"
  },
  {
    "objectID": "posts/01_GIS_SI_Uvod_v_R_in_RStudio.html#take-home-message",
    "href": "posts/01_GIS_SI_Uvod_v_R_in_RStudio.html#take-home-message",
    "title": "UVOD V UPORABO PROGRAMSKEGA JEZIKA R KOT GIS",
    "section": "Take home message",
    "text": "Take home message\nR je jezik in učenje je podobno kot učenje tujega jezika. Potreben je čas, potrpežljivost in vaja. Dobra stvar je, da je v osnovi potrebno razumeti dva koncepta: kaj so objekti (in kako ga ustvarimo) in funkcije. ter kako ta dva koncepta uporabljamo sočasno. Funkcije (definirane s strani R razvijalcev/developerjev) apliciramo na objekte (ki vsebuje podatke in ki smo ga mi poimenovali) in pričakujemo, da se bo nekaj zgodilo. Danes ste ustvarili različne objekte in uporabili tudi nekaj funkcij. To je osnova dela za R-om in večinoma bodo ukazi ravno to: aplicirali boste funkcijo na objekt (funkcija(objekt)) in dobili kar želite, ali pa vam bo R povedal, da vas ne razume: 😄\n\nfunkcija(objekt)\n\nError in funkcija(objekt): could not find function \"funkcija\""
  },
  {
    "objectID": "posts/02_GIS_SI_GBIF.html",
    "href": "posts/02_GIS_SI_GBIF.html",
    "title": "DOSTOP DO PODATKOV IZ PORTALA GBIF IN PRIKAZ Z UPORABO ORODIJ LEAFLET",
    "section": "",
    "text": "Povzetek\n\n\n\nNa teh vajah boste:\n\nspoznali bazo podatkov Global Biodiversity Information Facility (GBIF),\nse naučili instalirati in uporabiti dodatne R funkcije (iz paketov rgbif, dplyr in leaflet),\nuporabili R ukaze za dostop do in prenos lokacij iz GBIF serverja ,\nse naučili izbiranja stolpcev in filtiranja podatkov iz tabel,\nse naučili prikazati lokacije točk z uporabo paketa leaflet in izvoziti interaktivni zemljevid v html format."
  },
  {
    "objectID": "posts/02_GIS_SI_GBIF.html#what-is-global-biodiversity-information-facility",
    "href": "posts/02_GIS_SI_GBIF.html#what-is-global-biodiversity-information-facility",
    "title": "ACCESSING MARINE SPECIES OCCURENCES IN R WITH RGBIF",
    "section": "What is Global Biodiversity Information Facility?",
    "text": "What is Global Biodiversity Information Facility?\nGlobal Biodiversity Information Facility (GBIF) is an international network and data infrastructure. It is funded by the world’s governments and aimed at providing anyone, anywhere, open access to data about all types of life on Earth.\nAt the time of writing this study materials, there were more than 2.2 billion records published in the GBIF database, in both marine and terrestrial realm on a global scale. The webpage itself is very practical in terms of navigation and search, but what is even better is that occurrence data can be easily accessed and downloaded through R either for a species or taxa of interest.\n\n\n\n\n\n\nNaloga\n\n\n\nOpen the GBIF website and explore it for a couple of minutes.\n\n\n\n\n\nGlobal Biodiversity Information Facility landing site some time ago"
  },
  {
    "objectID": "posts/02_GIS_SI_GBIF.html#dostop-do-podatkov-v-spletni-bazi-gbif-v-r-u",
    "href": "posts/02_GIS_SI_GBIF.html#dostop-do-podatkov-v-spletni-bazi-gbif-v-r-u",
    "title": "DOSTOP DO PODATKOV IZ PORTALA GBIF IN PRIKAZ Z UPORABO ORODIJ LEAFLET",
    "section": "Dostop do podatkov v spletni bazi GBIF v R-u",
    "text": "Dostop do podatkov v spletni bazi GBIF v R-u\nPodatke iz GBIF je mogoče prenesti ročno in nato uvoziti v R. Vendar če so programerji lahko leni, smo lahko leni tudi biologi, kajne? V ta namen obstaja paket R, imenovan rgbif. Vsebuje funkcije, ki nam omogočajo neposreden stik s strežnikom GBIF, komuniciranje z njim in pridobivanje podatkov, ki nas zanimajo. V R-U moramo najprej inštalirati oziroma namestiti paket s funkcijo install.packages() z imenom paketa v narekovajih znotraj oklepajev. To samodejno prenese in namesti paket. Prav tako moramo paket naložiti vsakič, ko zaženemo ali znova zaženemo R ali RStudio. To naredimo s funkcijo library() z imenom paketa brez narekovajev v oklepaju. Vsakemu paketu je priložen dokument, v katerem so na voljo vse pomembne informacije, primer za rgbif je dostopen tukaj.\n\n\n\n\n\n\nPomembno\n\n\n\nZ instaliranjem osnovnega R-a so nam na voljo le nekatera privzeta orodja. Razlog za to je, da obstaja tako veliko število orodij, da jih posamezen uporabnik velike večine nikoli ne bo potreboval. Lahko pa enostavno dodajamo tista, ki jih potrebumo, tako da dodatne “pakete” prenesemo iz interneta in inštaliramo na naš računalnik (predstavljajte si R paket kot razširitev osnovnega R-a). Inštalacijo paketa potrebujemo narediti le enkrat, pred prvo uporabo le-tega!\nPozorni pa moramo biti, da pred vsako uporabo paketa, le-tega naredimo dostopnega za uporabo, kar pomeni, da ga moramo aktivirati vsakič, ko odpremo R ali RStudio!\n\n\n\n\n\n\n\n\nNaloga\n\n\n\nOdprite nov R skript v meniju File tako, da kliknete New file in potem R script. Skript bo imel ime Untitled1 (ali Untitled2, če je že odprt prazen skript).\nShranite skript na namizje vašega računalnika in ga poimenujte Dostop do podatkov iz portala GBIF z R: braszdasti kit.\nKopirajte in prilepite spodnjo kodo v skript R, premaknite kazalec v prvo vrstico s kodo in kliknite Run. Premaknite kazalec na vsako vrstico, ki vsebuje kodo, in ponovite.\n\n\n\ninstall.packages(\"rgbif\")\nlibrary(rgbif)\n\n\n\n\n\n\n\nNapake povezane z R paketi in kako jih rešiti\n\n\n\nČe vam R javi napako:\n\nError in library(...) : there is no package called ‘...’: paket ni inštaliran na računalniku in morate zagnati funkcijo install.packages(\"...\"), kjer ... predstavljajo ime želenega paketa.\nError in ... : could not find function \"...\": paket ni aktiviran in morate zagnati funkcijo library(\"...\"), kjer ... predstavljajo ime želenega paketa.\n\n\n\nZa dostop do podatkov o pojavljanju vrst obstaja funkcija occ_search(), ki bo vzpostavila stik s strežnikom GBIF, poiskala in prenesla podatke iz baze podatkov. Za primer bomo vzeli brazdastega kita (Balaenoptera physalus).\n\n\n\nBraszdasti kit (Vir fotografije: https://www.flickr.com/photos/slobirdr/29414853626)\n\n\nFunkcije ste spoznali na prvih vajah, kjer smo znotraj oklepajev natipkali ime nekega objekta, da smo dobili rezultat. Poleg objektov, ki jih ustvarimo, funkcije sprejemajo tudi druge vnose, ki jih imenujemo argumenti. Funkcija occ_search() ima med mnogimi možnimi argumenti, enega poimenovanega scientificName =, ki je privzeto nastavljen na NULL. Če želimo uporabiti funkcijo occ_search() za iskanje pojavljanj posamezne vrste, kot je naš primet brazdastega kita, argument izenačimo z imenom iskane vrste: scientificName = \"Balaenoptera physalus\". Upoštevajte, da je latinsko ime napisano v narekovajih, da ga R obravnava kot besedo. Obstaja veliko argumentov, ki bi jih lahko uporabili za izboljšanje našega iskanja (tj. hasCoordinate, country, continent itd.), vendar jih na tej točki ne bomo uporabili.\n\n\n\n\n\n\nNamig\n\n\n\nČe potrebujemo informacije o posamezni funkciji, pred njeno ime natipkamo znak za vprašaj (?) in izpustimo narekovaje. Ko ta ukaz zaženemo, se nam bo odprlo podokno Help z dokumnetacijo za izbrano funkcijo.\n\n\nSpodnja koda bo najprej odprla dokumentacijo za funkcijo occ_search() in nato shranila njen rezultate v objekt physalus_gbif, ki bi se moral pojaviti v vašem globalnem okolju kmalu po zagonu kode.\n\n\n\n\n\n\nNaloga\n\n\n\nKopirajte in prilepite spodnjo kodo v R skript, premaknite kazalec na prvo vrstico s kodo in kliknite Run. Raziščite dokument, ki se bo odprl na zavihku Help.\nKliknite Run za drugo vrstico kode in preverite delovno okolje: ali je bil ustvarjen nov objekt? Ker bomo vsi vzpostavljali stik s strežnikom GBIF hkrati, lahko traja nekaj časa, da se vse zahteve obdelajo in dokončajo.\n\n\n\n?occ_search\n\nphysalus_gbif &lt;- occ_search(scientificName = \"Balaenoptera physalus\")\n\nDesno od imena physalus_gbif lahko vidite kakšen tip R objekta je: to je seznam s 5 elementi. Če kliknete majhno modro ikono levo od physalus_gbif, bo njegova vsebina prikazana spodaj. Vidite lahko, da smo dejansko prenesli veliko podatkov. Obstajajo trije seznami, imenovani meta, hierarchy in media (daleč spodaj), in tabela poimenovana data. Peti element sploh ni naveden, saj imajo prvi štirje toliko vsebine, da njegova vsebina ni prikazana. Lahko bi raziskali vse te elemente, vendar bomo pogledali samo del data, kjer so shranjene koordinate in druge informacije o pojavljanjih brazdastega kita.\nV tabeli data je 500 opažanj braszdastih kitov, kar pa ni nujno dejansko število pojavljanj v GBIF bazi podatkov. Za preprečitev (pre)obremenitve strežnika je privzeto prenesenih le 500 pojavljanj. Za brazdaste kite je v GBIF bazi podatkov kar 113321 pojavljanj (preverite lahko tukaj). Če želimo spremeniti število prenesenih pojavljanj, dodamo argument limit = in izberemo želeno število (največja omejitev prenosa je 100000 pojavljanj).\nNa zaslonu lahko vidite znak za dolar ($) pred imenom elementa. To ni naključje, saj nam pove, da lahko do tega dela seznama dostopamo tako, da za njegovim imenom dodamo $data. Rezultat te operacije bomo shranili v še en nov objekt, ki ga bomo poimenovali physalus_data. To je tabela, v kateri so vsi potrebni podatki za nadaljevanje vaje.\n\n\n\n\n\n\nNaloga\n\n\n\nKopirajte in prilepite spodnjo kodo v R skript, premaknite kazalec na prvo vrstico s kodo in kliknite Run. Preverite svoj delovni imenik, če se po drugem ukazu v njem nahaja novo ime.\nKliknite na ime physalus_data, da se vam odpre tabela v pregled. V naslednjih nekaj minutah raziščite podatke in razmislite, ali so kateri od stolpcev še posebej pomembni za nadaljnje delo.\n\n\n\nphysalus_gbif &lt;- occ_search(scientificName = \"Balaenoptera physalus\",\n                            limit = 1500)\n\n\nphysalus_data &lt;- physalus_gbif$data \n\n\nVprašanja v razmislek:\n\nAli je physalus_data res tabela (ali tibble), kot je bil element $data v physalus_gbif?\nKoliko vrstic in stolpcev ima tabela physalus_data?\n\nImate vi kakšno vprašanje?"
  },
  {
    "objectID": "posts/02_GIS_SI_GBIF.html#partly-funded-by-eu-erasmus-programme-for-higher-education-staff-mobility.",
    "href": "posts/02_GIS_SI_GBIF.html#partly-funded-by-eu-erasmus-programme-for-higher-education-staff-mobility.",
    "title": "DOSTOP DO PODATKOV IZ PORTALA GBIF IN PRIKAZ Z UPORABO ORODIJ LEAFLET",
    "section": "",
    "text": "Partly funded by EU Erasmus+ Programme for Higher Education Staff Mobility"
  },
  {
    "objectID": "posts/02_GIS_SI_GBIF.html#kaj-je-global-biodiversity-information-facility-gbif",
    "href": "posts/02_GIS_SI_GBIF.html#kaj-je-global-biodiversity-information-facility-gbif",
    "title": "DOSTOP DO PODATKOV IZ PORTALA GBIF IN PRIKAZ Z UPORABO ORODIJ LEAFLET",
    "section": "Kaj je Global Biodiversity Information Facility (GBIF)?",
    "text": "Kaj je Global Biodiversity Information Facility (GBIF)?\nGlobal Biodiversity Information Facility (GBIF) je mednarodno omrežje oragnizacija, ki je vzpostavilo podatkovno infrastrukturo oziroma bazo. Financirajo ga vlade držav, namenjen pa je prostemu dostopu do podatkov o pojavljanju vrst na našem planetu.\nOb času pripravljanja teh vsebin je bilo na portalu objavljenih več kot 2.2 milijardi lokacij, tako v morskih kot tudi kopenskih ekosistemih na globalni ravni. Že sama spletna stran je zelo uporabna za iskanje in prenos podatkov, še boljše pa je, da lahko podatke o vrstah ali taksonih poiščemo in prenesemo z uporabo R ukazov neposredno iz serverja GBIF-ja.\n\n\n\n\n\n\nNaloga\n\n\n\nOdprite spletno stran GBIF in jo raziščite v naslednjih nekaj minutah.\n\n\n\n\n\nDomača stran Global Biodiversity Information Facility."
  },
  {
    "objectID": "posts/02_GIS_SI_GBIF.html#kako-z-uporabo-r-a-dostopamo-in-prenesemo",
    "href": "posts/02_GIS_SI_GBIF.html#kako-z-uporabo-r-a-dostopamo-in-prenesemo",
    "title": "DOSTOP DO PODATKOV IZ PORTALA GBIF IN PRIKAZ Z UPORABO RAZLIČNIH R ORODIJ",
    "section": "Kako z uporabo R-a dostopamo in prenesemo ?",
    "text": "Kako z uporabo R-a dostopamo in prenesemo ?\nZa dostop do podatkov o pojavljanju vrst obstaja funkcija occ_search(), ki bo vzpostavila stik s strežnikom GBIF, poiskala in prenesla podatke iz baze podatkov. Za primer bomo vzeli brazdastega kita (Balaenoptera physalus).\n\n\n\nBraszdasti kit (Vir fotografije: https://www.flickr.com/photos/slobirdr/29414853626)\n\n\nFunkcije ste spoznali na prvih vajah, kjer smo znotraj oklepajev natipkali ime nekega objekta, da smo dobili rezultat. Poleg objektov, ki jih ustvarimo, funkcije sprejemajo tudi druge vnose, ki jih imenujemo argumenti. Funkcija occ_search() ima med mnogimi možnimi argumenti, enega poimenovanega scientificName =, ki je privzeto nastavljen na NULL. Če želimo uporabiti funkcijo occ_search() za iskanje pojavljanj posamezne vrste, kot je naš primet brazdastega kita, argument izenačimo z imenom iskane vrste: scientificName = \"Balaenoptera physalus\". Upoštevajte, da je latinsko ime napisano v narekovajih, da ga R obravnava kot besedo. Obstaja veliko argumentov, ki bi jih lahko uporabili za izboljšanje našega iskanja (tj. hasCoordinate, country, continent itd.), vendar jih na tej točki ne bomo uporabili.\n\n\n\n\n\n\nNamig\n\n\n\nČe potrebujemo informacije o posamezni funkciji, pred njeno ime natipkamo znak za vprašaj (?) in izpustimo narekovaje. Ko ta ukaz zaženemo, se nam bo odprlo podokno Help z dokumnetacijo za izbrano funkcijo.\n\n\nBelow code will first open the documentation for occ_search() function and than store the results of it to physalus_gbif object, which should appear in your Global environment shortly after running the code.\n\n\n\n\n\n\nNaloga\n\n\n\nCopy and paste below code to the R script, move cursor to the row with the code and click Run. Explore the document that will open in the Help tab.\nRun the second line of the code and check your working directory, if a new object was created. As we will all be contacting the GBIF server at the same time, it might take a while for all requests to be processed and finished.\n\n\n\n?occ_search\n\nphysalus_gbif &lt;- occ_search(scientificName = \"Balaenoptera physalus\")\n\nRight of physalus_gbif object you can see what type of an R object it is: a list of 5 elements. If you click on the small blue icon left of the physalus_gbif, its content will be displayed below. You can see that we actually downloaded a lot of stuff. There are three lists called meta, hierarchy and media (far below), and a tibble or dataframe called data. Fifth element is not even listed as the first four have so much content that it was not printed in this display. We could explore all of this elements, but will look only at the data part, where coordinates and other information on the records are stored. In the display, you can see a dollar sign ($) in front of an element name. This is not coincidence, as it tells us, that we can access this part of the list by adding $data after its name. We will save the result of this operation to yet another object, that we will name physalus_data, which is a dataframe and which will be our dataset for further exploration.\n\n\n\n\n\n\nNaloga\n\n\n\nCopy and paste below code to the R script, move cursor to the row with code and click Run. Check your working directory if a new object was created.\n\n\n\nphysalus_data &lt;- physalus_gbif$data \n\n\nQuestions:\n\nIs physalus_data indeed a dataframe (or a tibble) as it was the $data element of physalus_gbif?\nHow do you know that and is there an R function with which you can check that out?\nHow many rows and columns does physalus_data dataframe has?\nHow do you know that and are there R functions with which you can check that out?\n\nDo you have any questions?\n\nThere are 500 observations of fin whales in the table, which is not necessarily the actual number of occurences in the database. To prevent server (over)load the default is to download 500 occurrences. This is the case for fin whales as well, as there are 113321 occurrences in the GBIF database (check here). To change the number of downloaded occurrences, we would need to change the argument limit = to the desired value (however, note that 100,000 is the maximum limit set by package creators).\n\n\n\n\n\n\nNaloga\n\n\n\nClick on the physalus_data object, its content should get displayed where your R script is open. Explore the table and try to identify columns that can be useful for us (i.e. coordinates, year, etc).\n\n\nNote that everything in R can be done in multiple ways. We will look at filtering (using a condition and retain a subset of observations - rows) and selecting (retaining only columns of interest) parts of our data using dplyr R package. The same could be achieved using only base R or advanced packages such as data.table. R package dplyr is very suitable for R beginners as it is very intuitive, but nevertheless very useful and powerful. Remember from above, we need to firs install the package and than load it, for its functions to be available.\n\n\n\n\n\n\nNaloga\n\n\n\nCopy and paste below code to the R script, move cursor to the row with code and click Run. Check your working directory if a new object was created.\n\n\n\ninstall.packages(\"dplyr\")\nlibrary(dplyr)\n\nFor selecting columns of a dataframe we use select() function which takes two arguments: the name of data object we want to select from and the name of column we want to select. With select()we can choose multiple columns. Of more than 100 columns that were downloaded, only some have meaningful values for us at this moment. … We will retain several, that are listed … For filtering by row values we use filter() function which also takes two arguments: the name of data object we want to select from and the expression based on which we want to filter. For example, we do not want fin whale observation with large coordinate uncertatinty, right? To retain only those with 5 km or less, we simply need to specify the name of the column coordinateUncertaintyInMeters and the filtering condition (&lt; 5000). 5 km is not that bad considering the movement capabilities of fin whales, right? We will save results of selecting and filtering in physalus_data object, which will overwrite the original object.\n\nphysalus_data &lt;- \n  select(physalus_data,\n         species,\n         decimalLatitude,\n         decimalLongitude,\n         coordinateUncertaintyInMeters,\n         country) %&gt;% \n  filter(coordinateUncertaintyInMeters &lt; 5000)\n\n\n\n\n\n\n\nWarning\n\n\n\nFunctions select() and filter() are defined in multiple R packages. Depending on which package was loaded last by library(), R chooses which version of the function it will apply. If we do not get the expected result from the function or an unexpected error after running it, this is the likeliest cause.\n\n\n\n\n\n\n\n\nTip\n\n\n\nWe can avoid problems with commonly named functions by telling R a priori which function from which package we want to use. For example, select() or filter() from dplyr as follows:\n\ndplyr::filter(),\ndplyr::select().\n\n\n\n\nInteraktivni prikaz s paketom leaflet\nPaket leaflet nam omogoca enostavno kreiranje interaktivnih zemljevidov. Osnovna funkcija, s katero zazenemo tak zemljevid je leaflet() in znotraj oklepajev navedemo, kateri objekt zelimo prikazati na zemljevidu (v nasem primeru mesta) Sloje zemljevidu dodajamo tako, da na koncu vrstice uporabimo operator %&gt;%. S funkcijo addProviderTiles() dolocimo ozadje nasega zemljevida. Izbiramo lahko med stevilnimi moznostmi, ki si jih lahko ogledate tu. Za zacetek bomo uporabili ozadje \"Esri.WorldImagery\", tako da definiramo provider = \"Esri.WorldImagery\". Lahko pa ga enostavno tudi zamenjamo, npr. s provider = \"OpenTopoMap\". Nato ponovimo operator %&gt;% in s funkcijo addCircleMarkers() dodamo tocke na nas zemljevid. Ta funkcija zahteva, da dolocimo, kateri stolpcev v podatkih je geografska dolzina (lng = ~) in kateri geografska sirina (lat = ~). Leaflet zahteva, da pred imeni stolpcev iz tabele dodamo znak ~, medtem ko ga drugi argumenti ne zahtevajo.\n\n\n\n\n\n\nNaloga\n\n\n\nKopirajte in prilepite spodnjo kodo v R skript, premaknite kazalec na prvo vrstico s kodo in kliknite Run. Premaknite kazalec na vsako vrstico, ki vsebuje kodo, in ponovite. Koda, ki se začne z leaflet(physalus_data), se mora zagnati od začetka do konca po enem kliku Run.\n\n\n\ninstall.packages(\"leaflet\") \nlibrary(leaflet)\n\nleaflet(physalus_data) %&gt;%\n    addProviderTiles(\"Esri.WorldImagery\") %&gt;%\n    addCircleMarkers(\n        lng = ~ decimalLongitude,\n        lat = ~ decimalLatitude)\n\n\n\n\n\n\n\n\nQuestions to consider:\n\nWhat is GBIF and how can it be useful for your research/teaching?\nWhat are the drawbacks of the GBIF data considering that some of it comes from citizen science?\nHow many times do you need to run install.packages() functions and how many times the library() function?\nWhich package and functions are easy to use for filtering and selecting only the data of interest?\nWhich package and functions are easy to use for simple spatial data visualization of spatial points?\n\nDo you have any questions?\n\n\nToday your task will be more challenging than those of yesterday. Follow the next steps to accomplish it:\n\nChoose one marine species (your favorite) and find its Latin name.\nOpen new R script, save it to desktop and name it Accessing \"insert your species name\" data with R on the desktop.\nCopy - paste all R code that we ran for fin whale example (you can exclude only install.packages(), as the packages are already on your computer now).\nAdapt the code in a way that you replace Balaenoptera physalus with chosen species name and rename physalus_gbif according to your species (i.e. Liza aurata & aurata_gbif).\nAdd the argument limit = to occ_search() function and download more than 500 occurrences (change 500 with a number of your choice).\nExtract the data part of the *_gbif object and rename the object according to you species (i.e. aurata_data).\n\nif there are zero or a small number of occurrences of your species (&lt; 100), repeat from step 1.\nif there are &gt; 100 occurrences of your species, proceed to step 7.\n\nSelect only meaningful columns from the *_data dataframe. The column names should be the same as in the fin whale example and the code should work on your data. Add a minimum three columns to the select function on top of the ones that I chose to select!\nApply filter to your data and try to change the filtering value of coordinate uncertainty to correspond to your species better (i.e. 500 metres might be better for Liza aurata).\nDisplay the filtered occurrences of your species on a leflet map. Explore the available base maps here and change it to one of your choice (i.e.replace \"Esri.WorldImagery\" with \"OpenTopoMap\".\n\nIf something doesn’t work straight away, first think about the problem/error, consult a neighbor on your left, then on your right. If after that you still don’t know how to fix the problem or proceed, ask me for help!\n\n\n\nSave both R scripts, so you can reuse your code in the following labs.\nWhen you close R studio, select Yes when it asks if you want to save your work-space."
  },
  {
    "objectID": "posts/02_GIS_SI_GBIF.html#imate-vi-kakšno-vprašanje",
    "href": "posts/02_GIS_SI_GBIF.html#imate-vi-kakšno-vprašanje",
    "title": "DOSTOP DO PODATKOV IZ PORTALA GBIF IN PRIKAZ Z UPORABO ORODIJ LEAFLET",
    "section": "Imate vi kakšno vprašanje?",
    "text": "Imate vi kakšno vprašanje?\n\n\n\n\n\n\nNaloga\n\n\n\nČe nekaj ne deluje takoj, najprej razmislite o težavi/napaki, se posvetujte s sosedom na levi, nato na desni. Če po tem še vedno ne veste, kako odpraviti težavo ali nadaljevati, vprašajte google ali chat gpt in šele nato vprašajte mene za pomoč!\nDanašnja naloga bo bolj zahtevna kot zadnjič. Sledite naslednjim korakom, da jo dokončate:\n\nIzberite si eno poljubno vrsto (lahko vašo najljubšo) in poiščite njeno latinsko ime.\nOdprite nov R skript v meniju File tako, da kliknete New file in potem R script. Skript bo imel ime Untitled1 (ali Untitled2, če je že odprt prazen skript). Shranite skript na namizje vašega računalnika in ga poimenujte Dostop do podatkov iz portala GBIF z R: ime vaše vrste.\nKopirajte in prilepite vso kodo, ki smo jo zagnali za primer braszdastega kita v prazno skripto. Vrstice, ki vsebujejo funkcije install.packages() lahko označite z znakom #, da se ne izvedejo ponovno, saj so paketi zdaj že inštalirani na vašem računalniku.\nPrilagodite kodo tako, da zamenjate Balaenoptera physalus z izbranim imenom vrste in preimenujete physalus_gbif glede na ime vaše vrste (npr. Liza aurata & aurata_gbif).\nPonastavite argument limit = v funkciji occ_search() in prenesite več kot 500 pojavljanj vrste (500 oz 1500 spremenite v številko po vaši izbiri).\nIz podatkovna seznama, ki se konča s končnico _gbif dostopajte do elementa data in ga shranite v nov objekt. Preimenujte glede na svojo vrsto (npr. aurata_data).\n\nče je število pojavljanj nič ali zelo majhno (&lt; 100), ponovite postopek od 1. koraka.\nče je &gt; 100 pojavitev vaše vrste, nadaljujte s 7. korakom.\n\nIzberite samo smiselne stolpce iz podatkovnega okvira *_data.\nFiltrirajte svoje podatke in poskusite spremeniti vrednost filtriranja napake koordinat, da bo bolje ustrezala vaši vrsti (npr. 500 metrov je morda bolje za Liza aurata).\nPrikažite filtrirana pojavljanja vaše vrste na leaflet zemljevidu. Raziščite razpoložljive osnovne zemljevide tukaj in ga spremenite v enega po svoji izbiri (npr. zamenjajte \"Esri.WorldImagery z drugim imenom iz seznama na spletni strani).\nSpremenite izgled točk na vašem zemljevidu, tako da poljubno spremenite vrednosti argumentov color =, radius = in fillOpacity =.\nIzvozite zemljevid v html dokument in ga naložite v nalogo na e-učilnico (lahko danes, lahko do postavljenega roka: 15.11.2023).\nShranite obe R skripti in si ju naložite na USB ali pošljite preko e-maila, da ju lahko ponovno uporabite.\n\n\n\n\n\n\n\n\n\n\nNaloge za hitre:\n\n\n\n\nNa leaflet zemljevidu prikažite mesta iz prvih vaj in spremenite izgled točk:\n\n\nime_mesta &lt;- c(\"Ljubljana\", \"Maribor\", \"Koper\", \"Kranjska Gora\", \"Novo mesto\")\n\ngeografska_sirina &lt;- c(46.047766, 46.550613, 45.547377,  46.4887160, 45.802626)\n\ngeografska_dolzina &lt;- c(14.507420, 15.645263, 13.730270,  13.787491, 15.164192)\n\nprebivalstvo &lt;- c(279631, 94370, 25753, 1452, 24183)\n\nprimorska &lt;- c(FALSE, FALSE, TRUE, FALSE, FALSE)\n\nmesta &lt;- data.frame(ime_mesta, geografska_dolzina, geografska_sirina, prebivalstvo, primorska)\n\n\nNa leaflet zemljevidu prikažite domače kraje sošolcev iz prvih vaj in spremenite izgled točk:\n\n\nimena_sosolcev &lt;- c(\"___\", \"___\", \"___\", \"___\") \n\nstarost &lt;- c(___, ___, ___, ___)\n\nbarva_oci &lt;- c(___, ___, ___, ___)\n\ndomaci_kraj &lt;- c(\"___\", \"___\", \"___\", \"___\")\n\ngeografska_sirina_dk &lt;- c(___, ___, ___, ___)\n\ngeografska_dolzina_dk &lt;- c(___, ___, ___, ___)\n\nsosolci &lt;- data.frame(___, # imena\n                      ___, # starosti\n                      ___, # barva oci\n                      ___, # domaci kraj\n                      ___, # geografska sirina\n                      ___) # geografska dolzina\n\nsosolci"
  },
  {
    "objectID": "posts/02_GIS_SI_GBIF.html#interaktivni-zemljevidi-paketa-leaflet",
    "href": "posts/02_GIS_SI_GBIF.html#interaktivni-zemljevidi-paketa-leaflet",
    "title": "DOSTOP DO PODATKOV IZ PORTALA GBIF IN PRIKAZ Z UPORABO ORODIJ LEAFLET",
    "section": "Interaktivni zemljevidi paketa leaflet",
    "text": "Interaktivni zemljevidi paketa leaflet\nPaket leaflet nam omogoča enostavno kreiranje interaktivnih zemljevidov. Osnovna funkcija, s katero zaženemo tak zemljevid je leaflet() in znotraj oklepajev navedemo, kateri podatkovni objekt želimo prikazati na zemljevidu. Sloje zemljevidu dodajamo tako, da na koncu vrstice uporabimo operator %&gt;%, kar R razumemo kot: k prejšnjim ukazom dodaj tudi naslednjega. S funkcijo addProviderTiles() določimo ozadje našega zemljevida. Izbiramo lahko med številnimi možnostmi, ki si jih lahko ogledate tu. Za začetek bomo uporabili ozadje \"Esri.WorldImagery\", tako da definiramo provider = \"Esri.WorldImagery\". Lahko pa ga enostavno tudi zamenjamo, npr. s provider = \"OpenTopoMap\". Nato ponovimo operator %&gt;% in s funkcijo addCircleMarkers() dodamo točke na naš zemljevid. Ta funkcija zahteva, da določimo, kateri stolpcev v podatkih je geografska dolžina (lng = ~) in kateri geografska širina (lat = ~). Leaflet zahteva, da pred imeni stolpcev iz tabele dodamo znak ~.\n\n\n\n\n\n\nNaloga\n\n\n\nKopirajte in prilepite spodnjo kodo v R skript, premaknite kazalec na prvo vrstico s kodo in kliknite Run. Premaknite kazalec na vsako vrstico, ki vsebuje kodo, in ponovite. Koda, ki se začne z leaflet(physalus_data), se mora zagnati od začetka do konca po enem kliku na Run.\n\n\n\ninstall.packages(\"leaflet\") \nlibrary(leaflet)\n\nleaflet(physalus_data) %&gt;%\n    addProviderTiles(\"Esri.WorldImagery\") %&gt;%\n    addCircleMarkers(\n        lng = ~ decimalLongitude,\n        lat = ~ decimalLatitude)\n\n\n\n\n\n\n\n\nZemljevid pojavljanj lahko še malo vizualno uredimo. Na primer, spremenimo barvo, prosojnost ali velikost točk, ali pa odstranimo obrobo. Vsaka od teh lastnosti je definirana s svojim argumentom, ki ga dodamo znotraj oklepajev funkcije addCircleMarkers():\n\ns color = lahko spremenimo barvo točk. Barve, ki jih lahko uporabimo najdete tu, delujejo pa tiste, ki nimajo števila na koncu imena.\nz radius = 5 lahko spremenimo velikost točk, uporabimo lahko pozitivna števila,\ns stroke = FALSE lahko odstranimo obrobo točk,\ns fillOpacity = 0.7 spreminjamo transparentnost oziroma prosojnost točk, izberemo lahko vrednosti med 0 in 1:\n\n\n\n\n\n\n\nNaloga\n\n\n\nKopirajte in prilepite spodnjo kodo v R skript, premaknite kazalec na prvo vrstico s kodo in kliknite Run. Koda, ki se začne z leaflet(physalus_data), se mora zagnati od začetka do konca po enem kliku na Run.\n\n\n\nleaflet(physalus_data) %&gt;%\n    addProviderTiles(\"Esri.WorldImagery\") %&gt;%\n    addCircleMarkers(\n        lng = ~ decimalLongitude,\n        lat = ~ decimalLatitude,\n        color = \"deepskyblue\",\n        stroke = FALSE,\n        radius = 8,\n        fillOpacity = 0.7\n        )\n\n\n\n\n\n\nZemljevid bomo izvozili v html obliko, kar bo ohranilo njegove interaktivne lastnosti:\n\nKlik na gumb Export\n\n\n\n\nKliknemo “Export”.\n\n\n\nIzberemo Save as web page\n\n\n\n\nIzberemo “Save as web page”.\n\n\n\nDoločimo ime datoteke in shranimo na namizje našega računalnika\n\n\n\n\nIzberemo “Save” da shranimo na namizje.\n\n\n\nVprašanja za razmislek:\n\nKaj je GBIF in kako je lahko koristen za vaše raziskave/poučevanje?\nKakšne so pomanjkljivosti podatkov GBIF glede na to, da nekateri od njih izvirajo iz državljanske znanosti (citizen science)?\nKolikokrat morate zagnati funkcijo install.packages() in kolikokrat funkcijo library()?\nKateri paket in funkcije so enostavni za uporabo za filtriranje in izbiro samo podatkov, ki vas zanimajo?\nKateri paket in funkcije so enostavni za preprosto vizualizacijo prostorskih točk?\n\nImate vi kakšno vprašanje?\n\n\n\n\n\n\n\nNaloga\n\n\n\nČe nekaj ne deluje takoj, najprej razmislite o težavi/napaki, se posvetujte s sosedom na levi, nato na desni. Če po tem še vedno ne veste, kako odpraviti težavo ali nadaljevati, vprašajte google ali chat gpt in šele nato vprašajte mene za pomoč!\nDanašnja naloga bo bolj zahtevna kot zadnjič. Sledite naslednjim korakom, da jo dokončate:\n\nIzberite si eno poljubno vrsto (lahko vašo najljubšo) in poiščite njeno latinsko ime.\nOdprite nov R skript v meniju File tako, da kliknete New file in potem R script. Skript bo imel ime Untitled1 (ali Untitled2, če je že odprt prazen skript). Shranite skript na namizje vašega računalnika in ga poimenujte Dostop do podatkov iz portala GBIF z R: ime vaše vrste.\nKopirajte in prilepite vso kodo, ki smo jo zagnali za primer braszdastega kita v prazno skripto. Vrstice, ki vsebujejo funkcije install.packages() lahko označite z znakom #, da se ne izvedejo ponovno, saj so paketi zdaj že inštalirani na vašem računalniku.\nPrilagodite kodo tako, da zamenjate Balaenoptera physalus z izbranim imenom vrste in preimenujete physalus_gbif glede na ime vaše vrste (npr. Liza aurata & aurata_gbif).\nPonastavite argument limit = v funkciji occ_search() in prenesite več kot 500 pojavljanj vrste (500 oz 1500 spremenite v številko po vaši izbiri).\nIz podatkovna seznama, ki se konča s končnico _gbif dostopajte do elementa data in ga shranite v nov objekt. Preimenujte glede na svojo vrsto (npr. aurata_data).\n\nče je število pojavljanj nič ali zelo majhno (&lt; 100), ponovite postopek od 1. koraka.\nče je &gt; 100 pojavitev vaše vrste, nadaljujte s 7. korakom.\n\nIzberite samo smiselne stolpce iz podatkovnega okvira *_data.\nFiltrirajte svoje podatke in poskusite spremeniti vrednost filtriranja napake koordinat, da bo bolje ustrezala vaši vrsti (npr. 500 metrov je morda bolje za Liza aurata).\nPrikažite filtrirana pojavljanja vaše vrste na leaflet zemljevidu. Raziščite razpoložljive osnovne zemljevide tukaj in ga spremenite v enega po svoji izbiri (npr. zamenjajte \"Esri.WorldImagery z drugim imenom iz seznama na spletni strani).\nSpremenite izgled točk na vašem zemljevidu, tako da poljubno spremenite vrednosti argumentov color =, radius = in fillOpacity =.\nIzvozite zemljevid v html dokument in ga naložite v nalogo na e-učilnico (lahko danes, lahko do postavljenega roka: 15.11.2023).\nShranite obe R skripti in si ju naložite na USB ali pošljite preko e-maila, da ju lahko ponovno uporabite.\n\n\n\n\n\n\n\n\n\n\nNaloge za hitre:\n\n\n\n\nNa leaflet zemljevidu prikažite mesta iz prvih vaj in spremenite izgled točk:\n\n\nime_mesta &lt;- c(\"Ljubljana\", \"Maribor\", \"Koper\", \"Kranjska Gora\", \"Novo mesto\")\n\ngeografska_sirina &lt;- c(46.047766, 46.550613, 45.547377,  46.4887160, 45.802626)\n\ngeografska_dolzina &lt;- c(14.507420, 15.645263, 13.730270,  13.787491, 15.164192)\n\nprebivalstvo &lt;- c(279631, 94370, 25753, 1452, 24183)\n\nprimorska &lt;- c(FALSE, FALSE, TRUE, FALSE, FALSE)\n\nmesta &lt;- data.frame(ime_mesta, geografska_dolzina, geografska_sirina, prebivalstvo, primorska)\n\n\nNa leaflet zemljevidu prikažite domače kraje sošolcev iz prvih vaj in spremenite izgled točk:\n\n\nimena_sosolcev &lt;- c(\"___\", \"___\", \"___\", \"___\") \n\nstarost &lt;- c(___, ___, ___, ___)\n\nbarva_oci &lt;- c(___, ___, ___, ___)\n\ndomaci_kraj &lt;- c(\"___\", \"___\", \"___\", \"___\")\n\ngeografska_sirina_dk &lt;- c(___, ___, ___, ___)\n\ngeografska_dolzina_dk &lt;- c(___, ___, ___, ___)\n\nsosolci &lt;- data.frame(___, # imena\n                      ___, # starosti\n                      ___, # barva oci\n                      ___, # domaci kraj\n                      ___, # geografska sirina\n                      ___) # geografska dolzina\n\nsosolci"
  },
  {
    "objectID": "posts/02_GIS_SI_GBIF.html#izbiranje-stolpcev-in-filtriranje-podatkov",
    "href": "posts/02_GIS_SI_GBIF.html#izbiranje-stolpcev-in-filtriranje-podatkov",
    "title": "DOSTOP DO PODATKOV IZ PORTALA GBIF IN PRIKAZ Z UPORABO ORODIJ LEAFLET",
    "section": "Izbiranje stolpcev in filtriranje podatkov",
    "text": "Izbiranje stolpcev in filtriranje podatkov\nVse v R-u je mogoče narediti na več načinov. Mi si bomo ogledali filtriranje (z uporabo pogoja in ohranitev podmnožice opazovanj – vrstic) in izbiranje (ohranjanje samo ključnih stolpcev) delov naših podatkov s paketom dplyr. R paket dplyr je zelo primeren za R začetnike, saj je zelo intuitiven za uporabo, a kljub temu zelo uporaben in zmogljiv. Spomnite se od začetka vaj, da moramo paket najprej inštalirati in nato aktivirati, da lahko uporabimo njegove funkcije.\n\n\n\n\n\n\nNaloga\n\n\n\nKopirajte in prilepite spodnjo kodo v R skript, premaknite kazalec na prvo vrstico s kodo in kliknite Run. Ponovite še za drugo vrstico.\n\n\n\ninstall.packages(\"dplyr\")\nlibrary(dplyr)\n\nZa izbiranje stolpcev iz tabel uporabljamo funkcijo select(), ki potrebuje vsaj dva argumenta: ime podatkovnega objekta, iz katerega želimo izbrati, in ime vsaj stolpca, ki ga želimo izbrati. S select() lahko izberemo več stolpcev naenkrat. Od več kot 100 stolpcev, ki smo jih prenesli iz baze GBIF, imajo le nekateri v tem trenutku za nas pomembne podatke: npr. stolpca s koordinatami (decimalLatitude, decimalLongitude), stolpec z državo pojavljanja (country), stolpec z napako v koordinatah (coordinateUncerttaintyInMeters).\nZa filtriranje po vrednostih vrstic uporabljamo funkcijo filter(), ki prav tako sprejme dva argumenta: ime podatkovnega objekta, ki ga želimo izbrati iz in izraz, na podlagi katerega želimo filtrirati. Na primer, ne želimo opažanj brazdastih kitov z veliko napako, kajne? Če želimo obdržati samo tiste s 5 km ali manj, moramo preprosto določiti ime stolpca coordinateUncerttaintyInMeters in pogoj filtriranja (&lt; 5000). 5 km ni tako slabo glede na gibalne sposobnosti kitov plavutatih, kajne? Rezultate izbiranja stolpcev in filtriranja bomo shranili v objekt physalus_data, kar bo prepisalo izvirni objekt.\n\nphysalus_data &lt;- \n  select(physalus_data,\n         species,\n         decimalLatitude,\n         decimalLongitude,\n         coordinateUncertaintyInMeters,\n         country)\n\nphysalus_data &lt;- \n  filter(physalus_data,\n         coordinateUncertaintyInMeters &lt; 5000)\n\n\n\n\n\n\n\nOpozorilo\n\n\n\nFunkciji select() in filter() imata zelo generični imeni in sta definirani v različnih R paketih. Odvisno od tega, kateri paket smo nazadnje aktivirali s funkcijo library(), R izbere verzijo funkcije, ki jo bo uporabil. Lahko se zgodi, da po zagonu kode ne bomo dobili željenih rezultatov. V tem primeru je zgornji razlog napogojsteši krivec.\n\n\n\n\n\n\n\n\nNamig\n\n\n\nČe se želimo izogniti tem težavam, lahko R-u a priori povemo funkcijo iz katerega paketa želimo uporabiti, tako da pred funckijo napišemo ime paketa in dvojno dvopičje. Na primer, select() ali filter() iz paketa dplyr:\n\ndplyr::filter(),\ndplyr::select()."
  },
  {
    "objectID": "posts/02_GIS_SI_GBIF.html#interaktivni-zemljevidi-s-paketom-leaflet",
    "href": "posts/02_GIS_SI_GBIF.html#interaktivni-zemljevidi-s-paketom-leaflet",
    "title": "DOSTOP DO PODATKOV IZ PORTALA GBIF IN PRIKAZ Z UPORABO ORODIJ LEAFLET",
    "section": "Interaktivni zemljevidi s paketom leaflet",
    "text": "Interaktivni zemljevidi s paketom leaflet\nPaket leaflet nam omogoča enostavno kreiranje interaktivnih zemljevidov. Osnovna funkcija, s katero zaženemo tak zemljevid je leaflet() in znotraj oklepajev navedemo, kateri podatkovni objekt želimo prikazati na zemljevidu. Sloje zemljevidu dodajamo tako, da na koncu vrstice uporabimo operator %&gt;%, kar R razumemo kot: k prejšnjim ukazom dodaj tudi naslednjega. S funkcijo addProviderTiles() določimo ozadje našega zemljevida. Izbiramo lahko med številnimi možnostmi, ki si jih lahko ogledate tu. Za začetek bomo uporabili ozadje \"Esri.WorldImagery\", tako da definiramo provider = \"Esri.WorldImagery\". Lahko pa ga enostavno tudi zamenjamo, npr. s provider = \"OpenTopoMap\". Nato ponovimo operator %&gt;% in s funkcijo addCircleMarkers() dodamo točke na naš zemljevid. Ta funkcija zahteva, da določimo, kateri stolpcev v podatkih je geografska dolžina (lng = ~) in kateri geografska širina (lat = ~). Leaflet zahteva, da pred imeni stolpcev iz tabele dodamo znak ~.\n\n\n\n\n\n\nNaloga\n\n\n\nKopirajte in prilepite spodnjo kodo v R skript, premaknite kazalec na prvo vrstico s kodo in kliknite Run. Premaknite kazalec na vsako vrstico, ki vsebuje kodo, in ponovite. Koda, ki se začne z leaflet(physalus_data), se mora zagnati od začetka do konca po enem kliku na Run.\n\n\n\ninstall.packages(\"leaflet\") \nlibrary(leaflet)\n\nleaflet(physalus_data) %&gt;%\n    addProviderTiles(\"Esri.WorldImagery\") %&gt;%\n    addCircleMarkers(\n        lng = ~ decimalLongitude,\n        lat = ~ decimalLatitude)\n\n\n\n\n\n\n\n\nZemljevid pojavljanj lahko še malo vizualno uredimo. Na primer, spremenimo barvo, prosojnost ali velikost točk, ali pa odstranimo obrobo. Vsaka od teh lastnosti je definirana s svojim argumentom, ki ga dodamo znotraj oklepajev funkcije addCircleMarkers():\n\ns color = lahko spremenimo barvo točk. Barve, ki jih lahko uporabimo najdete tu, delujejo pa tiste, ki nimajo števila na koncu imena.\nz radius = 5 lahko spremenimo velikost točk, uporabimo lahko pozitivna števila,\ns stroke = FALSE lahko odstranimo obrobo točk,\ns fillOpacity = 0.7 spreminjamo transparentnost oziroma prosojnost točk, izberemo lahko vrednosti med 0 in 1,\nz label = pa lahko dodamo oznako točkam, ki bo prikazana, ko bomo z miškinim kazalcem šli čez posamezno točko.\n\n\n\n\n\n\n\nNaloga\n\n\n\nKopirajte in prilepite spodnjo kodo v R skript, premaknite kazalec na prvo vrstico s kodo in kliknite Run. Koda, ki se začne z leaflet(physalus_data), se mora zagnati od začetka do konca po enem kliku na Run.\n\n\n\nleaflet(physalus_data) %&gt;%\n    addProviderTiles(\"Esri.WorldImagery\") %&gt;%\n    addCircleMarkers(\n        lng = ~ decimalLongitude,\n        lat = ~ decimalLatitude,\n        color = \"deepskyblue\",\n        stroke = FALSE,\n        radius = 8,\n        fillOpacity = 0.7,\n        label = ~country\n        )\n\n\n\n\n\n\nZemljevid bomo izvozili v html obliko, kar bo ohranilo njegove interaktivne lastnosti:\n\nKlik na gumb Export\n\n\n\n\nKliknemo “Export”.\n\n\n\nIzberemo Save as web page\n\n\n\n\nIzberemo “Save as web page”.\n\n\n\nDoločimo ime datoteke in shranimo na namizje našega računalnika\n\n\n\n\nIzberemo “Save” da shranimo na namizje.\n\n\n\nVprašanja za razmislek:\n\nKaj je GBIF in kako je lahko koristen za vaše raziskave/poučevanje?\nKakšne so pomanjkljivosti podatkov GBIF glede na to, da nekateri od njih izvirajo iz državljanske znanosti (citizen science)?\nKolikokrat morate zagnati funkcijo install.packages() in kolikokrat funkcijo library()?\nKateri paket in funkcije so enostavni za uporabo za filtriranje in izbiro samo podatkov, ki vas zanimajo?\nKateri paket in funkcije so enostavni za preprosto vizualizacijo prostorskih točk?\n\nImate vi kakšno vprašanje?\n\n\n\n\n\n\n\nNaloga\n\n\n\nČe nekaj ne deluje takoj, najprej razmislite o težavi/napaki, se posvetujte s sosedom na levi, nato na desni. Če po tem še vedno ne veste, kako odpraviti težavo ali nadaljevati, vprašajte google ali chat gpt in šele nato vprašajte mene za pomoč!\nDanašnja naloga bo bolj zahtevna kot zadnjič. Sledite naslednjim korakom, da jo dokončate:\n\nIzberite si eno poljubno vrsto (lahko vašo najljubšo) in poiščite njeno latinsko ime.\nOdprite nov R skript v meniju File tako, da kliknete New file in potem R script. Skript bo imel ime Untitled1 (ali Untitled2, če je že odprt prazen skript). Shranite skript na namizje vašega računalnika in ga poimenujte Dostop do podatkov iz portala GBIF z R: ime vaše vrste.\nKopirajte in prilepite vso kodo, ki smo jo zagnali za primer braszdastega kita v prazno skripto. Vrstice, ki vsebujejo funkcije install.packages() lahko označite z znakom #, da se ne izvedejo ponovno, saj so paketi zdaj že inštalirani na vašem računalniku.\nPrilagodite kodo tako, da zamenjate Balaenoptera physalus z izbranim imenom vrste in preimenujete physalus_gbif glede na ime vaše vrste (npr. Liza aurata & aurata_gbif).\nPonastavite argument limit = v funkciji occ_search() in prenesite več kot 500 pojavljanj vrste (500 oz 1500 spremenite v številko po vaši izbiri).\nIz podatkovna seznama, ki se konča s končnico _gbif dostopajte do elementa data in ga shranite v nov objekt. Preimenujte glede na svojo vrsto (npr. aurata_data).\n\nče je število pojavljanj nič ali zelo majhno (&lt; 100), ponovite postopek od 1. koraka.\nče je &gt; 100 pojavitev vaše vrste, nadaljujte s 7. korakom.\n\nIzberite samo smiselne stolpce iz podatkovnega okvira *_data.\nFiltrirajte svoje podatke in poskusite spremeniti vrednost filtriranja napake koordinat, da bo bolje ustrezala vaši vrsti (npr. 500 metrov je morda bolje za Liza aurata).\nPrikažite filtrirana pojavljanja vaše vrste na leaflet zemljevidu. Raziščite razpoložljive osnovne zemljevide tukaj in ga spremenite v enega po svoji izbiri (npr. zamenjajte \"Esri.WorldImagery z drugim imenom iz seznama na spletni strani).\nSpremenite izgled točk na vašem zemljevidu, tako da poljubno spremenite vrednosti argumentov color =, radius = in fillOpacity =.\nIzvozite zemljevid v html dokument in ga naložite v nalogo na e-učilnico (lahko danes, lahko do postavljenega roka: 15.11.2023).\nShranite obe R skripti in si ju naložite na USB ali pošljite preko e-maila, da ju lahko ponovno uporabite.\n\n\n\n\n\n\n\n\n\n\nNaloge za hitre:\n\n\n\n\nNa leaflet zemljevidu prikažite mesta iz prvih vaj in spremenite izgled točk, oznaka točke naj bo ime mesta:\n\n\nime_mesta &lt;- c(\"Ljubljana\", \"Maribor\", \"Koper\", \"Kranjska Gora\", \"Novo mesto\")\n\ngeografska_sirina &lt;- c(46.047766, 46.550613, 45.547377,  46.4887160, 45.802626)\n\ngeografska_dolzina &lt;- c(14.507420, 15.645263, 13.730270,  13.787491, 15.164192)\n\nprebivalstvo &lt;- c(279631, 94370, 25753, 1452, 24183)\n\nprimorska &lt;- c(FALSE, FALSE, TRUE, FALSE, FALSE)\n\nmesta &lt;- data.frame(ime_mesta, geografska_dolzina, geografska_sirina, prebivalstvo, primorska)\n\n\nNa leaflet zemljevidu prikažite domače kraje sošolcev iz prvih vaj in spremenite izgled točk, oznaka točke naj bo ime sošolca:\n\n\nimena_sosolcev &lt;- c(\"___\", \"___\", \"___\", \"___\") \n\nstarost &lt;- c(___, ___, ___, ___)\n\nbarva_oci &lt;- c(___, ___, ___, ___)\n\ndomaci_kraj &lt;- c(\"___\", \"___\", \"___\", \"___\")\n\ngeografska_sirina_dk &lt;- c(___, ___, ___, ___)\n\ngeografska_dolzina_dk &lt;- c(___, ___, ___, ___)\n\nsosolci &lt;- data.frame(___, # imena\n                      ___, # starosti\n                      ___, # barva oci\n                      ___, # domaci kraj\n                      ___, # geografska sirina\n                      ___) # geografska dolzina\n\nsosolci"
  },
  {
    "objectID": "posts/03_GIS_SI_global_raster_data_in_R.html",
    "href": "posts/03_GIS_SI_global_raster_data_in_R.html",
    "title": "GLOBALNI OKOLJSKI PODATKI V R-U",
    "section": "",
    "text": "Povzetek\n\n\n\nNa teh vajah boste:\n\nspoznali osnove rastrskih podatkov,\nspoznali bazo z globalnimi rastrskimi podatki sdmpredictors,\ndostopali in prenesli globalne rasterske podatke,\njih prikazali in smiselno obarvali z uporabo enostavnih R orodij."
  },
  {
    "objectID": "posts/03_GIS_SI_global_raster_data_in_R.html#rastrski-podatki-v-r-u",
    "href": "posts/03_GIS_SI_global_raster_data_in_R.html#rastrski-podatki-v-r-u",
    "title": "GLOBALNI OKOLJSKI PODATKI V R-U",
    "section": "Rastrski podatki (v R-u)",
    "text": "Rastrski podatki (v R-u)\nRastrski podatki so prikazani v obliki mrež, ki jih sestavljajo enake osnovne celice. Obstajajo tri različne oblike, v katerih so lahko rastrski podatki zasnovani, od katerih je kvadratna mreža najpogostejša.\n\nResolucija oziroma ločljivost je lastnost rastrov, ki nam pove kakšna je velikost posamezne celice. Pri nižjih resolucijah so celice večje in natančnost podatkov manjša. Pri višjih resolucijah so celice manjše in natančnost vecja. Odločitev, katero resolucijo uporabimo je odvisna od obsega naše raziskave (globalna, regionalna, lokalna), obravnavane vrste ali pojava, ki ga proučujemo (npr. čezoceanske migracije ali endemične, ozko razširjene vrste) in dostopnosti podatkov. Najpogostejše resolucije prostorskih podatkov, ki so danes na voljo, segajo od 10 arc minut (npr. worldclim) do 30x30 metrov (npr. landsat).\n\nProstorska orodja v R-u le redko uporabljajo podatke v tabelarni obliki. Za ta namen obstaja nekaj paketov (razširitev osnovnega R-a), v katerih se nahajajo ustrezne funkcije za pretvorbo in uporabo prostorskih podatkovnih struktur. Za rastrske podatke sta najpogosteje uporabljena:\n\nraster in\nterra.\n\nPaket raster je eden izmed najstarejših prostorskih orodij v R-u, ki je definiral različne oblike podatkovnih struktur v R-u: RasterLayer, Raster Stack in Raster Brick ter omogoča uvoz, urejanje in analizo rasterskih podatkov. Paket raster se počasi umika iz uporabe (ustvarjalci gredo v penzijo) in ga nadomeščaa paket terra.\nPaket terra je posodobljena, poenostavljena in predvsem hitrejša verzija paketa raster in sp. terra omogoča enostavnejši uvoz, urejanje in analizo tako vektorskih kot rastrskih podatkov.\nFunkcije za ustvarjanje / uvoz rastrskih podatkov in tipi rastrskih objektov so:\n\nraster() za rasterLayer: enoslojni rasterski podatkovni tip, ki hrani vrednosti v enem samem sloju. RasterLayer se uporablja za hranjenje podatkov, ki imajo en sam vidik, kot so podatki o nadmorski višini ali podatki o površini terena.\nstack() za rasterStack: večslojni rasterski podatkovni tip, ki hrani vrednosti v več slojih. RasterStack se uporablja za hranjenje podatkov, ki imajo več vidikov, kot so podatki o več vrstah klimatskih spremenljivk ali podatki o več vrstah površinskih lastnosti.\nbrick() za rasterBrick: večslojni rasterski podatkovni tip, ki je podoben RasterStack-u, vendar se najpogosteje uporablja za hranjenje velikih rasterskih slojev iz raličnih datotek na računalniku.\nrast() za SpatRaster (terra): krovna funkcija in podatkovni tip v paketu terra, ki vključuje vse zgoraj naštete podatkovne tipe iz paketa raster.\n\nMi bomo uporabljali le paket terra, ki ga moramo najprej inštalirati in potem aktivirati pred uporabo.\n\n\n\n\n\n\nNaloga\n\n\n\nOdprite nov R skript v meniju File tako, da kliknete New file in potem R script. Skript bo imel ime Untitled1 (ali Untitled2, če je že odprt prazen skript).\nShranite skript na namizje vašega računalnika in ga poimenujte Globalni rastrski podatki v R-u.\nKopirajte in prilepite spodnjo kodo v skript R, premaknite kazalec v prvo vrstico s kodo in kliknite Run. Premaknite kazalec na vsako vrstico, ki vsebuje kodo, in ponovite.\n\n\n\ninstall.packages(\"terra\")\nlibrary(terra)"
  },
  {
    "objectID": "posts/03_GIS_SI_global_raster_data_in_R.html#globalni-okoljski-podatki-v-paketu-sdmpredictors",
    "href": "posts/03_GIS_SI_global_raster_data_in_R.html#globalni-okoljski-podatki-v-paketu-sdmpredictors",
    "title": "GLOBALNI OKOLJSKI PODATKI V R-U",
    "section": "Globalni okoljski podatki v paketu sdmpredictors",
    "text": "Globalni okoljski podatki v paketu sdmpredictors\nsdmpredictors je paket v R-u, ki vsebuje globalne kopenske in morske okoljske podatke, pridobljene z različnimi metodami in iz različnih virov. Podatki so večinoma v rasterski obliki, nekateri pa tudi v vektorski. Glavna uporaba teh podatkov je za modeliranje razširjenosti organizmov v prostoru in času (na voljo so tudi podatki za prihodnost in preteklost).\nDa dostopamo do funkcij, ki nam omogočajo dostop in prenos podatkov neposredno preko serverjev, moramo paket sdmpredictors najprej inštalirati in aktivirati uporabo njegovih funkcij:\n\ninstall.packages(\"sdmpredictors\")\n\n\nlibrary(sdmpredictors) \n\nSporočilo, ki se nam izpiše, nas opozarja, da se bodo nekateri paketi za obdelavo prostorskih podatkov kmalu “upokojili”. Za zdaj še vedno vse deluje, avtorji in vzrdževalci paketa sdmpredictors pa bodo kmalu morali posodobiti paket na uporabo funkcij iz paketa terra, da bo še naprej deloval.\n\nV paketu sdmpredictors s funkcijo¸list_datasets() pogledamo kateri nabori podatkov so nam na voljo znotraj tega paketa (izpis v vaši R konzoli ne bo ustrezal izpisu v tem dokumentu):\n\nlist_datasets()\n\n\n\n\n\n\n\n\nNa voljo nam je 5 podatkovnih zbirk, od katerih sta dve morski (BioOracle, MARSPEC) in tri kopenske oziroma sladkovodne (WorldClim, ENVIREM in Freshwater). V zbirkah nam je na voljo veliko število prostorskih podatkov vključno:\n\nz geografskimi (nadmorske višine oziroma globine, tudi za preteklost ob poledenitvah, tip prsti, itd.),\ns fizikalno-kemijskimi parametri (npr. temperatura, slanost, morski tokovi itd. za morje, temperatura, padavine, ipd.),\nz biološkimi parametri (npr. primarna produkcija, tip vegetacije itd.),\nin z mnogimi, mnogimi drugimi.\n\n\nSloji v paketu sdmpredictors\nDo seznama slojev, ki so nam na voljo, lahko dostopamo s funkcijo list_layers(). Če znotraj oklepajev navedemo terrestrial = FALSE, freshwater = FALSE, marine = TRUE, se nam bodo prikazali le morski, če pa terrestrial = TRUE, freshwater = TRUE, marine = FALSE pa le kopenski. Okoljski podatki so razdeljeni na morske, kopenske in sladkovodne, po tabelah pa lahko brskate tudi z uporabo filtrov. V katerikoli okvirček v tabeli lahko vneste vrednosti, kar bo zmanjšalo nabor prikazanih slojev.\n\nMorskiKopenskiSladkovodni\n\n\n\nlist_layers(terrestrial = FALSE, freshwater = FALSE, marine = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nlist_layers(terrestrial = TRUE, freshwater = FALSE, marine = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\nlist_layers(terrestrial = FALSE, freshwater = TRUE, marine = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNaloga\n\n\n\nKopirajte in prilepite kodo iz vsakega zavihka v skript R, premaknite kazalec v prvo vrstico s kodo in kliknite Run. Premaknite kazalec na vsako vrstico, ki vsebuje kodo, in ponovite. Izpis v vaši R konzoli ne bo ustrezal izpisu v tem dokumentu, kjer sem izpis prilagodil, da vam omogoča lažje brskanje po slojih.\nNato v naslednjih 10 minutah:\n\nkliknite na povezave različnih podatkovnih zbirk in se seznanite z njimi.\nuporabite zgoraj pripravljene tabele in poglejte, kateri sloji so nam na voljo v paketu sdmpredictors.\n\nAli lahko ugotovite, koliko je vseh skupaj?"
  },
  {
    "objectID": "posts/03_GIS_SI_global_raster_data_in_R.html#prenos-slojev-iz-serverja-in-uvoz-v-r",
    "href": "posts/03_GIS_SI_global_raster_data_in_R.html#prenos-slojev-iz-serverja-in-uvoz-v-r",
    "title": "GLOBALNI OKOLJSKI PODATKI V R-U",
    "section": "Prenos slojev iz serverja in uvoz v R",
    "text": "Prenos slojev iz serverja in uvoz v R\nSloje prenesemo iz serverja s funkcijo load_layers(), tako da določimo kateri sloj ali sloje želimo (layercode = c().). Z ukazom &lt;- v istem koraku shranimo sloj v nov objekt, ki ga smiselno poimenujemo. Mi bomo najprej prenesli sloj, ki vsebuje povprečne temperature kopnega in je shranjen pod kodo WC_bio1. Zame je smiselno ime takega sloja povprecna_temp_kopno (v imenu objekta sem se namenoma izognil uporabi šumnikov, da ne pride do kakšnih neželenih težav). Ker se paket raster kmalu umika iz uporabe, bomo sloj takoj pretvorili še v terra tip rasterskih podatkov s funkcijo rast()7.\n\n\n\n\n\n\nNaloga\n\n\n\nKopirajte in prilepite kodo v skript R, premaknite kazalec v prvo vrstico s kodo in kliknite Run.\n\n\n\npovprecna_temp_kopno &lt;- terra::rast(load_layers(layercodes = c(\"WC_bio1\")))\n\n\nPreverjanje in spreminjanje lastnosti rastrskih slojev v R-u\nRastrski sloji imajo nekaj lastnosti, ki jih včasih želimo ali moramo preveriti (predvsem v smislu pravilnosti uvoza podatkov v R oziroma GIS). Med te lastnosti sodijo:\n\ngeografski obseg (območje, ki ga pokriva sloj),\nločljivost (resolucija) in s tem povezana velikost in število celic sloja,\nkoordinatni referenčni sistem sloja.\n\nZa ugotavljanje obsega (Extent) objekta SpatRaster iz paketa terra v R-u uporabimo funkcijo ext(). Ta funkcija nam izpiše koordinate za največjo vzhodno in zahodno geografsko dolžino ter največjo severno in južno geografsko širino objekta SpatRaster:\n\next(povprecna_temp_kopno)\n\nSpatExtent : -180, 180, -60, 90 (xmin, xmax, ymin, ymax)\n\n\n\nFunkcija res() iz paketa terra v R-u služi za ugotavljanje ločljivosti (resolucije) rasterskega sloja. Ločljivost oznacuje velikost celic v rasterskem sloju, enota je odvisna od enote v kateri je sloj definiran (geografske stopinje ali merske enote, npr. metri, kilometri). Funkcija nam vrne vrednosti, ki predstavljata dolžino stranice celice.\n\nres(povprecna_temp_kopno)\n\n[1] 0.08333333 0.08333333\n\n\nEnota v našem primeru so geografske stopinje, kar bi bilo preračunano v mersko enoto približno 1 km.\n\nFunkcija ncell iz paketa terra v R-u služi za ugotavljanje števila celic v rasterskem sloju in nam poda število celic v izbranem rasteru.\n\nncell(povprecna_temp_kopno)\n\n[1] 7776000\n\n\n\nFunkcija crs nam služi za ugotavljanje koordinatnega referencega sistema rasterskega sloja. Z njo lahko koordinatni sistem tudi določimo (če le-ta še ni določen in ga poznamo: v našem primeru so podatki v koordinatnem sistemu World Geographic System 1984 ali WGS 1984, ki ima kodo epsg 4326. V prvem koraku bom preverili koordinantni referenčni sistem, v drugem pa ga bomo ustrezno določili:\n\ncrs(povprecna_temp_kopno, describe = TRUE)\n\n     name authority code area         extent\n1 unknown      &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; NA, NA, NA, NA\n\ncrs(povprecna_temp_kopno) &lt;- \"epsg:4326\"\n\ncrs(povprecna_temp_kopno, describe = TRUE)\n\n    name authority code  area             extent\n1 WGS 84      EPSG 4326 World -180, 180, 90, -90\n\n\n\nFunkcija layer_stats iz paketa sdmpredictors v R-u služi za izračun povprečja in standardnega odklona vrednosti za posamezen sloj. Funkcija zahteva rasterski sloja (ali več njih) in vrne tabelo z rezultati ter vnaprej izloči manjkajoce vrednosti (NA). Poleg opisne statistike dobimo tudi vrednosti dveh indeksov prostorske avtokorelacije (stopnje koreliranosti vrednosti v celicah, ki so blizu skupaj):\n\n“Moran’s I” meri splošno raven avtokorelacije v rasterskem podatku,\n“Geary’s c” meri specifično raven avtokorelacije za zaporedne vrednosti v rastrskem podatku.\n\n\nlayer_stats(c(\"WC_bio1\"))"
  },
  {
    "objectID": "posts/03_GIS_SI_global_raster_data_in_R.html#prikaz-rastrskih-slojev",
    "href": "posts/03_GIS_SI_global_raster_data_in_R.html#prikaz-rastrskih-slojev",
    "title": "GLOBALNI OKOLJSKI PODATKI V R-U",
    "section": "Prikaz rastrskih slojev",
    "text": "Prikaz rastrskih slojev\nRastrske podatke lahko enostavno prikažemo z uporabo funkcije plot(). Če smo predhodno aktivirali paket terra, bo funkcija samodejno prikazala in obarvala rastrske podatke, ki jih bom navedli znotraj oklepajev:\n\nplot(povprecna_temp_kopno)\n\n\n\n\n\nTa prikaz že v osnovi ni slab, ampak lahko naredimo še boljšega, kajne? Izberemo lahko barve, ki bodo bolje predstavljale hladne in tople temperature na kopnem.\n\n\n\n\n\n\nNamig\n\n\n\nKako so definirane barve v R-u smo si že pogledali na prejšnjih vajah. Posamezno barvo lahko določimo z z njenim imenom, seznam tukaj. Lahko pa jo določimo s hex RGB ali RGB vrednostjo (npr. za belo barvo: \"white\"; hex RGB: \"#FFFFFF\"; RGB: rgb(255,255,255, max = 255))\nKer imamo opravka s številčno vrednostjo, ki ima precej velik razpon (poglejte rezultate iz tabele layer_stats), bomo potrebovali več kot le nekaj izbranih barv. Uporabimo lahko vnaprej določene nabore barv, ki se v R-u imenujejo barvna palete: color palette in pomenijo niz barv, ki prehajajo od temnejših k svetlejšim barvam (zaporedne) ali od temnih odtenkov ene barve do temnih odtenkov druge (divergentne).\n\n\n\n\n\n\n\n\nNaloga\n\n\n\nObravnavamo rastrski sloj, ki vsebuje povprečne temperature na kopnem. Katera od spodnih barvnih palet se vam zdi najprimernejša za uporabo v našem specifičnem primeru?\n\n\n\nČeprav je barvna paleta vnaprej pripravljena, jo moramo prilagoditi našim podatkom. Najmanjša vrednost sloja povprecna_temp_kopno je -27.4, največja pa 31.6 °C (te vrednosti lahko razberete iz rezultatov tabele layer_stats zgoraj). Preprost in učinkovit način za dosego tega je funkcija colorNumeric() iz paketa leaflet (ki ste ga namestili na prejšnjih vajah).\n\n\n\n\n\n\nNamig\n\n\n\nČe neko funkcijo iz paketa uporabimo samo enkrat, lahko ukaz library preskočimo, saj ne potrebujemo vseh funkcionalnosti paketa. Namesto tega lahko uporabimo naslednjo sintakso: leaflet::colorNumeric(), ki bo delovala, če je paket že nameščen na vašem računalniku (to smo naredili na prejšnjih vajah, tako da bi načeloma moralo. V nasprotnem sem za vas pripravil ukaz instal.packages(\"leaflet\"), izpred katerega izbrišite # in ga zaženite).\nRezultat funkcije colorNumeric moramo shraniti v objekt, da ga bomo lahko uporabili pozneje. To nam daje “odgovornost”, da zanj izberemo smiselno ime. Kaj menite o barve_temp_kopno?\n\n\nPripravljeno imamo barvno paleto, poznamo obseg vrednosti našega rastrskega sloja, kljub temu pa moramo narediti še eno stvar. In sicer, če uporabimo paleto \"RdBu\", bodo nizke vrednosti obarvane z rdečo, višje pa z modro, kar je ravno obratno od željenega. Zato lahko rečemo R-u, da naj barve uporabi obratno, saj je modra primernejša za nižje temperature, rdeča pa za toplejše. To dosežemo z dodatkom reverse = TRUE.\n\n\n\n\n\n\nNaloga\n\n\n\nKopirajte in prilepite spodnjo kodo v skript R, premaknite kazalec v prvo vrstico s kodo in kliknite Run.\n\n\n\n# instal.packages(\"leaflet\")\n\nbarve_temp_kopno &lt;- leaflet::colorNumeric(palette = \"RdBu\", \n                                    domain = c(-27.5, 31.7),\n                                    reverse = TRUE)\n\nV osnovni ukaz plot() bomo sedaj dodali še našo vnaprej pripravljeno paleto barv z argumentom col =. Uporabimo bomo našo paleto barv barve_temp_kopno, ki ji bomo povedali naj med najnižjo in najvišjo vrednostjo rastrskega sloja temepratur kopnega uporabi 999 različnih odtenkov izbrane barvne palete (seq(-27.5, 31.7, length.out = 999)). Da bo prikaz še informativnejši, bomo z argumentom main = zemljevidu dodali še naslov.\n\n\n\n\n\n\nNaloga\n\n\n\nKopirajte in prilepite spodnjo kodo v skript R, premaknite kazalec v prvo vrstico s kodo in kliknite Run.\n\n\n\nplot(povprecna_temp_kopno, \n     col = barve_temp_kopno(seq(-27.5, 31.7, length.out = 999)),\n     main = \"Povprečna temperatura kopnega (°C)\")\n\n\n\n\n\nZemljevid lahko tokrat izvozimo kot sliko (Export -&gt; Save as image):\n\n\nIzberemo namizje našega računalnika (Desktop), izberemo smiselno ime (Povprečna temperatura kopnega) in kliknemo Save:"
  },
  {
    "objectID": "posts/04_SDMs_Model evaluation and representation.html",
    "href": "posts/04_SDMs_Model evaluation and representation.html",
    "title": "MODEL EVALUATION AND REPRESENTATION",
    "section": "",
    "text": "Summary\n\n\n\nIn this lab you will:\n\nclassify model predictions into binary outcome using selected threshold,\ncompose confusion matrix and calculate specificity and sensitivity of the model,\nplot the ROC curve and calculate AUC of the models,\nrepresent the models in the geographic space."
  },
  {
    "objectID": "posts/04_SDMs_Model evaluation and representation.html#before-we-start",
    "href": "posts/04_SDMs_Model evaluation and representation.html#before-we-start",
    "title": "MODEL EVALUATION AND REPRESENTATION",
    "section": "Before we start",
    "text": "Before we start\n\n\n\n\n\n\nTask\n\n\n\n\nOpen the folder Introduction to species distribution models,\nStart RStudio from the Rproject icon named Introduction to species distribution models.\nOpen the R script named Erebia stirius.\nWhen following this lab, continue to copy & paste the code in the script so it is organised as it is in teaching materials."
  },
  {
    "objectID": "posts/04_SDMs_Model evaluation and representation.html#lab-plan",
    "href": "posts/04_SDMs_Model evaluation and representation.html#lab-plan",
    "title": "MODEL EVALUATION AND REPRESENTATION",
    "section": "Lab plan",
    "text": "Lab plan"
  },
  {
    "objectID": "posts/04_SDMs_Model evaluation and representation.html#data-import-from-previous-labs",
    "href": "posts/04_SDMs_Model evaluation and representation.html#data-import-from-previous-labs",
    "title": "MODEL EVALUATION AND REPRESENTATION",
    "section": "Data import from previous labs",
    "text": "Data import from previous labs\nFirst, we will load the data that we prepared on our last lab. The dataset is saved as .RDS files in 01_data folder. We will import it using readRDS() function and assign it to the objects with the same names as in lab 2: stirius_pa_final. This is a dataframe in which we prepared species presence points and pseudo-absence points and extracted values for not correlated environmental variables (bio2, bio4, bio6, bio 8, bio15, bio17 and bio18).\n\nstirius_pa_final &lt;- readRDS(\"01_data/stirius_pa_final.RDS\")"
  },
  {
    "objectID": "posts/04_SDMs_Model evaluation and representation.html#recap-from-previous-lab---opening-the-black-box",
    "href": "posts/04_SDMs_Model evaluation and representation.html#recap-from-previous-lab---opening-the-black-box",
    "title": "MODEL EVALUATION AND REPRESENTATION",
    "section": "Recap from previous lab - opening the black box",
    "text": "Recap from previous lab - opening the black box\nThe task of a modelling algorithm is to identify potentially complex non-linear relationships in between presence-absence locations and multi-dimensional environmental space and project them to 2 dimensional geographic space.\nModeling algorithms will identify areas with similar environments to where the species has been observed. Most algorithms generally do not return the presence (1) or absence (0) of the species, but the probability or suitability for finding the species in any given cell on a map based on observed species-environment relationships.\nThere is plethora of different modelling algorithms used for modelling species/habitat distribution in the literature, that broadly belong to:\n\nstatistical or regression (GLMs, GAMs, MARS, MDA & FDA),\nmachine learning (RF, BRT, MAXENT) and\nartificial intelligence (ANN, SVM).\n\nDue to high complexity of this field, we used only two following algorithms and just briefly addressed their main strengths and weaknesses:\n\nGeneralized Linear Models (GLM) and\nRandom Forests (RF).\n\n\nGeneralised linear models (GLM; Guisan et al., 2017, p. 167)\nWe built the model backwards, starting by a full model. This model included all possible environmental variables within our dataset and was the most complex of all models. Within glm() function we specified:\n\npresence ~ bio2 + bio4 + bio6 + bio8 + bio15 + bio17 + bio18 (presence explained by a linear combination of all bio variables),\nfamily = \"binomial\" (our response variable - presence - follows binomial distribution (0 and 1) and the model needs to take this into account)\ndata = stirius_pa_final (to tell the model, where to look for the data).\n\nand saved the results of this call to an object named glm_full:\nWe explored the results of glm_full using the summary() function, for interpretation of Coefficients, P-Values, Deviance and Akaike Information Criteria look at the previous lab materials.\nWe decided to remove bio17 as it was not significant according to the model. We rebuilt the model and based on its results also discarded the bio2 and bio18 variable. The last model that we built and also selected as the best was as follows:\n\nglm_4 &lt;-\n    glm(\n        presence ~ wc2.1_2.5m_bio_4 + wc2.1_2.5m_bio_6 + wc2.1_2.5m_bio_8 + wc2.1_2.5m_bio_15,\n        family = \"binomial\",\n        data = stirius_pa_final\n    )\n\n\n\n\nRandom forest (RF; Guisan et al., 2017, p. 203)\nRandom forests or random decision forests are an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time. The random forest model essentially represents an assembly of a selected number of decision trees, a flowchart-like structure made of nodes and branches. At each node, a split on the data is performed based on one of the input features, generating two or more branches as output.\n\n\n\nFrom decision tree to a random forest.\n\n\n\nThe random forest model can be fitted using randomForest() function from the randomForest package. A call to build a random forest needs the following arguments:\n\npresence ~ bio2 + bio4 + bio6 + bio8 + bio15 + bio17 + bio18 (presence explained by a linear combination of all bio variables),\ndata = stirius_pa_final (to tell the model, where to look for the data),\n\nand the following two we added optionally:\n\nimportance = TRUE (To assess importance of predictors in the model),\nna.action = na.omit (A function to specify the action to be taken if NAs are found - we will disregards NAs if present).\n\nand saved the results to an object named rf_full:\n\nlibrary(randomForest)\n\nrf_full &lt;- randomForest(presence ~ wc2.1_2.5m_bio_2 + wc2.1_2.5m_bio_4 + wc2.1_2.5m_bio_6 + wc2.1_2.5m_bio_8 + wc2.1_2.5m_bio_15 + wc2.1_2.5m_bio_17 + wc2.1_2.5m_bio_18, \n                        data = stirius_pa_final,\n                        importance = TRUE,\n                        na.action = na.omit)\n\n\n\n\n\n\n\nTask\n\n\n\nCopy and paste the code for both models as we will need them throughout this lab."
  },
  {
    "objectID": "posts/04_SDMs_Model evaluation and representation.html#assesing-model-accuracy-and-predictive-performance",
    "href": "posts/04_SDMs_Model evaluation and representation.html#assesing-model-accuracy-and-predictive-performance",
    "title": "MODEL EVALUATION AND REPRESENTATION",
    "section": "Assesing model accuracy and predictive performance",
    "text": "Assesing model accuracy and predictive performance\nOverview of the topic and exhaustive suggestions of literature in Guisan et al. (2017, Chapter 15). Explanatory videos of Sensitivity and specificity and ROC & AUC.\nTo evaluate models predictive power, the model predictions are classified into four categories:\n\nTrue positive (TP; cases when the model correctly predicted positive outcome - 1)\nTrue negative (TN; cases when the model correctly predicted negative outcome - 0)\nFalse positive (FP; cases when the outcome was negative (0), but the model predicted positive outcome(1))\nFalse negative (FN; cases when the outcome was positive (1), but the model predicted negative outcome(0)).\n\nand displayed in a confusion matrix:\n\n\n\nConfusion matrix.\n\n\nIMPORTANT NOTE: Binary model predictions are required (i.e. 0 and 1) in order to complete the confusion matrix. As our models will provide continuous predictions, we need to set a threshold that will divide our data into binary categories (Pearson, 2010, pp. 77).\nUsing these four values (TP, TN, FP, FN) we can compute many different metrics about the model accuracy, precision, predictive power, etc., of which we are now interested in:\n\nsensitivity, the ability of a model to correctly identify true positive cases (TP / [TP + FN]) &\nspecificity, the ability of a model to correctly identify true negative cases (TN / [TN + FP]).\n\n\n\n\nA Receiver Operating Characteristic curve (ROC curve) is a graph showing the performance of a classification/regression model for continuous response variable at all possible thresholds. This curve plots the changes in the above mentioned two parameters as:\n\nTrue Positive Rate (sensitivity) on y-axis &\n1 - True Negative Rate (specificity) on x- axis.\n\nSensitivity and specificity are used, because these two measures take into account all four elements of confusion matrix. The ROC curve thus describes relationship between the proportion of observed presences correctly predicted (sensitivity) and the proportion of observed (pseudo) absences incorrectly predicted (1 - specificity). The model with perfect predictions would generate a line following left axis and top of the plot. A model with random predictions would follow a diagonal:\n\n\n\nROC curve.\n\n\nThe Area Under the ROC Curve (AUC) test is derived from the ROC curve. Predictive performance of a model accross ful range of thresholds is measured as the area under the ROC curve, expressed as a proportion of the total area of square defined by the axes. AUC metric is desirable:\n\nas it is scale-invariant. It measures how well predictions are ranked, rather than their absolute values.\nas it is classification-threshold-invariant. It measures the quality of the model’s predictions irrespective of what classification threshold is chosen.\n\nAUC can range in values from 0 to 1. However, a model which predictions are random would have an AUC of 0.5 and the model which predictions are 100% correct has an AUC of 1.0."
  },
  {
    "objectID": "posts/04_SDMs_Model evaluation and representation.html#application-of-roc-and-auc-analysis-to-our-models",
    "href": "posts/04_SDMs_Model evaluation and representation.html#application-of-roc-and-auc-analysis-to-our-models",
    "title": "MODEL EVALUATION AND REPRESENTATION",
    "section": "Application of ROC and AUC analysis to our models",
    "text": "Application of ROC and AUC analysis to our models\n\nGeneralised Linear Model\nFirst, we will need to extract predicted values from glm_4. The function glm() calculated them by default and store them in the $fitted.values section of the glm_4 object. We will add these values to our starting dataframe stirius_pa_final using $ function from base package. A small but important tweak in the code is putting the predicted values glm_4$fitted.values within unname(). This step is needed, as otherwise row names are attached for some reason and we would not be able to apply subsequent functions to the actual values.\nThe function options(scipen = 999, digits = 4) will ensure that the numbers will be displayed as decimals (i.e. -0.0000000000000001811) not as scientific notation (i.e. -1.780798e-16) and thus easier to understand.\n\noptions(scipen = 999, digits = 4) \n\nstirius_pa_final$glm_4_predictions &lt;- unname(glm_4$fitted.values)\n\nTo see how our table looks like with the new column:\n\nView(stirius_pa_final)\n\n\nNext visual will show us how the actual presences and pseudo-absences are distributed along the predicted value of the GLM model. Right away, I added an arbitrary threshold line at 0.55 (geom_vline(xintercept = 0.55)), that seems reasonable to classify our model output to binary categories:\n\nlibrary(ggplot2)\n\nggplot(stirius_pa_final,  \n       aes(x = glm_4_predictions, \n           fill = as.factor(presence))) + \n    geom_density(alpha = 0.5) + \n    xlim(c(0,1)) +\n    theme_classic() +\n    geom_vline(xintercept = 0.55, col = \"red\", lwd = 1.2) + \n    ylab(\"Density\") +\n    xlab(\"Predicted probability of occurrence - GLM\")\n\n\n\n\nIn the next step, we use this (or any other choosen threshold) to create a column with binary classification of our model predictions. We will save this classifications in a new column glm_classification with mutate() function. To create the binary classification, we can use the case_when() function from dplyr. We tell this function to create a value of 0 when glm_4_predictions &lt; 0.55 and value of 1 when glm_4_predictions &gt;= 0.55.\n\nlibrary(dplyr)\n\nstirius_pa_final &lt;-\n    mutate(\n        stirius_pa_final,\n        glm_classification = case_when(glm_4_predictions &lt; 0.55 ~ \"0\",\n                                       glm_4_predictions &gt;= 0.55 ~ \"1\"))\n\n\nView(stirius_pa_final)\n\n\nTo create a confusion matrix, we will use xtabs() function to which we need to specifiy, the two columns with 0s and 1s (~ glm_classification + presence) and the dataframe where the two are stored (stirius_pa_final). The function will go through the column and counts pairs of 0 and 0, 1 and 1, 0 and 1, 1 and 0:\n\nxtabs( ~ glm_classification + presence, stirius_pa_final)\n\n                  presence\nglm_classification   0   1\n                 0 105  62\n                 1  45  88\n\n\nUsing these number, we can calculate the sensitivity and specificity\n\nsensitivity (TP / [TP + FN]) and\n\nspecificity (TN / [TN + FP])\n\nof glm_4 at 0.55 threshold:\n\n#sensitivity (TP / [TP + FN])\n\n88 / 150\n\n[1] 0.5867\n\n# specificity (TN / [TN + FP])\n\n105 / 150\n\n[1] 0.7\n\n\n\n\n\nRandom forest model\nFor random forest model we have to create predictions manually. We need to use predict() function, which requires:\n\na model, that will be used for predictions (rf_full) and\nthe predictor variables, that model will use to calculate predictions (bio2 - bio18). The simplest way is to select() them from stirius_pa_final.\n\nWe will add this predictions to stirius_pa_final using mutate() as above. Again a small but important tweak in the code is putting the predicted values rf_full_prediction within unname(). This step is needed, as otherwise row names are attached for some reason and we would not be able to apply subsequent functions to the actual values:\n\nrf_full_prediction &lt;- predict(rf_full, \n                              dplyr::select(stirius_pa_final,\n                                            wc2.1_2.5m_bio_2:wc2.1_2.5m_bio_18))\n\nstirius_pa_final &lt;- stirius_pa_final %&gt;% \n    dplyr::mutate(rf_full_predictions = unname(rf_full_prediction))\n\nLets also visualise how the actual presences and pseudo-absences are distributed along the predicted value of the RF model. Right away, I added an arbitrary threshold line at 0.42 (geom_vline(xintercept = 0.42)), that seems reasonable to classify our model output to binary categories:\n\nggplot(stirius_pa_final , aes(x = rf_full_prediction, fill = as.factor(presence))) +\n    geom_density(alpha = 0.5) +\n    xlim(c(0,1)) +\n    theme_classic() +\n    geom_vline(xintercept = 0.42,col = \"red\", lwd = 1.2) +\n    ylab(\"Density\") +\n    xlab(\"Predicted probability of occurrence - RF\")\n\n\n\n\nIn the next step, we use this (or any other chosen threshold) to create a column with binary classification of our model predictions. We will save this classifications in a new column glm_classification with mutate() function. To create the binary classification, we can use the case_when() function from dplyr. We tell this function to create a value of 0 when rf_full_predictions &lt; 0.42 and value of 1 when rf_full_predictions &gt;= 0.42.\n\nstirius_pa_final &lt;- stirius_pa_final %&gt;% \n        mutate(rf_classification = case_when(rf_full_predictions &lt; 0.42 ~ \"0\", \n                                             rf_full_predictions &gt;= 0.42 ~ \"1\"))\n\nTo create a confusion matrix, we will use xtabs() function to which we need to specifiy, the two columns with 0s and 1s (~ rf_classification + presence) and the data frame where the two are stored (stirius_pa_final). The function will go through the columns and counts pairs of 0 and 0, 1 and 1, 0 and 1, 1 and 0:\n\nxtabs( ~ rf_classification + presence, stirius_pa_final)\n\n                 presence\nrf_classification   0   1\n                0 145   0\n                1   5 150\n\n\nAnd we use this value to calculate:\n\nsensitivity (TP / [TP + FN]) and\n\nspecificity (TN / [TN + FP])\n\nof Random forest model at 0.42 threshold:\n\n#sensitivity (TP / [TP + FN])\n\n150 / 150\n\n[1] 1\n\n# specificity (TN / [TN + FP]\n\n144 / 150\n\n[1] 0.96\n\n\n\n\n\nPlot ROC curve and calculate AUC value with ROCR package\nModel evaluation using ROCR package starts with creating a prediction object. This function is used to transform the input data into a standardized format. To the prediction() function, we need to provide a vector containing the predictions (stirius_pa_final$glm_4_predictions) and a vector containing the true class labels or values (stirius_pa_final$presence), both must have the same dimensions. We supply these prediction to a function performance(), which can evaluate different model performance metrics. As we want to plot the ROC curve, we need to evaluate True positive rate (or sensitivity; \"tpr\") and false positive rate (or 1 - specificity; \"fpr\"). We save the results of these calculations to an object called roc_GLM:\n\ninstall.packages(\"ROCR\")\n\n\nlibrary(ROCR)\n\nroc_GLM &lt;- ROCR::performance(prediction(stirius_pa_final$glm_4_predictions, \n                                        stirius_pa_final$presence),\n                             \"tpr\", # sensitivity\n                             \"fpr\") # 1 - specificity\n\nTo plot the ROC curve for glm_4 model we simply use plot() function. To aid our interpretation of the plot, we will also add the diagonal with abline() starting at (0,0) and going to (1,1). I colored it grey, so it is not the focus of the plot:\n\nplot(roc_GLM, lwd = 3)\nabline(a = 0, b = 1, col = \"grey\", lwd = 2)\n\n\n\n\nWe repeat the same proces for random forest model, only these time we need to evaluate its prediction (stirius_pa_final$rf_full_predictions) towards actual values of presences (stirius_pa_final$presence):\n\nroc_rf &lt;- ROCR::performance(prediction(rf_full_prediction, \n                                       stirius_pa_final$presence),\n                            \"tpr\", # sensitivity\n                            \"fpr\") # 1 - specificity\n\n\nplot(roc_rf, lwd = 3)\nabline(a = 0, b = 1, col = \"grey\", lwd = 2)\n\n\n\n\nFor easier comparison, we plot both on the same graph, by add = TRUE in the second call to plot. Note that colors were added to both calls and the legend, to be able to distinguish between the two ROC curves. Lastly, we can also add the points for the thresholds we calculate above for GLM (0.55) and RF model (0.42):\n\nplot(roc_GLM, col = \"green\", lwd = 3)\n\nabline(a = 0, b = 1, col = \"grey\", lwd = 2)\n\n\nplot(roc_rf, add = TRUE, col = \"blue\", lwd = 3)\n\nlegend(\"bottomright\", \n       legend = c(\"GLM\", \"RF\"),\n       col = c(\"green\", \"blue\"),\n       lwd = 3)\n\npoints(x = c((1 - 0.96), (1 - 0.7)), # 1 - specificity\n       y = c(1, 0.586), # sensitivity\n       col = \"red\",\n       lwd = 3)\n\n\n\n\n\nThe Area Under the ROC Curve (AUC) test is derived from the ROC curve. Predictive performance of a model across full range of thresholds is measured as the area under the ROC curve, expressed as a proportion of the total area of square defined by the axes. AUC can range in values from 0 to 1. However, a model which predictions are random would have an AUC of 0.5 and the model which predictions are 100% correct has an AUC of 1.0.\n\n\n\nAUC example.\n\n\nAUC calculation using ROCR package starts with creating a prediction object. To the prediction() function, we need to provide a vector containing the predictions (stirius_pa_final$glm_4_predictions or stirius_pa_final$rf_full_predictions) and a vector containing the true class labels or values (stirius_pa_final$presence), both must have the same dimensions. We supply these prediction to a function performance(), which can evaluate different model performance metrics. As we want to calculate the AUC we specify the argument measure = \"auc\"). We extract the actual value of AUC by @y.values:\n\nROCR::performance(prediction(stirius_pa_final$glm_4_predictions, \n                             stirius_pa_final$presence),\n                             measure = \"auc\")@y.values\n\n[[1]]\n[1] 0.7216\n\nROCR::performance(prediction(stirius_pa_final$rf_full_prediction, \n                             stirius_pa_final$presence), \n                   measure = \"auc\")@y.values\n\n[[1]]\n[1] 0.9979\n\n\nAUC is one of many test statistics to evaluate model predictive performance. Among benefits of AUC, there are also some drawbacks of the metric. Most notably, AUC was demonstrated for being heavily dependent on the relative occupied area: models for more restricted (specialised) species get generally higher AUC, while models for species with wider geographic distributions (generalists) get generally lower AUC values.\nAUC is thus often combined with other metrics for model predictive power (Pearson 2010, pp. 78; Guisan et al., 2017, pp. 254):\n\nTrue Skill Statistics (TSS)\n(weigthed) Cohen’s kappa,\narea under precision - recall curve (AUC PR),\netc."
  },
  {
    "objectID": "posts/04_SDMs_Model evaluation and representation.html#model-representation",
    "href": "posts/04_SDMs_Model evaluation and representation.html#model-representation",
    "title": "MODEL EVALUATION AND REPRESENTATION",
    "section": "Model representation",
    "text": "Model representation\n\nWithin research area (buffers)\nFirst we load the data created in our second lab in which we cropped the environmental data to the buffer created. It was saved as bioclim_stirius.RDS and we will save it to an object of the same name bioclim_stirius.RDS. Due to some requirements of the terra package, we need to use the unwrap function on the imported raster layers to make them functional:\n\nlibrary(terra)\n\nbioclim_stirius &lt;- unwrap(readRDS(\"01_data/bioclim_stirius.RDS\"))\n\nnames(bioclim_stirius)\n\n[1] \"wc2.1_2.5m_bio_2\"  \"wc2.1_2.5m_bio_4\"  \"wc2.1_2.5m_bio_6\" \n[4] \"wc2.1_2.5m_bio_8\"  \"wc2.1_2.5m_bio_15\" \"wc2.1_2.5m_bio_17\"\n[7] \"wc2.1_2.5m_bio_18\"\n\n\nTo represent the model within our reseach area, we need to use a predict() function from terra package. The difference is, that we will use the raster object for predictions (bioclim_stirius) and the results itself will be a raster layer that we will name glm_geographic_prediction. We need to specify, that we want the predictions to be of a type \"response\" and which model the predict should use to calculate predictions (glm_4):\n\nglm_geographic_prediction &lt;- predict(bioclim_stirius,\n                                             glm_4,\n                                             type = \"response\")\n\nTo visualise glm_geographic_prediction with leaflet we first need to install the development version of the package:\n\nremotes::install_github(\"rstudio/leaflet\")\n\nNext, we need to use one of the predefined palette of colors that we will save to pal1 object using colorNumeric() function: the data we are plotting are continuous numbers. We will use the \"reds\" pallete, set the possible range of values between 0 and 1 (domain = c(0, 1)) and set the color for NAs to be transparent:\n\nlibrary(leaflet)\n\npal1 &lt;- colorNumeric(\"Reds\", \n                     domain = c(0,1),\n                     na.color = \"transparent\")\n\nWe will plot the GLMs geographic predictions with plet() function in which we need to define the basemap (tile =), collors that will be used (col =), the name of the legend (main =) and the transparency of the plotted raster (alpha =):\n\nplet(glm_geographic_prediction, \n            tile = \"Esri.WorldImagery\",\n            col = pal1,\n            main = \"Probability of presence\",\n            alpha = 1) \n\n\n\n\n\n\nAn repeat the same procedure for Random Forest model:\n\nrf_geographic_prediction &lt;- predict(bioclim_stirius,\n                                            rf_full,\n                                            type = \"response\")\n\n\nplet(rf_geographic_prediction, \n            tile = \"Esri.WorldImagery\",\n            col = pal1,\n            main = \"Probability of presence\",\n            alpha = 1) \n\n\n\n\n\n\n\nExtrapolation of model results outside of the research area\nWe will limit the extent of extrapolation to the wider area of Alps. We define it using function ext(), where we specify the outer bounds of the range we want to select.\n\nalps_extent &lt;- ext(6, # minimum longitude\n                   17, # maximum longitude\n                   44, # minimum latitude\n                   48) # maximum latitude\n\nWe will need the global bioclimatic data again, that we will crop by the extent created:\n\nbioclim_data &lt;- geodata::worldclim_global(var = \"bio\",\n                                          res = 2.5,\n                                          path = \"01_data\")\n\nalps_present &lt;- crop(x = bioclim_data, y = alps_extent)\n\nnames(alps_present)\n\n [1] \"wc2.1_2.5m_bio_1\"  \"wc2.1_2.5m_bio_2\"  \"wc2.1_2.5m_bio_3\" \n [4] \"wc2.1_2.5m_bio_4\"  \"wc2.1_2.5m_bio_5\"  \"wc2.1_2.5m_bio_6\" \n [7] \"wc2.1_2.5m_bio_7\"  \"wc2.1_2.5m_bio_8\"  \"wc2.1_2.5m_bio_9\" \n[10] \"wc2.1_2.5m_bio_10\" \"wc2.1_2.5m_bio_11\" \"wc2.1_2.5m_bio_12\"\n[13] \"wc2.1_2.5m_bio_13\" \"wc2.1_2.5m_bio_14\" \"wc2.1_2.5m_bio_15\"\n[16] \"wc2.1_2.5m_bio_16\" \"wc2.1_2.5m_bio_17\" \"wc2.1_2.5m_bio_18\"\n[19] \"wc2.1_2.5m_bio_19\"\n\nplot(alps_present)\n\n\n\n\nWe use function predict() from terra package to project habitat suitability of our species to extrapolatated geographical extent. Within it, we specify which one of our models we want ot use (glm_4 or rf_full) and which object contains raster layer(s) with bioclimatic variables (alps.present):\n\nalps_prediction_rf &lt;- predict(alps_present,\n                              rf_full,\n                              type = \"response\")\n\nalps_prediction_glm &lt;- predict(alps_present,\n                               glm_4,\n                               type = \"response\")\n\nWe will use this predictions and map it with plet() with color palette going from 0 (not suitable) to 1 (suitable habitat), the pal1.\nThe GLM extrapolation:\n\nplet(alps_prediction_glm, \n            tile = \"Esri.WorldImagery\",\n            col = pal1,\n            main = \"Probability of presence\",\n            alpha = 1) \n\n\n\n\n\n\nThe random forest extrapolation:\n\nplet(alps_prediction_rf, \n            tile = \"Esri.WorldImagery\",\n            col = pal1,\n            main = \"Probability of presence\",\n            alpha = 1) \n\n\n\n\n\n\n\n\nAnd save some of the created object for further use:\n\nsaveRDS(glm_geographic_prediction, \"01_data/glm_geographic_prediction.rds\")\n\nsaveRDS(rf_geographic_prediction, \"01_data/rf_geographic_prediction.rds\")\n\nsaveRDS(alps_prediction_rf, \"01_data/alps_prediction_rf.rds\")\n\nsaveRDS(alps_prediction_glm, \"01_data/alps_prediction_glm.rds\")"
  },
  {
    "objectID": "posts/04_SDMs_Model evaluation and representation.html#assignment",
    "href": "posts/04_SDMs_Model evaluation and representation.html#assignment",
    "title": "MODEL EVALUATION AND REPRESENTATION",
    "section": "Assignment",
    "text": "Assignment\n\n\n\n\n\n\nTask\n\n\n\n\nOpen R script that you named after the species you choose to work on.\nCopy - paste today's code from the Erebia stirius script to the end of your script.\nAdapt the code to achieve the following:\n\n3.1) add the columns for predictions and classifications at selected threshold for the GLM and RF model,\n3.2) compose confusion matrix and calculate sensitivity and specificity of both models,\n3.3) plot the ROC curves and calculate AUC values for both models,\n3.4) create visual representation of your model within research area (buffer) and extrapolate to wider area.\n3.5) save the script with the code for your species,\n3.6) make sure that the project folder will be available to you next week at the labs (either store it on USB, cloud or similar, in case it gets deleted from computers)."
  },
  {
    "objectID": "posts/04_GIS_SI_Rasterski_podatki_z_visoko_locljivostjo.html",
    "href": "posts/04_GIS_SI_Rasterski_podatki_z_visoko_locljivostjo.html",
    "title": "RASTRSKI PODATKI Z VISOKO LOČLJIVOSTJO V R-U",
    "section": "",
    "text": "Povzetek\n\n\n\nNa teh vajah boste:\n\nspoznali bazo podatkov geodata, ki vključuje rastrske podatke z visoko ločljivostjo,\ndostopali in prenesli rasterske podatke za nadmorske višine Slovenije,\nizračunali in prikazali naklon, aspekt in osončenost terena v Sloveniji,\ndostopali do slojev mesečnih temperatur Slovenije za sedanjost in dva scenarija za prihodnost,\nizračunali razliko v temperaturi ter nove sloje prikazali in smiselno obarvali z uporabo enostavnih R orodij."
  },
  {
    "objectID": "posts/04_GIS_SI_Rasterski_podatki_z_visoko_locljivostjo.html#rastrski-podatki-z-visoko-prostorsko-in-casovno-resolucijo-v-paketu-geodata",
    "href": "posts/04_GIS_SI_Rasterski_podatki_z_visoko_locljivostjo.html#rastrski-podatki-z-visoko-prostorsko-in-casovno-resolucijo-v-paketu-geodata",
    "title": "Fine scale raster data in R",
    "section": "",
    "text": "Danes si bomo na vajah pogledali še paket geodata, ki vsebuje funkcije za dostop do različnih rastrskih podatkov z visoko prostorsko in casovno resolucijo, med drugim:\n\nklimatskih podatkov,\nrabe tal,\ndigitalni model nadmorskih visin,\ntip prsti in kamnin,\ndrzavne in administrativne meje, itd.\n\nPaket najprej instaliramo (samo enkrat, ce ga se nismo) in omogocimo uporabo funkcij (vedno, ko zazenemo R ali RStudio):\n\n\nShow the code\ninstall.packages(\"geodata\")\n\n\n\n\nShow the code\nlibrary(geodata)\n\n\n\n\nShow the code\n?`geodata-package`\n\n\n\nNajprej bomo nalozili podatke za nadmorske visine v Sloveniji z resolucijo/locljivostjo 30 sekund (~km x km) ), ki so na voljo v paketu geodata. Do teh podatkov dostopamo s funkcijo elevation_30s(), ki od nas zahteva dve dodatni specifikaciji:\n\ndrzavo, za katero zelimo podatke (country = \"SI\") in\nmesto na racunalniku, kamor bodo podatki shranjeni (path = \"01_data\").\n\nRezultat shranimo v nov objekt slovenija_DMV:\n\n\nShow the code\nslovenija_DMV &lt;- elevation_30s(country = \"SI\", path = \"01_data\")\n\n\nCe je ukaz deloval, bo po nekaj sekundah v mapi 01_data nova datoteka, ki vsebuje podatke o nadmorskih visinah v Sloveniji. S funkcijo plot() enostavno izrisemo podatke, z namenom pregleda njihove ustreznosti (ali dejansko obsegajo ozemlje Slovenije? Ali so vrednosti in vzorec visin pricakovani, glede na nase poznavanje ozemlja drzave?):\n\n\nShow the code\nplot(slovenija_DMV)\n\n\n\n\n\nCe v konzoli zazenemo ime tega objekta, se nam izpisejo njegove lastnosti:\n\n\nShow the code\nslovenija_DMV\n\n\nclass       : SpatRaster \ndimensions  : 204, 420, 1  (nrow, ncol, nlyr)\nresolution  : 0.008333333, 0.008333333  (x, y)\nextent      : 13.2, 16.7, 45.3, 47  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource      : SVN_elv_msk.tif \nname        : SVN_elv_msk \nmin value   :          -2 \nmax value   :        2424 \n\n\n\n\nPodatke o nadmorskih visinah lahko uporabimo za izracun naklona terena (slope), aspekta oz. ekspozicije terena (aspect) in osoncenosti povrsja (hillshade). Ti sloji se nadalje uporabljajo za razlicne namene, npr. za opredelitev obmocij z vecjo plazovno nevarnostjo, za opredelitev obmocij z najvecjo osoncenostjo ipd. Sluzijo pa lahko tudi kot podporni vizualni elementi pri pripravi tematskih zemljevidov (se posebej osoncenost), s kateremi lahko poudarimo oziroma orisemo 3D lastnosti reliefa.\nNaklon in aspekt v R-u izracunamo z uporabo funkcije terrain v paketu terra. Za izracun obeh novih rastrskih slojev potrebujemo rastrski sloj z nadmorskimi visinami (to je nas slovenija_DMV) in dolociti, kaj zelimo izracunati (v =):\n\nza naklon dolocimo v = \"slope\",\nza aspekt dolocimo v = \"aspect\".\n\nOba sloja bomo shranili v nov R-objekt (naklon in aspekt) in v datoteko na nasem racunalniku (filename =):\n\n\nShow the code\nnaklon &lt;- terrain(slovenija_DMV, v = \"slope\", filename = \"01_data/slovenija_naklon_wgs84.tif\")\n\n\n\n\nShow the code\naspekt &lt;- terrain(slovenija_DMV, v = \"aspect\", filename = \"01_data/slovenija_aspekt_wgs84.tif\")\n\n\n\nCe sta ukaza delovala, bosta po nekaj sekundah v mapi 01_data novi datoteki, ki vsebujeta podatke o naklonu in aspektu terena v Sloveniji. S funkcijo plot() enostavno izrisemo podatke. Bodi pozorni na enote v legendi, naklon je samodejno izracunan v %, aspekt pa v stopinjah (pove nam, koliko stopinj od severa je smer usmerjenosti posamezne rastrske celice):\n\n\nShow the code\nplot(naklon)\n\n\n\n\n\n\n\nShow the code\nplot(aspekt)\n\n\n\n\n\nUcinek osoncenosti (hillshade) ni nic drugega kot izracun in dodajanje hipoteticne osvetlitve terena glede na položaj svetlobnega vira. Uporablja se vecinoma za dodajanje globine kartografskim prikazom (zanimivost: z isto metodo se izracuna tudi “osoncenost” morskega dna za poudarjanje 3D prikaza morskih globin, kljub temu, da tam nikoli ne posije sonce). Osoncenost je odvisna od dveh spremenljivk, naklona in aspekta terena, ki ju bomo uporabili za njen izracun. Funkcija, s katero izracunamo osoncenost se imenuje shade(), zahteva pa naklon in aspekt izracunana v enoti radian, kar pomeni, da nasih zgornjih izracunov ne moremo uporabiti neposredno. Da zadovoljimo potrebam funkcije shade(), bomo neposredno znotraj oklepajev, naklon in aspekt izracunali se enkrat in tokrat v vsako dodali argument unit = \"radian\". Funkciji shade() bomo ukazali, da normalizira podatke normalize = TRUE in shrani na nas racunalnik rezultat izracuna (filename = \"01_data/slovenija_osoncenost_wgs84.tif\").\n\n\nShow the code\nosoncenost &lt;- shade(terrain(slovenija_DMV, v = \"slope\", unit = \"radian\"),\n                    terrain(slovenija_DMV, v = \"aspect\", unit = \"radian\"),\n                    normalize= TRUE,\n                    filename = \"01_data/slovenija_osoncenost_wgs84.tif\")\n\n\nKot v mnogih predhodnih korakih, tudi tokrat informativno prikazemo sloj, ki mu tokrat barve spremenimo v sive (grey(1:100/100)):\n\n\nShow the code\nplot(osoncenost, col = grey(1:100/100))\n\n\n\n\n\nZa infomativnejsi prikaz dosedanjega dela, lahko vse 4 zemljevide prikazemo v mrezi 2x2 (par(mfrow = c(2,2))) in jim dodamo smiselne naslove (main = \"Informativen naslov\"):\n\n\nShow the code\npar(mfrow = c(2,2))\n\nplot(slovenija_DMV, main = \"Nadmorske visine v Sloveniji (m)\")\nplot(naklon, main = \"Naklon terena v Sloveniji (%)\")\nplot(osoncenost, col = grey(1:100/100), main = \"Osoncenost terena v Sloveniji\")\nplot(aspekt, main = \"Ekspozicija terena v Sloveniji (°)\")\n\n\n\n\n\nShow the code\npar(mfrow = c(1,1)) # ponastavimo izris grafov na 1 x 1\n\n\n\n\nV novo, prazno skripto kopirajte ukaze, ki smo jih do sedaj izvedli (zacnite z ukazom library(geodata). Spomnite se, da funkcije install.packages() ne potrebujete zagnati vec kot enkrat! Funkcije library() pa morate zagnati vsakic, ko na novo zazenete R ali RStudio!\nVasa naloga je, da prilagodite kopirane ukaze, tako da:\n\nSi iz spodnje tabele izberete eno drzavo, ki ni Slovenija.\nUporabite mednarodno oznako te drzave (v stolpcu ISO2) in z uporabo funkcije elevation_30s() prenesete podatke o nadmorskih visinah te drzave. Rezultate shranite v nov R-objekt.\nPodatke o nadmorskih visinah izbrane drzave uporabite za izracun:\n\nnaklona terena v izbrani drzavi,\naspekta terena v izbrani drzavi,\nosoncenosti v izbrani drzavi.\n\nCilj naloge je, da prikazete vse stiri sloje za izbrano drzavo skupaj, kot smo jih prikazali za Slovenijo zgoraj.\n\nCe cesa ne razumete ali ne znate narediti takoj, najprej ponovno preberite zgronji postopek ali se pozanimajte pri sosedu!\n\n\n\nShow the code\ncountry_codes()\n\n\n\n\n\n\n\n\n\n\n\nNadaljujemo z mesecno temperaturo v Sloveniji. Podatki so na voljo kot del baze WorldClim s prostorsko locljivostjo priblizno 1 kvadratni kilometer. Podatkovni nabor \"tmax\" (maksimalna temperatura) vsebuje mesecne vrednosti maksimalne temperature. Podatki so povprecni za obdobje od 1950 do 2000 in temeljijo na opazovanjih s postajami za merjenje vremena in so interpolirani na ločljivost 1 km². Do njih dostopamo s funkcijo worldclim_country(), ki od nas zahteva dva ze znana parametra (country = \"SI\", path = \"01_data\"), dva pa sta specificna za to funkcijo:\n\nvar = tmax, definiramo kateri nabor podatkov zelimo prenesti,\nres = 0.5, definiramo resolucijo/locljivost, ki jo zelimo, v nasem primeru 0.5 minute oziroma 30s (km x km):\n\nOPOMBA: Nabor podatkov je precej velik in lahko traja nekaj casa, da se prenese iz serverjev!\n\n\nShow the code\nslovenija_tmax_mesecno &lt;- worldclim_country(country = \"SI\", var = \"tmax\", res = 0.5, path = \"01_data\")\n\n\n\nCe v konzoli zazenemo ime objekta slovenija_tmax_mesecno, se nam izpisejo njegove lastnosti, s funkcijo names() pa izpisemo imena slojev, ki jih objekt vsebuje:\n\n\nShow the code\nslovenija_tmax_mesecno\n\n\nclass       : SpatRaster \ndimensions  : 240, 480, 12  (nrow, ncol, nlyr)\nresolution  : 0.008333333, 0.008333333  (x, y)\nextent      : 13, 17, 45, 47  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource      : SVN_wc2.1_30s_tmax.tif \nnames       : SVN_w~max_1, SVN_w~max_2, SVN_w~max_3, SVN_w~max_4, SVN_w~max_5, SVN_w~max_6, ... \nmin values  :        -7.6,        -8.4,        -6.8,        -4.4,         0.5,         3.7, ... \nmax values  :        10.5,        10.2,        13.7,        17.4,        23.1,        26.4, ... \n\n\nShow the code\nnames(slovenija_tmax_mesecno)\n\n\n [1] \"SVN_wc2.1_30s_tmax_1\"  \"SVN_wc2.1_30s_tmax_2\"  \"SVN_wc2.1_30s_tmax_3\" \n [4] \"SVN_wc2.1_30s_tmax_4\"  \"SVN_wc2.1_30s_tmax_5\"  \"SVN_wc2.1_30s_tmax_6\" \n [7] \"SVN_wc2.1_30s_tmax_7\"  \"SVN_wc2.1_30s_tmax_8\"  \"SVN_wc2.1_30s_tmax_9\" \n[10] \"SVN_wc2.1_30s_tmax_10\" \"SVN_wc2.1_30s_tmax_11\" \"SVN_wc2.1_30s_tmax_12\"\n\n\n\nS funkcijo plot() ponovno izrisemo in preverimo kakseg geografski obseg zajema nabor podatkov:\n\n\nShow the code\nplot(slovenija_tmax_mesecno)\n\n\n\n\n\n\n\nDa obrezemo le na obmocje Slovenija, bomo s funkcijo gadm() dostopali do globalnih administrativnih meja. Ena od moznosti, ki jo imamo, je prenos meje posamezne drzave (level = 0), ki lahko vkljucuje tudi meje pokrajin (level = 1) ali obcin (level = 2). Mi bomo prenesli samo drzavno mejo Slovenije (country = \"SI\") in shranili v objekt z imenom slovenija_shp. Argument path = \"01_data\" pove funkciji, v katero mapo naj shrani ta vektorski sloj na trdem disku racunalnika:\n\n\nShow the code\nslovenija_shp &lt;- gadm(country = \"SI\", path = \"01_data\", level = 0)\n\n\n\nS funkcijo class() preverimo, kakšen tip podatkov v R-u predstavlja naš vektorski podatek:\n\n\nShow the code\nclass(slovenija_shp)\n\n\n[1] \"SpatVector\"\nattr(,\"package\")\n[1] \"terra\"\n\n\n\nIn s funkcijo plot() izrisemo, da preverimo, ce dejansko obsega ozemlje Slovenije:\n\n\nShow the code\nplot(slovenija_shp)\n\n\n\n\n\n\n\nNabor podatkov slovenija_tmax_mesecno obrezemo s funkcijo crop() v paketu terra. Definirati moramo podatke (slovenija_tmax_mesecno), vektorski sloj, s katerim obrezemo (slovenija_shp), in dolociti, da ohrani le celice znotraj meja Slovenije (mask = TRUE):\n\n\nShow the code\nslovenija_tmax_mesecno &lt;- terra::crop(slovenija_tmax_mesecno,\n                                      # obreze po obsegu slovenija_shp\n                                      slovenija_shp,\n                                      # obdrzi le podatke znotraj mejne crte Slovenije\n                                      mask = TRUE) \n\n\n\nIn prikazemo se enkrat:\n\n\nShow the code\nplot(slovenija_tmax_mesecno)\n\n\n\n\n\n\n\n\nIntergovernmental Panel on Climate Change (IPCC) je v preteklosti na razlicne nacine definirala scenarije razvoja cloveske druzbe in s tem povezanih izpustov toplogrednih plinov v prihodnosti. Ti scenariji sluzijo kot izhodisca za razumevanje vplivov clovestva na globalno okolje do leta 2100 (in kasneje). Zacetki scenarijev segajo v leto 2000 in so bili do danes veckrat posodobljeni.\nV letu 2021 je IPCC definirala do sedaj najkompleksnejse Shared-Socioeconomic pathways (SSPs). SSP scenariji opisujejo razlicne smernice razvoja druzbe in okolja v prihodnosti in so oznaceni s stevilkami od 1 do 5. Scenarija SSP 1 in 2 opisujeta svet, v katerem se sprejmejo ukrepi za zmanjsanje emisij ogljikovega dioksida (CO2) in se uporabljajo bolj okolju prijazni viri energije. Scenarija SSP 3 in 4 opisujeta svet, v katerem se emisije CO2 nadaljujejo z visokimi stopnjami, kar lahko povzroci velike spremembe v podnebnih pogojih. Scenarij SSP 5 pa opisuje svet, v katerem se sprejmejo ukrepi za zmanjsanje emisij CO2 in se uporabljajo bolj okolju prijazni viri energije, vendar pa se hkrati spodbuja tudi visoka stopnja urbanizacije in industrializacije (IPCC porocilo. Okoljski podatki, ki ustrezajo tem scenarijem in so izracunani z najnovejsimi metodami in modeli (CMIP6), so bili javno objavljeni in prvic prosto dostopni 1. decembra 2022!!\n\n\n\nIPCC Shared Socio-economic Pathways.\n\n\nSSP scenariji upostevajo tako gospodarski kot tudi druzbeni razvoj in poskusajo napovedati, kako se bodo koncentracije toplogrednih plinov spreminjale v prihodnje ter kako bo to vplivalo na spremembe v okolju.\n\n\n\nIPCC carbon emision scenarios.\n\n\n\nDo podatkov za prihodnost po scenarijih ssp in metodologiji CMIP6 dostopamo s funkcijo cmip6_tile(). Za razliko od prejsnih primerov, ko smo obseg podatkov definirali z oznako drzave, so tu podatki razdeljeni na kvadrante (tile). Da dobimo kvadrant, v katerem se nahaja Slovenija, moramo podati ustrezno lokacijo v obliki geografske sirine in dolzine (lon = 13, lat = 45), ki jih na primer razberemo iz google-ovih zemljevidov. Kot lahko opazite, sem koordinate definiral le do stopinje natacnosti - predvsem zato, ker kvadranti zajemajo relativno velike povrsine (primer v nadaljevanju). Poleg koordinate, funkcijo cmip6_tile(). od nas zahteva nekaj ze znanih parametrov (country = \"SI\", path = \"01_data\", var = \"tmax\"), trije pa so specificna za to funkcijo:\n\nmodel =,\nssp = in\ntime =.\n\nZ argumentom model = deifiniramo tip modela, ki je bil uporabljen za projekcije v prihodnost. Izbiramo lahko med mnogimi, v tem trenutku za nas to ni bistveno, lahko pa si ogledate seznam vseh moznosti tukaj. Mi bomo uporabili prvega po abecednem redu \"ACCESS-CM2\". Z argumentom ssp = definiramo katerega od petih scenarij za prihodnost zelimo (glej sliko zgoraj), z argumentom time = pa za katero casovno obdobje (za zdaj so na voljo: “2021-2040”, “2041-2060”, “2061-2080”). Prenesli bomo podatke za pricakovane najvisje mesecne temperature v sloveniji za scenarija 126 in 585 za leta 2061 - 2080:\nOPOMBA: Nabor podatkov je precej velik in lahko traja nekaj casa, da se prenese iz serverjev!\n\n\nShow the code\nslovenija_tmax_ssp126_2080 &lt;- cmip6_tile(lon = 13, \n                                         lat = 45, \n                                         model = \"ACCESS-CM2\", \n                                         ssp = \"126\", \n                                         time = \"2061-2080\", \n                                         var = \"tmax\", \n                                         path = \"01_data\")\n\n\n\n\nShow the code\nslovenija_tmax_ssp585_2080 &lt;- cmip6_tile(lon = 13, \n                                         lat = 45, \n                                         model =\"ACCESS-CM2\", \n                                         ssp = \"585\", \n                                         time = \"2061-2080\", \n                                         var = \"tmax\", \n                                         path = \"01_data\")\n\n\nKot smo ze nekajkrat do sedaj, izrisimo podatke:\n\n\nShow the code\nplot(slovenija_tmax_ssp126_2080)\n\n\n\n\n\n\n\nShow the code\nplot(slovenija_tmax_ssp585_2080)\n\n\n\n\n\nOba nabora podatkov bomo se obrezali, saj jih v naslednjem koraku potrebujemo v enakem obsegu kot slovenija_tmax_mesecno:\n\n\nShow the code\nslovenija_tmax_ssp126_2080 &lt;- terra::crop(slovenija_tmax_ssp126_2080, \n                                          slovenija_shp, \n                                          mask = TRUE) \n\n\n\n\nShow the code\nslovenija_tmax_ssp585_2080 &lt;- terra::crop(slovenija_tmax_ssp585_2080, \n                                          slovenija_shp, \n                                          mask = TRUE) \n\n\n\n\n\nRastrski podatki, tako v terri kot v rastru, omogocajo enostvno aplikacijo racunskih opracij:\n\nsestevanje (+),\nodstevanje (-),\ndeljenje (/),\nmnozenje (*),\nkorenjenje (sqrt()), itd.\n\nMi bomo izracunali, za koliko se bo spremenila mesecna temperatura v Sloveniji, glede na oba zgornja scenarija v primerjavi s sedanjastjo. Vsi trije rastrski objekti imajo 12 slojev, v vsakem sloji ustrezajo enemu od mesecev v letu. Prvi sloj je v vseh januar, dvanajsti sloj pa v vseh december. Ce so podatki urejeni na ta nacin, bomo z uporabo racunske operacije med dvema rastrskima objektoma, izracunali vrednosti po parih slojev, tako kot si sledijo po vrstnem redu (npr. januar prihodnost - januar sedanjost, vse do december prihodnost - december sedanjost). Rezultat racunskih operacij shranimo v nova objekta:\n\n\nShow the code\nrazlika_v_temperaturi_danes_ssp126_2080 &lt;- slovenija_tmax_ssp126_2080 - slovenija_tmax_mesecno\n\nrazlika_v_temperaturi_danes_ssp585_2080 &lt;- slovenija_tmax_ssp585_2080 - slovenija_tmax_mesecno\n\n\nS funkcijo plot() izrisemo in vidimo kaksne so ocenjene razlike v maksimalni temperature na ozemlju Slovenije v prihodnosti:\n\n\nShow the code\nplot(razlika_v_temperaturi_danes_ssp126_2080)\n\n\n\n\n\n\n\nShow the code\nplot(razlika_v_temperaturi_danes_ssp585_2080)\n\n\n\n\n\nZ nekaj dodatki, lahko nasi grafi izgledajo bistveno bolj informativni:\n\ndolocimo skupno lestvico legende (range = c(0 - 8); glej legende zgoraj),\nizberemo ustreznejše barve (heat.colors() v obratnem vrstnem redu rev() - bela do rdeca),\ndodamo se ime meseca na katerega se prikaz nanasa z main = month.name:\n\n\n\nShow the code\nterra::plot(razlika_v_temperaturi_danes_ssp126_2080, \n            range = c(0, 8), \n            col = rev(heat.colors(999)),\n            main = month.name)\n\n\n\n\n\n\n\nShow the code\nterra::plot(razlika_v_temperaturi_danes_ssp585_2080, \n            range = c(0, 8), \n            col = rev(heat.colors(999)),\n            main = month.name)"
  },
  {
    "objectID": "posts/04_GIS_SI_Rasterski_podatki_z_visoko_locljivostjo.html#rastrski-podatki-z-visoko-prostorsko-in-časovno-resolucijo-v-paketu-geodata",
    "href": "posts/04_GIS_SI_Rasterski_podatki_z_visoko_locljivostjo.html#rastrski-podatki-z-visoko-prostorsko-in-časovno-resolucijo-v-paketu-geodata",
    "title": "RASTRSKI PODATKI Z VISOKO LOČLJIVOSTJO V R-U",
    "section": "Rastrski podatki z visoko prostorsko in časovno resolucijo v paketu geodata",
    "text": "Rastrski podatki z visoko prostorsko in časovno resolucijo v paketu geodata\nNadaljujemo z mesečnimi temperaturami v Sloveniji. Podatki so na voljo kot del baze WorldClim s prostorsko ločljivostjo približno 1 kvadratni kilometer. Podatkovni nabor \"tmax\" (maksimalna temperatura) vsebuje mesečne vrednosti maksimalne temperature v Sloveniji. Podatki so povprečni za obdobje od 1950 do 2000 in temeljijo na opazovanjih s postajami za merjenje vremena in so interpolirani na ločljivost 1 km². Do njih dostopamo s funkcijo worldclim_country(), ki od nas zahteva dva že znana parametra (country = \"SI\", path = \"01_data\"), dva pa sta specifična za to funkcijo:\n\nz var = tmax definiramo kateri nabor podatkov želimo prenesti,\nin z res = 0.5 definiramo resolucijo/ločljivost, ki jo želimo, v našem primeru 0.5 arc minute oziroma 30 arc sekund (približno 1 km x 1 km):\n\nČe v konzoli zaženemo ime objekta slovenija_tmax_mesecno, se nam izpišejo njegove lastnosti, s funkcijo names() pa izpišemo imena slojev, ki jih objekt vsebuje. S funkcijo plot() ponovno izrišemo podatke in preverimo kakšen geografski obseg zajema nabor podatkov.\n\n\n\n\n\n\nNaloga\n\n\n\nKopirajte in prilepite spodnjo kodo v R skript, premaknite kazalec v prvo vrstico s kodo in kliknite Run. Premaknite kazalec na vsako vrstico, ki vsebuje kodo, in ponovite.\nOPOMBA: Nabor podatkov je precej velik in lahko traja nekaj časa, da se prenese iz serverjev!\n\n\n\nslovenija_tmax_mesecno &lt;- worldclim_country(country = \"SI\", var = \"tmax\", res = 0.5, path = \"01_data\")\n\n\nslovenija_tmax_mesecno\n\nclass       : SpatRaster \ndimensions  : 240, 480, 12  (nrow, ncol, nlyr)\nresolution  : 0.008333333, 0.008333333  (x, y)\nextent      : 13, 17, 45, 47  (xmin, xmax, ymin, ymax)\ncoord. ref. : lon/lat WGS 84 (EPSG:4326) \nsource      : SVN_wc2.1_30s_tmax.tif \nnames       : SVN_w~max_1, SVN_w~max_2, SVN_w~max_3, SVN_w~max_4, SVN_w~max_5, SVN_w~max_6, ... \nmin values  :        -7.6,        -8.4,        -6.8,        -4.4,         0.5,         3.7, ... \nmax values  :        10.5,        10.2,        13.7,        17.4,        23.1,        26.4, ... \n\nnames(slovenija_tmax_mesecno)\n\n [1] \"SVN_wc2.1_30s_tmax_1\"  \"SVN_wc2.1_30s_tmax_2\"  \"SVN_wc2.1_30s_tmax_3\" \n [4] \"SVN_wc2.1_30s_tmax_4\"  \"SVN_wc2.1_30s_tmax_5\"  \"SVN_wc2.1_30s_tmax_6\" \n [7] \"SVN_wc2.1_30s_tmax_7\"  \"SVN_wc2.1_30s_tmax_8\"  \"SVN_wc2.1_30s_tmax_9\" \n[10] \"SVN_wc2.1_30s_tmax_10\" \"SVN_wc2.1_30s_tmax_11\" \"SVN_wc2.1_30s_tmax_12\"\n\n\n\nplot(slovenija_tmax_mesecno)\n\n\n\n\n\nPodatke bomo obrezali le na območje Slovenije, zato bomo s funkcijo gadm() dostopali do globalnih administrativnih meja. Ena od možnosti, ki jo imamo, je prenos meje posamezne države (level = 0). Ostale možnosti vključujejo tudi meje pokrajin (level = 1) ali občin (level = 2). Mi bomo prenesli samo državno mejo Slovenije (country = \"SI\") in shranili v objekt z imenom slovenija_shp. Argument path = \"01_data\" pove funkciji, v katero mapo naj shrani ta vektorski sloj na trdem disku računalnika. S funkcijo plot() izrišemo, da preverimo, če dejansko obsega ozemlje Slovenije:\n\n\n\n\n\n\nNaloga\n\n\n\nKopirajte in prilepite spodnjo kodo v R skript, premaknite kazalec v prvo vrstico s kodo in kliknite Run. Premaknite kazalec na vsako vrstico, ki vsebuje kodo, in ponovite.\n\n\n\nslovenija_shp &lt;- gadm(country = \"SI\", path = \"01_data\", level = 0)\n\n\nplot(slovenija_shp)\n\n\n\n\n\nNabor podatkov slovenija_tmax_mesecno bomo obrezali s funkcijo crop() iz paketa terra. Definirati moramo podatke (slovenija_tmax_mesecno), vektorski sloj, s katerim obrezujemo (slovenija_shp), in določiti, da ohrani le celice znotraj meja Slovenije (mask = TRUE).\n\n\n\n\n\n\nNaloga\n\n\n\nKopirajte in prilepite spodnjo kodo v R skript, premaknite kazalec v prvo vrstico s kodo in kliknite Run. Premaknite kazalec na vsako vrstico, ki vsebuje kodo, in ponovite.\n\n\n\nslovenija_tmax_mesecno &lt;- terra::crop(slovenija_tmax_mesecno,\n                                      slovenija_shp,\n                                      mask = TRUE) \n\n\nplot(slovenija_tmax_mesecno)"
  },
  {
    "objectID": "posts/04_GIS_SI_Rasterski_podatki_z_visoko_locljivostjo.html#rastrski-podatki-z-visoko-prostorsko-resolucijo-v-paketu-geodata",
    "href": "posts/04_GIS_SI_Rasterski_podatki_z_visoko_locljivostjo.html#rastrski-podatki-z-visoko-prostorsko-resolucijo-v-paketu-geodata",
    "title": "RASTRSKI PODATKI Z VISOKO LOČLJIVOSTJO V R-U",
    "section": "Rastrski podatki z visoko prostorsko resolucijo v paketu geodata",
    "text": "Rastrski podatki z visoko prostorsko resolucijo v paketu geodata\nDanes si bomo na vajah pogledali še paket geodata, ki vsebuje funkcije za dostop do različnih rastrskih podatkov z visoko prostorsko in časovno resolucijo.\nPaket najprej instaliramo (samo enkrat, če ga se nismo) in omogočimo uporabo funkcij (vedno, ko zaženemo R ali RStudio).\n\n\n\n\n\n\nNaloga\n\n\n\nOdprite nov R skript v meniju File tako, da kliknete New file in potem R script. Skript bo imel ime Untitled1 (ali Untitled2, če je že odprt prazen skript).\nShranite skript na namizje vašega računalnika in ga poimenujte Rastrski podatki z visoko ločljivostjo v R-u.\nKopirajte in prilepite spodnjo kodo v skript R, premaknite kazalec v prvo vrstico s kodo in kliknite Run. Premaknite kazalec na vsako vrstico, ki vsebuje kodo, in ponovite.\n\n\n\ninstall.packages(\"geodata\")\n\n\nlibrary(geodata)\n\nVsebino dostopnih podatkovnih zbirk si lahko ogledamo s pomočjo dokumentacije paketa, do katere dostopamo s sledečo kodo:\n\n?`geodata-package`\n\nS paketom geodata lahko dostopamo do:\n\nklimatskih podatkov,\npodatkov rabe tal,\ndigitalnega modela nadmorskih višin,\npodatkov o tipih prsti in kamnin,\ndržavnih in administrativnih mej,\nprebivalstva, itd.\n\n\nMi bomo najprej bomo naložili podatke za nadmorske višine v Sloveniji z resolucijo/ločljivostjo 30 sekund (približno 1 km x 1 km) ). Do teh podatkov dostopamo s funkcijo elevation_30s(), ki od nas zahteva dve dodatni specifikaciji:\n\nkodo države, za katero želimo podatke (country = \"SI\") in\nmesto na računalniku, kamor bodo podatki shranjeni (path = \"01_data\").\n\nRezultat shranimo v nov objekt slovenija_DMV. če je ukaz deloval, bo po nekaj sekundah v mapi 01_data nova datoteka, ki vsebuje podatke o nadmorskih višinah v Sloveniji, prav tako pa bomo imeli v R-ov delovnem okolju nov objekt z imenom slovenija_DMV. S funkcijo plot() lahko enostavno izrišemo podatke, z namenom pregleda njihove ustreznosti oziroma pravilnosti.\n\n\n\n\n\n\nNaloga\n\n\n\nKopirajte in prilepite spodnjo kodo v R skript, premaknite kazalec v prvo vrstico s kodo in kliknite Run. Premaknite kazalec na vsako vrstico, ki vsebuje kodo, in ponovite.\n\n\n\nslovenija_DMV &lt;- elevation_30s(country = \"SI\", path = \"01_data\")\n\nplot(slovenija_DMV)\n\n\n\n\n\n\n\n\n\n\nVprašanje\n\n\n\nAli podatki dejansko obsegajo ozemlje Slovenije? Ali so vrednosti in vzorec višin pričakovani, glede na vaše poznavanje ozemlja države?\n\n\n\n\nPodatke o nadmorskih višinah lahko uporabimo za izračun naklona terena (slope), aspekta oz. ekspozicije terena (aspect) in osončenosti površja (hillshade). Ti sloji se nadalje uporabljajo za različne namene, npr. za opredelitev območij z vecjo plazovno nevarnostjo, za opredelitev območij z največjo osončenostjo ipd. Služijo pa lahko tudi kot podporni vizualni elementi pri pripravi tematskih zemljevidov, s kateremi poudarimo oziroma orišemo 3D lastnosti reliefa.\nNaklon in aspekt v R-u izračunamo z uporabo funkcije terrain v paketu terra. Za izračun obeh novih rastrskih slojev potrebujemo rastrski sloj z nadmorskimi višinami (uporabili bomo slovenija_DMV) in določiti, kaj želimo izračunati (definirati moramo argument v =):\n\nza naklon določimo v = \"slope\",\nza aspekt določimo v = \"aspect\".\n\nOba sloja bomo shranili v nov R-objekt (naklon in aspekt) in v datoteko na našem računalniku (filename =).\nČe sta ukaza delovala, bosta po nekaj sekundah v mapi 01_data novi datoteki, ki vsebujeta podatke o naklonu in aspektu terena v Sloveniji, v našem delovnem okolju pa dve novi imeni. S funkcijo plot() enostavno izrišemo podatke. Bodite pozorni na enote v legendi:\n\nnaklon je izračunan v %,\naspekt pa v stopinjah ° (pove nam, koliko stopinj od severa je smer usmerjenosti terena posamezne rastrske celice)\n\n\n\n\n\n\n\nNaloga\n\n\n\nKopirajte in prilepite spodnjo kodo v R skript, premaknite kazalec v prvo vrstico s kodo in kliknite Run. Premaknite kazalec na vsako vrstico, ki vsebuje kodo, in ponovite.\n\n\n\nnaklon &lt;- terrain(slovenija_DMV, v = \"slope\", filename = \"01_data/slovenija_naklon_wgs84.tif\")\n\naspekt &lt;- terrain(slovenija_DMV, v = \"aspect\", filename = \"01_data/slovenija_aspekt_wgs84.tif\")\n\n\n\n\n\n\n\nOpomba\n\n\n\nKo ukaz za izračun s funkcijo terrain() izvedemo in shranimo datoteko na računalnik, bomo ob vsakem naslednjem zagonu funkcije dobili napako:\nError: [terrain] file exists. You can use 'overwrite=TRUE' to overwrite it\nTo je “varovalka”, da si datotek na računalniku pomotoma ne spreminjamo. Če bi dejansko želeli ustvariti nov izračun in ga shraniti na računalnik, dodamo argument overwrite=TRUE, ampak moramo biti potem pozorni, da si pomotoma v datoteka ne shranimo česa neželenega.\n\n\n\nplot(naklon)\n\n\n\nplot(aspekt)\n\n\n\n\nUčinek osončenosti (hillshade) ni nič drugega kot dodajanje hipotetične osvetlitve terena glede na položaj svetlobnega vira. Uporablja se večinoma za dodajanje globine kartografskim prikazom (zanimivost: z isto metodo se izračuna tudi “osončenost” morskega dna za poudarjanje 3D prikaza morskih globin, kljub temu, da tam nikoli ne posije sonce). Osončenost je odvisna od naklona in aspekta terena. Funkcija, s katero izračunamo osončenost se imenuje shade(), zahteva pa naklon in aspekt izračunana v enoti radian, kar pomeni, da naših zgornjih izračunov ne moremo uporabiti neposredno. Da zadovoljimo potrebam funkcije shade(), bomo neposredno znotraj oklepajev, naklon in aspekt izracunali se enkrat in tokrat v vsako dodali argument unit = \"radian\". Funkciji shade() bomo ukazali, da normalizira podatke normalize = TRUE in shrani na nas racunalnik rezultat izracuna (filename = \"01_data/slovenija_osoncenost_wgs84.tif\").\nKot v mnogih predhodnih korakih, tudi tokrat informativno prikažemo sloj, ki mu bomo tokrat barve spremenimo v sive (grey(1:100/100)).\n\n\n\n\n\n\nNaloga\n\n\n\nKopirajte in prilepite spodnjo kodo v R skript, premaknite kazalec v prvo vrstico s kodo in kliknite Run. Premaknite kazalec na vsako vrstico, ki vsebuje kodo, in ponovite.\n\n\n\nosoncenost &lt;- shade(terrain(slovenija_DMV, v = \"slope\", unit = \"radian\"),\n                    terrain(slovenija_DMV, v = \"aspect\", unit = \"radian\"),\n                    normalize= TRUE,\n                    filename = \"01_data/slovenija_osoncenost_wgs84.tif\")\n\n\nplot(osoncenost, col = grey(1:100/100))\n\n\n\n\nZa infomativnejši prikaz dosedanjega dela, lahko vse 4 zemljevide prikažemo v mreži 2x2 (par(mfrow = c(2,2))) in jim dodamo smiselne naslove (main = \"Informativen naslov\")\n\n\n\n\n\n\nNaloga\n\n\n\nKopirajte in prilepite spodnjo kodo v R skript, premaknite kazalec v prvo vrstico s kodo in kliknite Run. Premaknite kazalec na vsako vrstico, ki vsebuje kodo, in ponovite.\n\n\n\npar(mfrow = c(2,2))\n\nplot(slovenija_DMV, main = \"Nadmorske višine v Sloveniji (m)\")\nplot(naklon, main = \"Naklon terena v Sloveniji (%)\")\nplot(osoncenost, col = grey(1:100/100), main = \"Osončenost terena v Sloveniji\")\nplot(aspekt, main = \"Ekspozicija terena v Sloveniji (°)\")\n\n\n\npar(mfrow = c(1,1)) # ponastavimo izris grafov na 1 x 1\n\n\n\n\n\n\n\nNaloga\n\n\n\nV novo, prazno skripto kopirajte ukaze, ki smo jih do sedaj izvedli (začnite z ukazom library(geodata). Spomnite se, da funkcije install.packages() ne potrebujete zagnati več kot enkrat! Funkcijo library() pa morate zagnati vsakič, ko na novo zaženete R ali RStudio!\nVaša naloga je, da prilagodite kopirane ukaze, tako da:\n\nSi iz spodnje tabele izberete eno državo, ki ni Slovenija.\nUporabite mednarodno oznako te drzave (v stolpcu ISO2) in z uporabo funkcije elevation_30s() prenesete podatke o nadmorskih višinah te izbrane države. Rezultate shranite v nov R-objekt.\nPodatke o nadmorskih višinah izbrane države uporabite za izračun:\n\nnaklona terena v izbrani državi,\naspekta terena v izbrani državi,\nosončenosti v izbrani državi.\n\nKončni cilj naloge je, da prikažete vse štiri sloje za izbrano državo skupaj, kot smo jih prikazali za Slovenijo zgoraj.\n\n\n\n\n\ncountry_codes()"
  },
  {
    "objectID": "posts/04_GIS_SI_Rasterski_podatki_z_visoko_locljivostjo.html#mesečna-temperatura-v-sloveniji-za-prihodnost",
    "href": "posts/04_GIS_SI_Rasterski_podatki_z_visoko_locljivostjo.html#mesečna-temperatura-v-sloveniji-za-prihodnost",
    "title": "RASTRSKI PODATKI Z VISOKO LOČLJIVOSTJO V R-U",
    "section": "Mesečna temperatura v Sloveniji za prihodnost",
    "text": "Mesečna temperatura v Sloveniji za prihodnost\nIntergovernmental Panel on Climate Change (IPCC) je v preteklosti na različne načine definiral scenarije razvoja človeške družbe in s tem povezanih izpustov toplogrednih plinov v prihodnosti. Ti scenariji služijo kot izhodišča za razumevanje vplivov človestva na globalno okolje do leta 2100 (in kasneje). Začetki scenarijev segajo v leto 2000 in so bili do danes večkrat posodobljeni.\nV letu 2021 je IPCC definirala do sedaj najkompleksnejše scenarije, ki so jih poimenovali Shared-Socioeconomic pathways (SSPs). SSP scenariji opisujejo različne mogoče smernice razvoja družbe in okolja v prihodnosti in so označeni s številkami od 1 do 5. Scenarija SSP 1 in 2 opisujeta svet, v katerem se sprejmejo ukrepi za zmanjšanje emisij ogljikovega dioksida (CO2) in se uporabljajo bolj okolju prijazni viri energije. Scenarija SSP 3 in 4 opisujeta svet, v katerem se emisije CO2 nadaljujejo z visokimi stopnjami, kar lahko povzroči velike spremembe v podnebnih pogojih. Scenarij SSP 5 pa opisuje svet, v katerem se sprejmejo ukrepi za zmanjšanje emisij CO2 in se uporabljajo bolj okolju prijazni viri energije, vendar pa se hkrati spodbuja tudi visoka stopnja urbanizacije in industrializacije (IPCC poročilo. Okoljski podatki, ki ustrezajo tem scenarijem in so izračunani z najnovejšimi metodami in modeli (CMIP6), so bili javno objavljeni in prvič prosto dostopni 1. decembra 2022!!\n\nSSP scenariji upoštevajo tako gospodarski kot tudi družbeni razvoj in poskušajo napovedati, kako se bodo koncentracije toplogrednih plinov spreminjale v prihodnje ter kako bo to vplivalo na spremembe v okolju.\n\n\nDo podatkov za prihodnost po scenarijih ssp in metodologiji CMIP6 dostopamo s funkcijo cmip6_tile(). Za razliko od prejšnih primerov, ko smo obseg podatkov definirali z oznako drzave, so tu podatki razdeljeni na kvadrante (tile). Da dobimo kvadrant, v katerem se nahaja Slovenija, moramo podati ustrezno lokacijo v obliki geografske širine in dolžine (lon = 13, lat = 45), ki jih na primer razberemo iz google-ovih zemljevidov. Kot lahko opazite, sem koordinate definiral le do stopinje natačnosti - predvsem zato, ker kvadranti zajemajo relativno velike površine (primer v nadaljevanju). Poleg koordinate, funkcija cmip6_tile(). od nas zahteva nekaj ze znanih parametrov (country = \"SI\", path = \"01_data\", var = \"tmax\"), trije pa so specifični za to funkcijo:\n\nmodel =,\nssp = in\ntime =.\n\nZ argumentom model = definiramo tip modela, ki je bil uporabljen za projekcije v prihodnost. Izbiramo lahko med mnogimi, v tem trenutku za nas to ni bistveno, lahko pa si ogledate seznam vseh možnosti tukaj. Mi bomo uporabili prvega po abecednem redu \"ACCESS-CM2\". Z argumentom ssp = definiramo katerega od petih scenarij za prihodnost želimo (glej sliko zgoraj), z argumentom time = pa za katero časovno obdobje (za zdaj so na voljo: “2021-2040”, “2041-2060”, “2061-2080”). Mi bomo prenesli podatke za pričakovane najvišje mesečne temperature v Sloveniji po scenarijih 126 in 585 za leta 2061 - 2080. Kot smo že nekajkrat do sedaj, bomo podatke tudi izrisali:\n\n\n\n\n\n\nNaloga\n\n\n\nKopirajte in prilepite spodnjo kodo v R skript, premaknite kazalec v prvo vrstico s kodo in kliknite Run. Premaknite kazalec na vsako vrstico, ki vsebuje kodo, in ponovite.\nOPOMBA: Nabor podatkov je precej velik in lahko traja nekaj časa, da se prenese iz serverjev!\n\n\n\nslovenija_tmax_ssp126_2080 &lt;- cmip6_tile(lon = 13, \n                                         lat = 45, \n                                         model = \"ACCESS-CM2\", \n                                         ssp = \"126\", \n                                         time = \"2061-2080\", \n                                         var = \"tmax\", \n                                         path = \"01_data\")\n\n\nslovenija_tmax_ssp585_2080 &lt;- cmip6_tile(lon = 13, \n                                         lat = 45, \n                                         model =\"ACCESS-CM2\", \n                                         ssp = \"585\", \n                                         time = \"2061-2080\", \n                                         var = \"tmax\", \n                                         path = \"01_data\")\n\n\n\n\n\n\n\nOpozorilo\n\n\n\nV zadnjem času se nekaj R paketov, povezanih s prostorskimi analizami upokojuje, novejši paketi pa se morajo zaradi tega posodobiti in postati neodvisni od upokojenih paketov, kar drži tudi za paket geodata. Do sedaj smo brez težav lahko prenesli vse sloje, iz nekega razloga pa slojev za prihodnost s funkcijo cmip6_tile() trenutno ni mogoče prenesti iz serverjev (vsaj na mojem računalniku). Če bosta funkciji vrnili sporočilo:\nThe geodata server is down for maintenance.  It is expected to be back online on October 12, 2023. download failed\nbomo uporabili alternativno možnost. Enake sloje smo uporabili na lanskih vajah in sem jih začasno naložil na tej povezavi.\nKo sloje prenesete iz interneta na računalnik, jih kopirajte v mapo 01_data, ki se najverjetneje nahaja v mapi Moji dokumenti oziroma Documents.\n\n\n\nplot(slovenija_tmax_ssp126_2080)\n\n\n\n\n\nplot(slovenija_tmax_ssp585_2080)\n\n\n\n\nOba nabora podatkov bomo še obrezali, saj jih v naslednjem koraku potrebujemo v enakem obsegu kot slovenija_tmax_mesecno.\n\nslovenija_tmax_ssp126_2080 &lt;- terra::crop(slovenija_tmax_ssp126_2080, \n                                          slovenija_shp, \n                                          mask = TRUE) \n\n\nslovenija_tmax_ssp585_2080 &lt;- terra::crop(slovenija_tmax_ssp585_2080, \n                                          slovenija_shp, \n                                          mask = TRUE) \n\n\nRačunanje z rastri\nV R-u lahko na rastrske podatki enostavno apliciramo računske operacije, kot so:\n\nseštevanje (+),\nodštevanje (-),\ndeljenje (/),\nmnoženje (*),\nkorenjenje (sqrt()), itd.\n\nMi bomo izračunali, za koliko se bo spremenila mesečna temperatura v Sloveniji, glede na oba zgornja scenarija v primerjavi s sedanjostjo. Vsi trije rastrski objekti imajo 12 slojev, v vsakem od njih sloji po vrstnem redu ustrezajo enemu od mesecev v letu. Prvi sloj je v vseh januar, dvanajsti sloj pa v vseh december. Če so podatki urejeni na ta način, lahko z uporabo računske operacije med dvema rastrskima objektoma, izračunamo vrednosti po parih slojev, tako kot si sledijo po vrstnem redu (npr. januar prihodnost - januar sedanjost, vse do december prihodnost - december sedanjost). Rezultat računskih operacij shranimo v nova objekta, ki bosta prav tako vsebovala 12 rastrskih slojev, od katerih vsak predstavlja razliko v temperaturi med posameznimaa mesecema:\n\nrazlika_v_temperaturi_danes_ssp126_2080 &lt;- slovenija_tmax_ssp126_2080 - slovenija_tmax_mesecno\n\nrazlika_v_temperaturi_danes_ssp585_2080 &lt;- slovenija_tmax_ssp585_2080 - slovenija_tmax_mesecno\n\nS funkcijo plot() izrišemo in vidimo kakšne so ocenjene razlike v maksimalni temperature na ozemlju Slovenije v prihodnosti:\n\nplot(razlika_v_temperaturi_danes_ssp126_2080)\n\n\n\n\n\nplot(razlika_v_temperaturi_danes_ssp585_2080)\n\n\n\n\nZ nekaj dodatki, lahko naši zemljevidi izgledajo še bolj informativni:\n\ndoločimo skupno lestvico legende (range = c(0 - 8); glej legende zgoraj),\nizberemo ustreznejše barve (heat.colors() v obratnem vrstnem redu rev() - bela do rdeča),\ndodamo še ime meseca na katerega se prikaz nanaša z main = month.name:\n\n\nterra::plot(razlika_v_temperaturi_danes_ssp126_2080, \n            range = c(0, 8), \n            col = rev(heat.colors(999)),\n            main = month.name)\n\n\n\n\n\nterra::plot(razlika_v_temperaturi_danes_ssp585_2080, \n            range = c(0, 8), \n            col = rev(heat.colors(999)),\n            main = month.name)"
  },
  {
    "objectID": "posts/03_GIS_SI_global_raster_data_in_R.html#naloge",
    "href": "posts/03_GIS_SI_global_raster_data_in_R.html#naloge",
    "title": "GLOBALNI OKOLJSKI PODATKI V R-U",
    "section": "Naloge",
    "text": "Naloge\n\n\n\n\n\n\nNaloga 1\n\n\n\nČe nekaj ne deluje takoj, najprej razmislite o težavi/napaki, se posvetujte s sosedom na levi, nato na desni. Če po tem še vedno ne veste, kako odpraviti težavo ali nadaljevati, vprašajte google ali chat gpt in šele nato vprašajte mene za pomoč!\nDanašnja naloga bo bolj zahtevna kot zadnjič. Sledite naslednjim korakom, da jo dokončate:\n\nKopirajte in prilepite vso kodo, ki smo jo zagnali za primer povprečnih temperatur kopnega na konec R skripte. Vrstice, ki vsebujejo funkcije install.packages() lahko označite z znakom #, da se ne izvedejo ponovno, saj so paketi zdaj že inštalirani na vašem računalniku.\nZ uporabo funkcije load_layers() prenesite rastrski sloj s povprečnimi temperaturami morja, ki ima kodo \"BO_sstmean\". Spremenite rastrski sloj v terra tip rastrskih podatkov in ga shranite v objekt s smiselnim imenom.\nPreverite lastnosti rastrstkega sloja z uporabo funkcij ext(), res(), ncell() in crs().\nRastrskemu sloju določite ustrezen koordinatni referenčni sistem, ki je World Geographic System 1984 oziroma WGS 1984 in ima kodo \"epsg:4326\"\nPrilagodite kodo tako, da barvno paleto prilagodite razponu vrednosti sloja s temperaturami morja in ustrezno spremenite ime. Izbrana paleta \"RdBu\" lahko ostane enaka, saj spet prikazujemo temperature.\nUstrezno modificirajte ukaz za prikaz rastrskega sloja (spremeniti morate minimalno in maksimalno vrednost znotraj ukaza seq()) ter mu dodajte naslov.\nIzvozite zemljevid kot sliko na namizje in mu izberite ustrezno ime.\n\n\n\n\n\n\n\n\n\n\nNaloga 2\n\n\n\n\nIzberite si poljuben rastrski sloj iz paketa sdmpredictors, ki ne prikazuje temperatur!\nPonovite korake 2) do 7) iz zgornje naloge, vendar v koraku 5) izberite paleto barv, ki bo najbolj ustrezna za ta sloj po vašem mnenju - razmislite, kaj prikazuje in s katerimi barvami to najboljše prikažemo.\nOddajte zemljevid v nalogo na e-učilnici."
  },
  {
    "objectID": "posts/05_SDMs_Future_projections.html",
    "href": "posts/05_SDMs_Future_projections.html",
    "title": "PROJECTING SPECIES DISTRIBUTION ACCORDING TO FUTURE SCENARIOS",
    "section": "",
    "text": "Summary\n\n\n\nIn this lab you will:\n\nbe introduced to IPPC’s Shared Socio-economic Pathways (SSPs),\n\nuse R code to access the CMPI6 worldclim data for different SSPs from the server and download it,\ncompare present and future data,\ncreate species distribution projections for the future environmental data and\ndisplay them all on the same leaflet map."
  },
  {
    "objectID": "posts/05_SDMs_Future_projections.html#lab-plan",
    "href": "posts/05_SDMs_Future_projections.html#lab-plan",
    "title": "PROJECTING SPECIES DISTRIBUTION ACCORDING TO FUTURE SCENARIOS",
    "section": "Lab plan",
    "text": "Lab plan"
  },
  {
    "objectID": "posts/05_SDMs_Future_projections.html#data-import-from-previous-labs",
    "href": "posts/05_SDMs_Future_projections.html#data-import-from-previous-labs",
    "title": "PROJECTING SPECIES DISTRIBUTION ACCORDING TO FUTURE SCENARIOS",
    "section": "Data import from previous labs",
    "text": "Data import from previous labs\nFirst, load the data that we prepared in our previous labs. The datasets are saved as .RDS files in 01_data folder, we will import them using readRDS() function and assign them to the objects with same names as in lab 2:\n\nErebia stirius occurrences and pseudo absences with environmental data - stirius_pa_final,\nE. stitirus buffer around the presence points - stirius_buffer,\nE. stirius bioclimatic background - stirius_bioclim.\n\n\nstirius_pa_final &lt;- readRDS(\"01_data/stirius_pa_final.RDS\") \n\n\nstirius_buffer &lt;- terra::vect(readRDS(\"01_data/stirius_buffer.RDS\"))\n\n\nlibrary(terra)\n\nstirius_bioclim &lt;- crop(geodata::worldclim_global(var = \"bio\",\n                                          res = 2.5,\n                                          path = \"01_data\"),\n                        stirius_buffer,\n                        mask = TRUE)"
  },
  {
    "objectID": "posts/05_SDMs_Future_projections.html#data-import",
    "href": "posts/05_SDMs_Future_projections.html#data-import",
    "title": "PROJECTING SPECIES DISTRIBUTION ACCORDING TO FUTURE SCENARIOS",
    "section": "Data import",
    "text": "Data import\nFirst, load the data that we prepared in our previous labs. The datasets are saved as .RDS files in 01_data folder, we will import them using readRDS() function and assign them to the objects with same names as in lab 2:\n\nErebia stirius occurrences and pseudo absences with environmental data - stirius_pa_final (dataframe)\nE. stitirus buffer around the presence points - stirius_buffer (Spatial poligon)\nE. stirius bioclimatic background - stirius_bioclim (raster brick)\n\n\nlibrary(dplyr)\nstirius_pa_final &lt;- readRDS(\"01_data/stirius_pa_final.RDS\") \n\n\nstirius_buffer &lt;- terra::vect(readRDS(\"01_data/stirius_buffer.RDS\"))\n\n\nlibrary(terra)\n\nbioclim_data &lt;- geodata::worldclim_global(var = \"bio\",\n                                          res = 2.5,\n                                          path = \"01_data\")\n\n\nstirius_bioclim &lt;- crop(bioclim_data,\n                        stirius_buffer,\n                        mask = TRUE)"
  },
  {
    "objectID": "posts/05_SDMs_Future_projections.html#ipcc-rcp-and-ssp-scenarios-future-bio-climatic-data",
    "href": "posts/05_SDMs_Future_projections.html#ipcc-rcp-and-ssp-scenarios-future-bio-climatic-data",
    "title": "PROJECTING SPECIES DISTRIBUTION ACCORDING TO FUTURE SCENARIOS",
    "section": "IPCC RCP and SSP Scenarios & future bio-climatic data",
    "text": "IPCC RCP and SSP Scenarios & future bio-climatic data\nIntergovernmental Panel on Climate Change (IPCC) defined multiple scenarios (Representative Concentration Pathways scenarios: RCP 26, 45, 60, 85) of how greenhouse gases and other human activities will potentially influence our planet until 2100 (and beyond). The RCPs were used by Coupled Model Intercomparison Project (CMIP5) to model effects of future climate changes on environmental variables (more info: here). After 2021 IPCC report the CMIP6 was developed based on the Shared Socio-economic Pathways scenarios (SSPs) that represents advancements in RCPs. This new data became freely available through geodata package on 1st December 2022.\n\n\n\nIPCC Shared Socio-economic Pathways.\n\n\nThese scenarios take into account actions and measures for reducing emission while one scenario predicts what will happen if we continue doing everything as we are doing it now. The scenarios are then used to model the environmental changes (as in changes of Bio1 - Bio19) in different future time frames.\n\n\n\nIPCC carbon emision scenarios.\n\n\n\nWe will access and download future global bioclimatic variables with cmip6_world() function from geodata() package. We will use predicted bioclimatic variables (var = \"bioc\") on 2.5 resolution scale (~4.8 km; res = 2.5) for scenario ssp = 585 predicted with model = 'ACCESS-ESM1-5' for the years 2061-2080 and save it to an object called bioclim_future_SSP126_2080:\n\nbioclim_future_SSP126_2080 &lt;- \n    geodata::cmip6_world(\n        model = \"ACCESS-ESM1-5\",\n        ssp = \"126\",\n        time = \"2061-2080\",\n        var = \"bioc\",\n        path = \"01_data\",\n        res = 2.5\n    )\n\n\nnames(bioclim_future_SSP126_2080)\n\n\n\n[1] \"wc2.1_2.5m_bioc_ACCESS-ESM1-5_ssp126_2061-2080_1\"\n\n\n\n\n\nThe name of each variable starts with wc2.1_2.5m_bioc: which tells us about the variable itself - wc2.1 means it come from WorldClim version 2.1 and 2.5m tells us it is in 2.5 arc minute resolution and bioc that it as bioclimatic dataset.\nSuccesive parts of the name represent:\n\nACCESS-ESM1-5 comes from the model = 'ACCESS-ESM1-5' and represents the choosen extrapolation model (list here),\nssp126 comes from ssp = 126 and represents the Shared Socio-Economic scenario,\n2060-2081 comes from time = 2061-2080 and represents the choosen future period,\n1 - 19 denote the consecutive number of bioclimatic variable in the dataset.\n\n\nRemember, for present, the variables in worldclim dataset follow nomenclature BIO1, BIO2, …, to BIO19 and the actual environmental variables behind these codes are:\n\nBIO1 = Annual Mean Temperature\nBIO2 = Mean Diurnal Range (Mean of monthly (max temp ‐ min temp))\nBIO3 = Isothermality (P2/P7) (* 100)\nBIO4 = Temperature Seasonality (standard deviation *100)\nBIO5 = Max Temperature of Warmest Month\nBIO6 = Min Temperature of Coldest Month\nBIO7 = Temperature Annual Range (P5‐P6)\nBIO8 = Mean Temperature of Wettest Quarter\nBIO9 = Mean Temperature of Driest Quarter\nBIO10 = Mean Temperature of Warmest Quarter\nBIO11 = Mean Temperature of Coldest Quarter\nBIO12 = Annual Precipitation\nBIO13 = Precipitation of Wettest Month\nBIO14 = Precipitation of Driest Month\nBIO15 = Precipitation Seasonality (Coefficient of Variation)\nBIO16 = Precipitation of Wettest Quarter\nBIO17 = Precipitation of Driest Quarter\nBIO18 = Precipitation of Warmest Quarter\nBIO19 = Precipitation of Coldest Quarter\n\n\n\nAnd also predicted bioclimatic variables (var = \"bioc\") on 2.5 resolution scale for scenario ssp = 585 predicted with model = 'ACCESS-ESM1-5' for the years 2061-2080 and save it to an object called bioclim_future_SSP585_2080:\n\nbioclim_future_SSP585_2080 &lt;- \n    geodata::cmip6_world(\n        model = \"ACCESS-ESM1-5\",\n        ssp = \"585\",\n        time = \"2061-2080\",\n        var = \"bioc\",\n        path = \"01_data\",\n        res = 2.5\n    )"
  },
  {
    "objectID": "posts/05_SDMs_Future_projections.html#compare-present-and-future-environmental-data-within-research-area",
    "href": "posts/05_SDMs_Future_projections.html#compare-present-and-future-environmental-data-within-research-area",
    "title": "PROJECTING SPECIES DISTRIBUTION ACCORDING TO FUTURE SCENARIOS",
    "section": "Compare present and future environmental data within research area",
    "text": "Compare present and future environmental data within research area\nWe create a mask that will contain bioclim variables cropped or extracted from the entire bioclim_future_SSP126_2080 and bioclim_future_SSP585_2080 only for the area of stirius_buffer. We do this with crop() function within which we set the we want to keep only the extent within the buffer mask = TRUE. We will assign the results of this actions to new objects - stirius_bioclim_future_SSP126_2080 and stirius_bioclim_future_SSP585_2080:\n\nstirius_bioclim_future_SSP126_2080 &lt;-\n    crop(bioclim_future_SSP126_2080,\n         stirius_buffer,\n         mask = TRUE)  \n\nplot(stirius_bioclim_future_SSP126_2080)\n\n\n\n\n\nstirius_bioclim_future_SSP585_2080 &lt;-\n    crop(bioclim_future_SSP585_2080,\n         stirius_buffer,\n         mask = TRUE)\n\n\n\nNext, lets visualise present and both future scenarios for variable Bio1 - Annual Mean Temperature. To display 3 plots within one frame, we first set plotting parameter to par(mfrow = c(1,3)) - this means plots will be shown in one row with three equal size places. Than we run the command for each plot, remember simple way of accessing layers from raster stack can done by using double [[]] and specifying the number of the layer we want. With main = \"Some text\" we add a title to our plot (to distinguish what layer is displayed in which slot).\n\nop &lt;- par(mfrow = c(1,3)) # show three plots one next to another\n\nplot(stirius_bioclim[[1]], main = \"Present\")\n\nplot(stirius_bioclim_future_SSP126_2080[[1]], main = \"Future 2080 SSP 126\")\n\nplot(stirius_bioclim_future_SSP585_2080[[1]], main = \"Future 2080 SSP 585\")\n\npar(op) # reset plot settings\n\n\nAs it a bit hard to compare this three plots due to uneven scales, lets calculate range of values for each raster layer of Bio1. The layer can be accessed with [[1]] and provided to the function global(), which requires a specific summary statistics function \"range\" and \"mean\", with added argument na.rm = TRUE to ignore NA values:\n\nglobal(c(stirius_bioclim[[1]], \n         stirius_bioclim_future_SSP126_2080[[1]],\n         stirius_bioclim_future_SSP585_2080[[1]]), \n       c(\"range\", \"mean\"), na.rm = TRUE)\n\n                                                      mean    min    max\nwc2.1_2.5m_bio_1                                  6.966854 -5.852 14.233\nwc2.1_2.5m_bioc_ACCESS-ESM1-5_ssp126_2061-2080_1 10.010267 -2.900 17.400\nwc2.1_2.5m_bioc_ACCESS-ESM1-5_ssp585_2061-2080_1 11.927445 -1.000 19.200\n\n\nWe will use this values to define the common scale with range = c(min, max) in all three plots, color them with heat colors and give them a short, meaningful title with main =. To plot all three at once, we add the op &lt;- par(mfrow = c(1,3)) command.\n\nop &lt;- par(mfrow = c(1,3))  \n\nplot(\n    stirius_bioclim[[1]],\n    range = c(-6, 20), # add common scale\n    col = rev(heat.colors(999)), # change to reversed heat colors\n    main = \"Present\" # add title\n) \n\n\nplot(\n    stirius_bioclim_future_SSP126_2080[[1]],\n    range = c(-6, 20),\n    col = rev(heat.colors(999)),\n    main = \"SSP126 2080\"\n)\n\nplot(\n    stirius_bioclim_future_SSP585_2080[[1]],\n    range = c(-6, 20),\n    col = rev(heat.colors(999)),\n    main = \"SSP585 2080\"\n)\n\n\n\npar(op) \n\n\nAnd visualise frequencies of bio1 values with a histogram for each scenario within our research area. This time, we will display histograms one below another par(mfrow = c(3,1)) - three rows with one plot, and use xlim to make them with common x axis (values correspond to those of range =) above:\n\nop &lt;- par(mfrow = c(3,1)) \n\nhist(values(stirius_bioclim[[1]]), \n      xlim = c(-6, 20), # add common scale\n      main = \"Present\")\n\nhist(values(stirius_bioclim_future_SSP126_2080[[1]]), \n      xlim = c(-6, 20), # add common scale\n      main = \"SSP126 2080\")\n\nhist(values(stirius_bioclim_future_SSP585_2080[[1]]), \n      xlim = c(-6, 20), # add common scale\n      main = \"SSP585 2080\")\n\n\n\npar(op)\n\nWe note that present and future SSP26 for 2080 conditions overlap a lot, while this overlap is lower between present and future SSP585 for 2080 and at the tails the distributions diverge (SSP585 for 2080 has two bins at right tail, that are not represented in present conditions.\n\n\n\n\n\n\nImportant\n\n\n\nWe fitted or “trained” our models within certain ranges of predictor variables (-6 to 14 °C in terms of bio_1). If the values of the predictor in the future change so much, that there is little or no overlap with present conditions, we need to be very cautious with interpreting our results. The uncertainty of predictions outside of training data is usually very high and our confidence in their accuracy conversely should be very low!\n\n\n\n\n\n\n\n\n\nTask\n\n\n\nChoose one of the precipitation variables (bio_13 - bio_19) and:\n\nexplore the range and mean of its values within present, future SSP26 and future SSP585 conditions,\nplot all three rasters next to each other and with a common scale, compare how they differ (if they do),\nplot values of all three rasters as histograms one below another (don’t forget the common x axis) and compare their distributions."
  },
  {
    "objectID": "posts/05_SDMs_Future_projections.html#final-projects",
    "href": "posts/05_SDMs_Future_projections.html#final-projects",
    "title": "PROJECTING SPECIES DISTRIBUTION ACCORDING TO FUTURE SCENARIOS",
    "section": "Final projects",
    "text": "Final projects\nWith this, we concluded all the topics we wanted you to get familiar with as a part of this lab. As we have emphasized throughout the course, all steps of data acquiring, processing, analysis and modeling were simplified and we did not delve in details as our time is limited. You can get detail descriptions about habitat suitability modeling theory and application in Pearson (2010) and Guisan et al. (2017).\n\n\n\nConsiderations and limitations.\n\n\nThe only thing left to complete are your group projects. So, what I expect of you to do and present is the following:\n\nspecies description (short description, visual appearance, ecological characteristics that are potentially important to understand and interpret models),\nspecies occurrence (map occurrences from GBIF),\nbioclimatic variable selection (correlation analysis and short explanation of selection)\ncreate GLM and RF models (model evaluation via AUC and short explanation)\nmap and compare present habitat suitability from both models\nproject results to the future and map them\n\nuse both models for predictions with minimum two different future scenarios (a total of four predictions),\nshortly explain how the distribution of your two species might change in the future according to your models.\n\n\nThe results of your work should be a powerpoint or similar type of presentation, written report is not required. The presentation should be 10 - 12 minutes long, I encourage you to use visual material as much as possible (photos, plots, maps) which you should briefly explain during your presentation."
  },
  {
    "objectID": "posts/05_SDMs_Future_projections.html#before-we-start",
    "href": "posts/05_SDMs_Future_projections.html#before-we-start",
    "title": "PROJECTING SPECIES DISTRIBUTION ACCORDING TO FUTURE SCENARIOS",
    "section": "Before we start",
    "text": "Before we start\n\n\n\n\n\n\nTask\n\n\n\n\nOpen the folder Introduction to species distribution models,\nStart RStudio from the Rproject icon named Introduction to species distribution models.\nOpen the R script named Erebia stirius.\nWhen following this lab, continue to copy & paste the code in the script so it is organised as it is in teaching materials."
  },
  {
    "objectID": "posts/05_SDMs_Future_projections.html#model-projections-to-the-future-within-research-area",
    "href": "posts/05_SDMs_Future_projections.html#model-projections-to-the-future-within-research-area",
    "title": "PROJECTING SPECIES DISTRIBUTION ACCORDING TO FUTURE SCENARIOS",
    "section": "Model projections to the future within research area",
    "text": "Model projections to the future within research area\nWe already limited the extent of future bioclimatic variables to our research area. For predictions to work, we have to also change the names of the variables within stirius_bioclim_future_SSP585_2080 and stirius_bioclim_future_SSP126_2080 to correspond to the names of the variables in bioclim dataset (wc2.1_2.5m_bio_x). This is required, as both models (GLM and RF) have these names in their formulas, remember?\n\nglm_4 &lt;-\n    glm(\n        presence ~ wc2.1_2.5m_bio_4 + wc2.1_2.5m_bio_6 + wc2.1_2.5m_bio_8 + wc2.1_2.5m_bio_15,\n        family = \"binomial\",\n        data = stirius_pa_final\n    )\n\n\nlibrary(randomForest)\n\nrf_full &lt;- randomForest(presence ~ wc2.1_2.5m_bio_2 + wc2.1_2.5m_bio_4 + wc2.1_2.5m_bio_6 + wc2.1_2.5m_bio_8 + wc2.1_2.5m_bio_15 + wc2.1_2.5m_bio_17 + wc2.1_2.5m_bio_18, \n                        data = stirius_pa_final,\n                        importance = TRUE,\n                        na.action = na.omit)\n\nWe will thus rename the layers in both future raster stacks. First, we create a vector of names (new_names) in which we paste togehter wc2.1_2.5m_bio_ and a sequence of numbers 1:19. Than we assign this values to names of each future raster stack (i.e. names(stirius_bioclim_future_SSP585_2080) &lt;- new_names):\n\n# create sequence bio1 - bio19 and rename variables\nnew_names &lt;- paste(\"wc2.1_2.5m_bio_\", 1:19, sep = \"\")\n\nnames(stirius_bioclim_future_SSP585_2080) &lt;- new_names \n\nnames(stirius_bioclim_future_SSP126_2080) &lt;- new_names\n\n\nnames(stirius_bioclim_future_SSP126_2080)\nnames(stirius_bioclim_future_SSP585_2080)\n\n\nNext we use function predict() from terra package to project habitat suitability of our species to future. Within it, we specify first an object with raster layer(s) with predicted future bioclimatic variables (stirius_bioclim_future_SSP126_2080 and stirius_bioclim_future_SSP585_2080), second argument as one of our models (glm_4 or rf_full) and type of predictions we want (`response``{.R}). We will store these predictions into 4 new objects:\n\nprediction_rf_SSP26_2080 and prediction_rf_SSP585_2080 will be random forest predictions for two different scenarios,\nprediction_glm_SSP26_2080 and prediction_glm_SSP585_2080 will be GLMs predictions for two different scenarios.\n\n\n\n# projects the model to novel conditions\nprediction_rf_SSP126_2080 &lt;- predict(stirius_bioclim_future_SSP126_2080,\n                                            rf_full,\n                                            type = \"response\") \n\nprediction_rf_SSP585_2080 &lt;- predict(stirius_bioclim_future_SSP585_2080,\n                                            rf_full,\n                                            type = \"response\")\n\nprediction_glm_SSP126_2080 &lt;- predict(stirius_bioclim_future_SSP126_2080,\n                                             glm_4, \n                                             type = \"response\")\n\nprediction_glm_SSP585_2080 &lt;- predict(stirius_bioclim_future_SSP585_2080,\n                                             glm_4, \n                                             type = \"response\")\n\nWe will use this four predictions and map all of them with leaflet() style function from terra. First we define the color palette going from 0 (not suitable) to 1 (suitable habitat).\n\nlibrary(leaflet)\n\npal1 &lt;- colorNumeric(palette = \"Reds\",\n                     domain = c(0, 1),\n                     na.color = \"transparent\")\n\nWe will also combine the four layers into one object called predictions and give each layer a nicer name:\n\npredictions &lt;- c(\n    prediction_glm_SSP126_2080,\n    prediction_glm_SSP585_2080,\n    prediction_rf_SSP126_2080,\n    prediction_rf_SSP585_2080\n)\n\nnames(predictions) &lt;- c(\"GLM SSP126 2080\", \"GLM SSP585 2080\", \n                        \"RF SSP126 2080\", \"RF SSP585 2080\") \n\nWe will plot the predictions with plet() function in which we need to define the basemap (tile =), colors that will be used (col =), the name of the legend (main =) and the transparency of the plotted raster (alpha =).\nAs we will be plotting more than one layer, we need to add the sequence of the layer we want to be shown, right behind the object with layers (1:4). In addition, we want layer control to be visible (collapse = FALSE) and the lagend to be shared between all layers (shared = TRUE):\n\n# Visualise all predictions on the same map with option to choose one of them \nplet(predictions, 1:4,\n     tile = \"Esri.WorldImagery\",\n     col = pal1,\n     main = names(predictions),\n     alpha = 1,\n     collapse = FALSE,\n     shared = TRUE\n)\n\n\n\n\n\n\n\n\n\n\n\n\nTask\n\n\n\n\nDownload future bioclimatic data for two SSPs in a time period of your choice,\nExplore the range and mean of its values with present conditions\nCrop these two global layers to contain data only within stirius_buffer extent,\nRename layers with wc2.1_2.5m_bio_1 - wc2.1_2.5m_bio_19 (new_names),\nUse glm_4 and rf_full to create predictions for these two future scenarios (a total of 4 predictions),\nPlot all projections together on the same plet map and try to interpret changes.\n\n\n\n\n\nWith this, we concluded all the topics we wanted you to get familiar with as a part of this lab. As we have emphasized throughout the course, all steps of data acquiring, processing, analysis and modelling were simplified and we did not delve into much details. You can get detailed descriptions about habitat suitability modelling theory and application in Pearson (2010) and Guisan et al. (2017) (and many other).\n\n\n\nConsiderations and limitations.\n\n\n\n\n\n\n\n\n\n\nFinal projects\n\n\n\nThe only thing left to complete are your group projects. So, what I expect of you to do and present is the following:\n\nspecies description (short description, visual appearance, ecological characteristics that are potentially important to understand and interpret models),\nspecies occurrence (map occurrences from GBIF),\nbioclimatic variable selection (correlation analysis and short explanation of selection)\ncreate GLM and RF models (model evaluation via AUC and short explanation)\nmap and compare present habitat suitability from both models\nproject results to the future and map them\n\nuse both models for predictions with minimum two different future scenarios (a total of four predictions),\nshortly explain how the distribution of your species might change in the future according to your models.\n\n\nThe results of your work should be a powerpoint or similar type of presentation, written report is not required. The presentation should be 10 - 12 minutes long, I encourage you to use visual material as much as possible (photos, plots, maps) which you should briefly explain during your presentation."
  },
  {
    "objectID": "posts/05_SDMs_Future_projections.html#task-2",
    "href": "posts/05_SDMs_Future_projections.html#task-2",
    "title": "PROJECTING SPECIES DISTRIBUTION ACCORDING TO FUTURE SCENARIOS",
    "section": "Task",
    "text": "Task\n\nDownload future bioclimatic data for two SSPs in a time period of your choice,\nExplore the range and mean of its values with present conditions\nCrop these two global layers to contain data only within stirius_buffer extent,\nRename layers with wc2.1_2.5m_bio_1 - wc2.1_2.5m_bio_19 (new_names),\nUse glm_4 and rf_full to create predictions for these two future scenarios (a total of 4 predictions),\nPlot all projections together on the same plet map and try to interpret changes.\n\n\nWith this, we concluded all the topics we wanted you to get familiar with as a part of this lab. As we have emphasized throughout the course, all steps of data acquiring, processing, analysis and modelling were simplified and we did not delve in details. You can get detail descriptions about habitat suitability modelling theory and application in Pearson (2010) and Guisan et al. (2017) (and many other).\n\n\n\nConsiderations and limitations.\n\n\n\n\n\n\n\n\nFinal projects\n\n\n\nThe only thing left to complete are your group projects. So, what I expect of you to do and present is the following:\n\nspecies description (short description, visual appearance, ecological characteristics that are potentially important to understand and interpret models),\nspecies occurrence (map occurrences from GBIF),\nbioclimatic variable selection (correlation analysis and short explanation of selection)\ncreate GLM and RF models (model evaluation via AUC and short explanation)\nmap and compare present habitat suitability from both models\nproject results to the future and map them\n\nuse both models for predictions with minimum two different future scenarios (a total of four predictions),\nshortly explain how the distribution of your two species might change in the future according to your models.\n\n\nThe results of your work should be a powerpoint or similar type of presentation, written report is not required. The presentation should be 10 - 12 minutes long, I encourage you to use visual material as much as possible (photos, plots, maps) which you should briefly explain during your presentation."
  }
]